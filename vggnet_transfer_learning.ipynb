{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0-rc1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Uses tf.contrib.data module which is in release candidate 1.2.0rc0\n",
    "Based on:\n",
    "    - PyTorch example from Justin Johnson:\n",
    "      https://gist.github.com/jcjohnson/6e41e8512c17eae5da50aebef3378a4c\n",
    "      - https://gist.github.com/omoindrot/dedc857cdc0e680dfb1be99762990c9c\n",
    "Required packages: tensorflow (v1.2)\n",
    "You can install the release candidate 1.2.0rc0 here:\n",
    "https://www.tensorflow.org/versions/r1.2/install/\n",
    "\n",
    "Download the weights trained on ImageNet for VGG:\n",
    "```\n",
    "wget http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz\n",
    "tar -xvf vgg_16_2016_08_28.tar.gz\n",
    "rm vgg_16_2016_08_28.tar.gz\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "\n",
    "from vggnet_utils import *\n",
    "\n",
    "VGG_MEAN = [123.68, 116.78, 103.94]\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:00<00:00, 60774.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'lr2': 1e-06, 'dp': 0.5, 'lr1': 5e-05, 'wd': 0.0005}, {'lr2': 1e-07, 'dp': 0.5, 'lr1': 5e-05, 'wd': 0.0005}, {'lr2': 1e-05, 'dp': 0.5, 'lr1': 5e-05, 'wd': 0.0005}, {'lr2': 1e-06, 'dp': 0.5, 'lr1': 0.001, 'wd': 0.0005}, {'lr2': 1e-07, 'dp': 0.5, 'lr1': 0.001, 'wd': 0.0005}, {'lr2': 1e-05, 'dp': 0.5, 'lr1': 0.001, 'wd': 0.0005}]\n",
      "{'lr2': 1e-06, 'dp': 0.5, 'lr1': 5e-05, 'wd': 0.0005}\n",
      "listed\n",
      "dataset created\n",
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 1\n",
      "Current loss: 10.628801\n",
      "thresh: 0.100000, max F1: 0.382801\n",
      "Current loss: 10.037493\n",
      "thresh: 0.100000, max F1: 0.414635\n",
      "Current loss: 10.805817\n",
      "thresh: 0.100000, max F1: 0.417296\n",
      "Current loss: 10.279757\n",
      "thresh: 0.100000, max F1: 0.443461\n",
      "Current epoch loss: 10.279757\n",
      "Epoch thresh: 0.100000, max F1: 0.443461\n",
      "Starting epoch 1 / 1\n",
      "Current loss: 10.007555\n",
      "thresh: 0.100000, max F1: 0.431770\n",
      "Current loss: 10.336011\n",
      "thresh: 0.100000, max F1: 0.450736\n",
      "Current loss: 9.738379\n",
      "thresh: 0.100000, max F1: 0.465231\n",
      "Current loss: 9.751067\n",
      "thresh: 0.100000, max F1: 0.410952\n",
      "Epoch loss: 9.751067\n",
      "Epoch thresh: 0.100000, max F1: 0.410952\n",
      "Starting epoch 2 / 1\n",
      "Current loss: 10.133892\n",
      "thresh: 0.100000, max F1: 0.428103\n",
      "Current loss: 9.689192\n",
      "thresh: 0.100000, max F1: 0.458323\n",
      "Current loss: 10.464103\n",
      "thresh: 0.100000, max F1: 0.462256\n",
      "Current loss: 9.573012\n",
      "thresh: 0.100000, max F1: 0.452416\n",
      "Epoch loss: 9.573012\n",
      "Epoch thresh: 0.100000, max F1: 0.452416\n",
      "Starting epoch 3 / 1\n",
      "Current loss: 10.533958\n",
      "thresh: 0.100000, max F1: 0.429410\n",
      "Current loss: 10.061406\n",
      "thresh: 0.100000, max F1: 0.450593\n",
      "Current loss: 9.871865\n",
      "thresh: 0.100000, max F1: 0.438990\n",
      "Current loss: 9.547820"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:00<00:00, 376311.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "thresh: 0.250000, max F1: 0.402677\n",
      "Epoch loss: 9.547820\n",
      "Epoch thresh: 0.250000, max F1: 0.402677\n",
      "{'lr2': 1e-07, 'dp': 0.5, 'lr1': 5e-05, 'wd': 0.0005}\n",
      "listed\n",
      "dataset created\n",
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 1\n",
      "Current loss: 9.708883\n",
      "thresh: 0.100000, max F1: 0.483047\n",
      "Current loss: 9.199813\n",
      "thresh: 0.100000, max F1: 0.523258\n",
      "Current loss: 9.355344\n",
      "thresh: 0.100000, max F1: 0.481391\n",
      "Current loss: 8.590098\n",
      "thresh: 0.100000, max F1: 0.521835\n",
      "Current epoch loss: 8.590098\n",
      "Epoch thresh: 0.100000, max F1: 0.521835\n",
      "Starting epoch 1 / 1\n",
      "Current loss: 9.565545\n",
      "thresh: 0.250000, max F1: 0.511056\n",
      "Current loss: 10.158063\n",
      "thresh: 0.100000, max F1: 0.462623\n",
      "Current loss: 8.823673\n",
      "thresh: 0.500000, max F1: 0.527157\n",
      "Current loss: 8.595170\n",
      "thresh: 0.100000, max F1: 0.526031\n",
      "Epoch loss: 8.595170\n",
      "Epoch thresh: 0.100000, max F1: 0.526031\n",
      "Starting epoch 2 / 1\n",
      "Current loss: 9.407018\n",
      "thresh: 0.100000, max F1: 0.491213\n",
      "Current loss: 9.853235\n",
      "thresh: 0.750000, max F1: 0.493252\n",
      "Current loss: 8.497812\n",
      "thresh: 0.250000, max F1: 0.522204\n",
      "Current loss: 9.180522\n",
      "thresh: 0.250000, max F1: 0.503656\n",
      "Epoch loss: 9.180522\n",
      "Epoch thresh: 0.250000, max F1: 0.503656\n",
      "Starting epoch 3 / 1\n",
      "Current loss: 9.465776\n",
      "thresh: 0.100000, max F1: 0.487598\n",
      "Current loss: 9.627128\n",
      "thresh: 0.100000, max F1: 0.476233\n",
      "Current loss: 9.314213\n",
      "thresh: 0.100000, max F1: 0.505929\n",
      "Current loss: 8.518124"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:00<00:00, 367052.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "thresh: 0.250000, max F1: 0.524293\n",
      "Epoch loss: 8.518124\n",
      "Epoch thresh: 0.250000, max F1: 0.524293\n",
      "{'lr2': 1e-05, 'dp': 0.5, 'lr1': 5e-05, 'wd': 0.0005}\n",
      "listed\n",
      "dataset created\n",
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 1\n",
      "Current loss: 10.538985\n",
      "thresh: 0.100000, max F1: 0.324629\n",
      "Current loss: 11.264452\n",
      "thresh: 0.100000, max F1: 0.370807\n",
      "Current loss: 11.578806\n",
      "thresh: 0.100000, max F1: 0.325828\n",
      "Current loss: 9.297522\n",
      "thresh: 0.250000, max F1: 0.322911\n",
      "Current epoch loss: 9.297522\n",
      "Epoch thresh: 0.250000, max F1: 0.322911\n",
      "Starting epoch 1 / 1\n",
      "Current loss: 10.281910\n",
      "thresh: 0.100000, max F1: 0.329909\n",
      "Current loss: 11.106212\n",
      "thresh: 0.100000, max F1: 0.360906\n",
      "Current loss: 10.569511\n",
      "thresh: 0.100000, max F1: 0.430275\n",
      "Current loss: 9.749726\n",
      "thresh: 0.100000, max F1: 0.404699\n",
      "Epoch loss: 9.749726\n",
      "Epoch thresh: 0.100000, max F1: 0.404699\n",
      "Starting epoch 2 / 1\n",
      "Current loss: 9.932203\n",
      "thresh: 0.100000, max F1: 0.393905\n",
      "Current loss: 9.915010\n",
      "thresh: 0.100000, max F1: 0.436029\n",
      "Current loss: 10.379750\n",
      "thresh: 0.100000, max F1: 0.442036\n",
      "Current loss: 9.423435\n",
      "thresh: 0.100000, max F1: 0.351471\n",
      "Epoch loss: 9.423435\n",
      "Epoch thresh: 0.100000, max F1: 0.351471\n",
      "Starting epoch 3 / 1\n",
      "Current loss: 9.677709\n",
      "thresh: 0.100000, max F1: 0.440816\n",
      "Current loss: 9.926279\n",
      "thresh: 0.250000, max F1: 0.468988\n",
      "Current loss: 9.122641\n",
      "thresh: 0.100000, max F1: 0.494934\n",
      "Current loss: 9.589538"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:00<00:00, 380499.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "thresh: 0.100000, max F1: 0.436627\n",
      "Epoch loss: 9.589538\n",
      "Epoch thresh: 0.100000, max F1: 0.436627\n",
      "{'lr2': 1e-06, 'dp': 0.5, 'lr1': 0.001, 'wd': 0.0005}\n",
      "listed\n",
      "dataset created\n",
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 1\n",
      "Current loss: 11.522924\n",
      "thresh: 0.100000, max F1: 0.317002\n",
      "Current loss: 9.787330\n",
      "thresh: 0.100000, max F1: 0.464089\n",
      "Current loss: 8.825499\n",
      "thresh: 0.750000, max F1: 0.576057\n",
      "Current loss: 9.558337\n",
      "thresh: 0.100000, max F1: 0.569960\n",
      "Current epoch loss: 9.558337\n",
      "Epoch thresh: 0.100000, max F1: 0.569960\n",
      "Starting epoch 1 / 1\n",
      "Current loss: 8.104037\n",
      "thresh: 0.750000, max F1: 0.596633\n",
      "Current loss: 8.753656\n",
      "thresh: 0.750000, max F1: 0.618544\n",
      "Current loss: 8.492132\n",
      "thresh: 0.750000, max F1: 0.605605\n",
      "Current loss: 8.817321\n",
      "thresh: 0.750000, max F1: 0.621015\n",
      "Epoch loss: 8.817321\n",
      "Epoch thresh: 0.750000, max F1: 0.621015\n",
      "Starting epoch 2 / 1\n",
      "Current loss: 7.964802\n",
      "thresh: 0.750000, max F1: 0.570656\n",
      "Current loss: 9.258780\n",
      "thresh: 0.750000, max F1: 0.616863\n",
      "Current loss: 8.559749\n",
      "thresh: 0.750000, max F1: 0.605525\n",
      "Current loss: 8.327982\n",
      "thresh: 0.750000, max F1: 0.602332\n",
      "Epoch loss: 8.327982\n",
      "Epoch thresh: 0.750000, max F1: 0.602332\n",
      "Starting epoch 3 / 1\n",
      "Current loss: 8.864462\n",
      "thresh: 0.750000, max F1: 0.613150\n",
      "Current loss: 9.873937\n",
      "thresh: 0.500000, max F1: 0.571826\n",
      "Current loss: 7.112977\n",
      "thresh: 0.750000, max F1: 0.628815\n",
      "Current loss: 8.340298"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:00<00:00, 144561.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "thresh: 0.750000, max F1: 0.614883\n",
      "Epoch loss: 8.340298\n",
      "Epoch thresh: 0.750000, max F1: 0.614883\n",
      "{'lr2': 1e-07, 'dp': 0.5, 'lr1': 0.001, 'wd': 0.0005}\n",
      "listed\n",
      "dataset created\n",
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 1\n",
      "Current loss: 11.892557\n",
      "thresh: 0.100000, max F1: 0.238875\n",
      "Current loss: 9.678385\n",
      "thresh: 0.100000, max F1: 0.456372\n",
      "Current loss: 8.117160\n",
      "thresh: 0.250000, max F1: 0.548410\n",
      "Current loss: 9.413392\n",
      "thresh: 0.500000, max F1: 0.555134\n",
      "Current epoch loss: 9.413392\n",
      "Epoch thresh: 0.500000, max F1: 0.555134\n",
      "Starting epoch 1 / 1\n",
      "Current loss: 7.984505\n",
      "thresh: 0.750000, max F1: 0.617429\n",
      "Current loss: 7.724209\n",
      "thresh: 0.750000, max F1: 0.576494\n",
      "Current loss: 9.251383\n",
      "thresh: 0.750000, max F1: 0.602492\n",
      "Current loss: 7.489954\n",
      "thresh: 0.750000, max F1: 0.611477\n",
      "Epoch loss: 7.489954\n",
      "Epoch thresh: 0.750000, max F1: 0.611477\n",
      "Starting epoch 2 / 1\n",
      "Current loss: 8.579584\n",
      "thresh: 0.750000, max F1: 0.588192\n",
      "Current loss: 8.407468\n",
      "thresh: 0.750000, max F1: 0.576083\n",
      "Current loss: 8.693299\n",
      "thresh: 0.750000, max F1: 0.616948\n",
      "Current loss: 6.838485\n",
      "thresh: 0.750000, max F1: 0.576761\n",
      "Epoch loss: 6.838485\n",
      "Epoch thresh: 0.750000, max F1: 0.576761\n",
      "Starting epoch 3 / 1\n",
      "Current loss: 8.503829\n",
      "thresh: 0.750000, max F1: 0.589194\n",
      "Current loss: 8.217081\n",
      "thresh: 0.750000, max F1: 0.614532\n",
      "Current loss: 8.221737\n",
      "thresh: 0.750000, max F1: 0.595630\n",
      "Current loss: 8.709765"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:00<00:00, 145722.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "thresh: 0.750000, max F1: 0.548493\n",
      "Epoch loss: 8.709765\n",
      "Epoch thresh: 0.750000, max F1: 0.548493\n",
      "{'lr2': 1e-05, 'dp': 0.5, 'lr1': 0.001, 'wd': 0.0005}\n",
      "listed\n",
      "dataset created\n",
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 1\n",
      "Current loss: 9.344441\n",
      "thresh: 0.100000, max F1: 0.457174\n",
      "Current loss: 8.256356\n",
      "thresh: 0.750000, max F1: 0.508306\n",
      "Current loss: 8.556936\n",
      "thresh: 0.500000, max F1: 0.544933\n",
      "Current loss: 10.322712\n",
      "thresh: 0.500000, max F1: 0.544139\n",
      "Current epoch loss: 10.322712\n",
      "Epoch thresh: 0.500000, max F1: 0.544139\n",
      "Starting epoch 1 / 1\n",
      "Current loss: 7.911575\n",
      "thresh: 0.750000, max F1: 0.565912\n",
      "Current loss: 9.147920\n",
      "thresh: 0.750000, max F1: 0.538521\n",
      "Current loss: 8.662244\n",
      "thresh: 0.750000, max F1: 0.588329\n",
      "Current loss: 8.417968\n",
      "thresh: 0.750000, max F1: 0.534555\n",
      "Epoch loss: 8.417968\n",
      "Epoch thresh: 0.750000, max F1: 0.534555\n",
      "Starting epoch 2 / 1\n",
      "Current loss: 9.415633\n",
      "thresh: 0.750000, max F1: 0.592064\n",
      "Current loss: 8.754071\n",
      "thresh: 0.750000, max F1: 0.550955\n",
      "Current loss: 8.868193\n",
      "thresh: 0.750000, max F1: 0.544086\n",
      "Current loss: 8.799255\n",
      "thresh: 0.750000, max F1: 0.516465\n",
      "Epoch loss: 8.799255\n",
      "Epoch thresh: 0.750000, max F1: 0.516465\n",
      "Starting epoch 3 / 1\n",
      "Current loss: 9.557267\n",
      "thresh: 0.750000, max F1: 0.563684\n",
      "Current loss: 8.809092\n",
      "thresh: 0.750000, max F1: 0.550585\n",
      "Current loss: 8.881880\n",
      "thresh: 0.750000, max F1: 0.562611\n",
      "Current loss: 9.440928\n",
      "thresh: 0.750000, max F1: 0.586383\n",
      "Epoch loss: 9.440928\n",
      "Epoch thresh: 0.750000, max F1: 0.586383\n"
     ]
    }
   ],
   "source": [
    "experiments = [] # list with dict of params for each experiment\n",
    "\n",
    "lr1s = [5e-5, 1e-3]\n",
    "lr2s = [1e-6, 1e-7, 1e-5]\n",
    "dropout_probs = [0.5]\n",
    "weight_decays = [5e-4]\n",
    "\n",
    "# create a dict of experiments\n",
    "for lr1 in lr1s:\n",
    "    for lr2 in lr2s:\n",
    "        for dp in dropout_probs:\n",
    "            for wd in weight_decays:\n",
    "                experiments.append({'lr1': lr1, 'lr2': lr2, 'dp': dp, 'wd': wd})\n",
    "\n",
    "print(experiments)\n",
    "\n",
    "for params_dict in experiments:\n",
    "    print(params_dict)\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train_dir', default='data/train-jpg/')\n",
    "    parser.add_argument('--model_path', default='vgg_16.ckpt', type=str)\n",
    "    parser.add_argument('--batch_size', default=100, type=int) #32\n",
    "    parser.add_argument('--num_workers', default=50, type=int) #4\n",
    "    parser.add_argument('--num_epochs1', default=1, type=int) #10\n",
    "    parser.add_argument('--num_epochs2', default=3, type=int) #10\n",
    "    parser.add_argument('--learning_rate1', default = params_dict['lr1'], type=float) #1e-3\n",
    "    parser.add_argument('--learning_rate2', default = params_dict['lr2'], type=float)\n",
    "    parser.add_argument('--dropout_keep_prob', default = params_dict['dp'], type=float)\n",
    "    parser.add_argument('--weight_decay', default = params_dict['wd'], type=float)\n",
    "    \n",
    "    # For accessing args in an ipython notebook\n",
    "    import sys; sys.argv=['']; del sys\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Get the list of filenames and corresponding list of labels for training et validation\n",
    "    # train_filenames, train_labels = list_images(args.train_dir)\n",
    "    # val_filenames, val_labels = list_images(args.val_dir)\n",
    "    \n",
    "    all_filenames, all_labels = list_images(args.train_dir)\n",
    "    \n",
    "    train_filenames, train_labels, val_filenames, val_labels = split_samples(all_filenames, all_labels)\n",
    "    \n",
    "    num_classes = 17\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # In TensorFlow, you first want to define the computation graph with all the\n",
    "    # necessary operations: loss, training op, accuracy...\n",
    "    # Any tensor created in the `graph.as_default()` scope will be part of `graph`\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # Standard preprocessing for VGG on ImageNet taken from here:\n",
    "        # https://github.com/tensorflow/models/blob/master/slim/preprocessing/vgg_preprocessing.py\n",
    "        # Also see the VGG paper for more details: https://arxiv.org/pdf/1409.1556.pdf\n",
    "    \n",
    "        # Preprocessing (for both training and validation):\n",
    "        # (1) Decode the image from jpg format\n",
    "        # (2) Resize the image so its smaller side is 256 pixels long\n",
    "        def _parse_function(filename, label):\n",
    "            image_string = tf.read_file(filename)\n",
    "            image_decoded = tf.image.decode_jpeg(image_string, channels=3)          # (1)\n",
    "            image = tf.cast(image_decoded, tf.float32)\n",
    "    \n",
    "            smallest_side = 256.0\n",
    "            height, width = tf.shape(image)[0], tf.shape(image)[1]\n",
    "            height = tf.to_float(height)\n",
    "            width = tf.to_float(width)\n",
    "    \n",
    "            scale = tf.cond(tf.greater(height, width),\n",
    "                            lambda: smallest_side / width,\n",
    "                             lambda: smallest_side / height)\n",
    "            new_height = tf.to_int32(height * scale)\n",
    "            new_width = tf.to_int32(width * scale)\n",
    "    \n",
    "            resized_image = tf.image.resize_images(image, [new_height, new_width])  # (2)\n",
    "            return resized_image, label\n",
    "\n",
    "        # Preprocessing (for training)\n",
    "        # (3) Take a random 224x224 crop to the scaled image\n",
    "        # (4) Horizontally flip the image with probability 1/2\n",
    "        # (5) Substract the per color mean `VGG_MEAN`\n",
    "        # Note: we don't normalize the data here, as VGG was trained without normalization\n",
    "        def training_preprocess(image, label):\n",
    "            crop_image = tf.random_crop(image, [224, 224, 3])                       # (3)\n",
    "            flip_image = tf.image.random_flip_left_right(crop_image)                # (4)\n",
    "    \n",
    "            means = tf.reshape(tf.constant(VGG_MEAN), [1, 1, 3])\n",
    "            centered_image = flip_image - means                                     # (5)\n",
    "    \n",
    "            return centered_image, label\n",
    "    \n",
    "        # Preprocessing (for validation)\n",
    "        # (3) Take a central 224x224 crop to the scaled image\n",
    "        # (4) Substract the per color mean `VGG_MEAN`\n",
    "        # Note: we don't normalize the data here, as VGG was trained without normalization\n",
    "        def val_preprocess(image, label):\n",
    "            crop_image = tf.image.resize_image_with_crop_or_pad(image, 224, 224)    # (3)\n",
    "    \n",
    "            means = tf.reshape(tf.constant(VGG_MEAN), [1, 1, 3])\n",
    "            centered_image = crop_image - means                                     # (4)\n",
    "    \n",
    "            return centered_image, label\n",
    "    \n",
    "            # ----------------------------------------------------------------------\n",
    "            # DATASET CREATION using tf.contrib.data.Dataset\n",
    "            # https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data\n",
    "        \n",
    "            # The tf.contrib.data.Dataset framework uses queues in the background to feed in\n",
    "            # data to the model.\n",
    "            # We initialize the dataset with a list of filenames and labels, and then apply\n",
    "        # the preprocessing functions described above.\n",
    "        # Behind the scenes, queues will load the filenames, preprocess them with multiple\n",
    "        # threads and apply the preprocessing in parallel, and then batch the data\n",
    "    \n",
    "        # Training dataset\n",
    "        train_filenames = tf.constant(train_filenames)\n",
    "        train_labels = tf.constant(train_labels)\n",
    "        train_dataset = tf.contrib.data.Dataset.from_tensor_slices((train_filenames, train_labels))\n",
    "        train_dataset = train_dataset.map(_parse_function,\n",
    "           num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        train_dataset = train_dataset.map(training_preprocess,\n",
    "           num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=10000)  # don't forget to shuffle\n",
    "        batched_train_dataset = train_dataset.batch(args.batch_size)\n",
    "    \n",
    "        # Validation dataset\n",
    "        val_filenames = tf.constant(val_filenames)\n",
    "        val_labels = tf.constant(val_labels)\n",
    "        val_dataset = tf.contrib.data.Dataset.from_tensor_slices((val_filenames, val_labels))\n",
    "        val_dataset = val_dataset.map(_parse_function,\n",
    "        num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        val_dataset = val_dataset.map(val_preprocess,\n",
    "        num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        batched_val_dataset = val_dataset.batch(args.batch_size)\n",
    "\n",
    "        print(\"dataset created\")\n",
    "        # Now we define an iterator that can operator on either dataset.\n",
    "        # The iterator can be reinitialized by calling:\n",
    "        #     - sess.run(train_init_op) for 1 epoch on the training set\n",
    "        #     - sess.run(val_init_op)   for 1 epoch on the valiation set\n",
    "        # Once this is done, we don't need to feed any value for images and labels\n",
    "        # as they are automatically pulled out from the iterator queues.\n",
    "    \n",
    "        # A reinitializable iterator is defined by its structure. We could use the\n",
    "        # `output_types` and `output_shapes` properties of either `train_dataset`\n",
    "        # or `validation_dataset` here, because they are compatible.\n",
    "        iterator = tf.contrib.data.Iterator.from_structure(batched_train_dataset.output_types,\n",
    "                                                           batched_train_dataset.output_shapes)\n",
    "        images, labels = iterator.get_next()\n",
    "        train_init_op = iterator.make_initializer(batched_train_dataset)\n",
    "        val_init_op = iterator.make_initializer(batched_val_dataset)\n",
    "    \n",
    "        # Indicates whether we are in training or in test mode\n",
    "        is_training = tf.placeholder(tf.bool)\n",
    "    \n",
    "        # ---------------------------------------------------------------------\n",
    "        # Now that we have set up the data, it's time to set up the model.\n",
    "        # For this example, we'll use VGG-16 pretrained on ImageNet. We will remove the\n",
    "        # last fully connected layer (fc8) and replace it with our own, with an\n",
    "        # output size num_classes=8\n",
    "        # We will first train the last layer for a few epochs.\n",
    "        # Then we will train the entire model on our dataset for a few epochs.\n",
    "    \n",
    "        # Get the pretrained model, specifying the num_classes argument to create a new\n",
    "        # fully connected replacing the last one, called \"vgg_16/fc8\"\n",
    "        # Each model has a different architecture, so \"vgg_16/fc8\" will change in another model.\n",
    "        # Here, logits gives us directly the predicted scores we wanted from the images.\n",
    "        # We pass a scope to initialize \"vgg_16/fc8\" weights with he_initializer\n",
    "        vgg = tf.contrib.slim.nets.vgg\n",
    "        with slim.arg_scope(vgg.vgg_arg_scope(weight_decay=args.weight_decay)):\n",
    "            logits, _ = vgg.vgg_16(images, num_classes=num_classes, is_training=is_training,\n",
    "                                       dropout_keep_prob=args.dropout_keep_prob)\n",
    "    \n",
    "        # Specify where the model checkpoint is (pretrained weights).\n",
    "        model_path = args.model_path\n",
    "        assert(os.path.isfile(model_path))\n",
    "    \n",
    "        # Restore only the layers up to fc7 (included)\n",
    "        # Calling function `init_fn(sess)` will load all the pretrained weights.\n",
    "        variables_to_restore = tf.contrib.framework.get_variables_to_restore(exclude=['vgg_16/fc8'])\n",
    "        init_fn = tf.contrib.framework.assign_from_checkpoint_fn(model_path, variables_to_restore)\n",
    "    \n",
    "        # Initialization operation from scratch for the new \"fc8\" layers\n",
    "        # `get_variables` will only return the variables whose name starts with the given pattern\n",
    "        fc8_variables = tf.contrib.framework.get_variables('vgg_16/fc8')\n",
    "        fc8_init = tf.variables_initializer(fc8_variables)\n",
    "    \n",
    "        # ---------------------------------------------------------------------\n",
    "        # Using tf.losses, any loss is added to the tf.GraphKeys.LOSSES collection\n",
    "        # We can then call the total loss easily\n",
    "        # tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits) \n",
    "        tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits) # softmax cross entropy loss so can have labels with multiple classes\n",
    "        loss = tf.losses.get_total_loss()  \n",
    "    \n",
    "        # First we want to train only the reinitialized last layer fc8 for a few epochs.\n",
    "        # We run minimize the loss only with respect to the fc8 variables (weight and bias).\n",
    "        fc8_optimizer = tf.train.GradientDescentOptimizer(args.learning_rate1)\n",
    "        fc8_train_op = fc8_optimizer.minimize(loss, var_list=fc8_variables)\n",
    "\n",
    "        # Then we want to finetune the entire model for a few epochs.\n",
    "        # We run minimize the loss only with respect to all the variables.\n",
    "        full_optimizer = tf.train.GradientDescentOptimizer(args.learning_rate2)\n",
    "        full_train_op = full_optimizer.minimize(loss)\n",
    "    \n",
    "        # Evaluation metrics\n",
    "        \n",
    "        tf.get_default_graph().finalize()\n",
    "    \n",
    "    # --------------------------------------------------------------------------\n",
    "    # Now that we have built the graph and finalized it, we define the session.\n",
    "    # The session is the interface to *run* the computational graph.\n",
    "    # We can call our training operations with `sess.run(train_op)` for instance\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        init_fn(sess)  # load the pretrained weights\n",
    "        sess.run(fc8_init)  # initialize the new fc8 layer\n",
    "    \n",
    "        # Update only the last layer for a few epochs.\n",
    "        for epoch in range(args.num_epochs1):\n",
    "            # Run an epoch over the training data.\n",
    "            print('Starting epoch %d / %d' % (epoch + 1, args.num_epochs1))\n",
    "            # Here we initialize the iterator with the training set.\n",
    "            # This means that we can go through an entire epoch until the iterator becomes empty.\n",
    "            sess.run(train_init_op)\n",
    "            while True:\n",
    "                try:\n",
    "                    _, curr_loss, curr_logits, curr_labels = sess.run([fc8_train_op, loss, logits, labels], {is_training: True})\n",
    "                    \n",
    "                    print('Current loss: %f' % curr_loss)\n",
    "\n",
    "                    # Check F1 score on logits\n",
    "                    threshs = [0.1, 0.25, 0.5, 0.75]\n",
    "                    F1s = []\n",
    "                    for i in range(len(threshs)):\n",
    "                        F1s.append(fbeta_score(curr_labels, np.array(curr_logits) > threshs[i], beta=2, average='samples'))\n",
    "                    max_i = F1s.index(max(F1s))\n",
    "                    print('thresh: %f, max F1: %f' %(threshs[max_i], F1s[max_i]))\n",
    "                \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "            \n",
    "            # Print current loss\n",
    "            print('Current epoch loss: %f' % curr_loss)\n",
    "            \n",
    "            # Check F1 score on logits\n",
    "            threshs = [0.1, 0.25, 0.5, 0.75]\n",
    "            F1s = []\n",
    "            for i in range(len(threshs)):\n",
    "                F1s.append(fbeta_score(curr_labels, np.array(curr_logits) > threshs[i], beta=2, average='samples'))\n",
    "            max_i = F1s.index(max(F1s))\n",
    "            print('Epoch thresh: %f, max F1: %f' %(threshs[max_i], F1s[max_i]))\n",
    "            \n",
    "            # Check accuracy on the train and val sets every epoch.\n",
    "            # train_acc = check_accuracy(sess, correct_prediction, is_training, train_init_op)\n",
    "            # val_acc = check_accuracy(sess, correct_prediction, is_training, val_init_op)\n",
    "            # print('Train accuracy: %f' % train_acc)\n",
    "            # print('Val accuracy: %f\\n' % val_acc)\n",
    "    \n",
    "    \n",
    "        # Train the entire model for a few more epochs, continuing with the *same* weights.\n",
    "        for epoch in range(args.num_epochs2):\n",
    "            print('Starting epoch %d / %d' % (epoch + 1, args.num_epochs1))\n",
    "            sess.run(train_init_op)\n",
    "            while True:\n",
    "                try:\n",
    "                    _, curr_loss, curr_logits, curr_labels = sess.run([full_train_op, loss, logits, labels], {is_training: True})\n",
    "                    print('Current loss: %f' % curr_loss)\n",
    "    \n",
    "                    # Check F1 score on logits\n",
    "                    threshs = [0.1, 0.25, 0.5, 0.75]\n",
    "                    F1s = []\n",
    "                    for i in range(len(threshs)):\n",
    "                        F1s.append(fbeta_score(curr_labels, np.array(curr_logits) > threshs[i], beta=2, average='samples'))\n",
    "                    max_i = F1s.index(max(F1s))\n",
    "                    print('thresh: %f, max F1: %f' %(threshs[max_i], F1s[max_i]))\n",
    "                    \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "    \n",
    "            # Print current loss\n",
    "            print('Epoch loss: %f' % curr_loss)\n",
    "    \n",
    "            # Check F1 score on logits\n",
    "            threshs = [0.1, 0.25, 0.5, 0.75]\n",
    "            F1s = []\n",
    "            for i in range(len(threshs)):\n",
    "                F1s.append(fbeta_score(curr_labels, np.array(curr_logits) > threshs[i], beta=2, average='samples'))\n",
    "            max_i = F1s.index(max(F1s))\n",
    "            print('Epoch thresh: %f, max F1: %f' %(threshs[max_i], F1s[max_i]))\n",
    "            \n",
    "            # Check accuracy on the train and val sets every epoch\n",
    "            # train_acc = check_accuracy(sess, correct_prediction, is_training, train_init_op)\n",
    "            # val_acc = check_accuracy(sess, correct_prediction, is_training, val_init_op)\n",
    "            # print('Train accuracy: %f' % train_acc)\n",
    "            # print('Val accuracy: %f\\n' % val_acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
