{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0-rc1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Uses tf.contrib.data module which is in release candidate 1.2.0rc0\n",
    "Based on:\n",
    "    - PyTorch example from Justin Johnson:\n",
    "      https://gist.github.com/jcjohnson/6e41e8512c17eae5da50aebef3378a4c\n",
    "      - https://gist.github.com/omoindrot/dedc857cdc0e680dfb1be99762990c9c\n",
    "Required packages: tensorflow (v1.2)\n",
    "You can install the release candidate 1.2.0rc0 here:\n",
    "https://www.tensorflow.org/versions/r1.2/install/\n",
    "\n",
    "Download the weights trained on ImageNet for VGG:\n",
    "```\n",
    "wget http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz\n",
    "tar -xvf vgg_16_2016_08_28.tar.gz\n",
    "rm vgg_16_2016_08_28.tar.gz\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "\n",
    "from vggnet_utils import *\n",
    "\n",
    "VGG_MEAN = [123.68, 116.78, 103.94]\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:00<00:00, 390299.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'lr2': 1e-05, 'wd': 0.0001, 'dp': 0.4, 'lr1': 0.001}]\n",
      "{'lr2': 1e-05, 'wd': 0.0001, 'dp': 0.4, 'lr1': 0.001}\n",
      "listed\n",
      "dataset created\n",
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 10\n",
      "Current loss: 7.705766\n",
      "thresh: 0.250000, max F: 0.473975\n",
      "Current loss: 8.107130\n",
      "thresh: 0.800000, max F: 0.630032\n",
      "Current loss: 7.674615\n",
      "thresh: 0.800000, max F: 0.658615\n",
      "Current loss: 8.124624\n",
      "thresh: 0.900000, max F: 0.684927\n",
      "Current loss: 8.112829\n",
      "thresh: 0.750000, max F: 0.642529\n",
      "Current loss: 7.545458\n",
      "thresh: 0.900000, max F: 0.649560\n",
      "Current loss: 7.540549\n",
      "thresh: 0.900000, max F: 0.675468\n",
      "Current loss: 7.616459\n",
      "thresh: 0.750000, max F: 0.627566\n",
      "Current loss: 7.288611\n",
      "thresh: 0.900000, max F: 0.658123\n",
      "Current loss: 7.957115\n",
      "thresh: 0.750000, max F: 0.644743\n",
      "Current loss: 7.737102\n",
      "thresh: 0.950000, max F: 0.665767\n",
      "Current loss: 7.825218\n",
      "thresh: 0.800000, max F: 0.646709\n",
      "Current loss: 7.398033\n",
      "thresh: 0.900000, max F: 0.661985\n",
      "Current loss: 8.405693\n",
      "thresh: 0.800000, max F: 0.688250\n",
      "Current loss: 7.999835\n",
      "thresh: 0.900000, max F: 0.669203\n",
      "Current loss: 8.602598\n",
      "thresh: 0.800000, max F: 0.682773\n",
      "Current loss: 7.371038\n",
      "thresh: 0.900000, max F: 0.688544\n",
      "Current loss: 7.506722\n",
      "thresh: 0.800000, max F: 0.658739\n",
      "Current loss: 7.333869\n",
      "thresh: 0.950000, max F: 0.617708\n",
      "Current loss: 8.245564\n",
      "thresh: 0.900000, max F: 0.691688\n",
      "Current loss: 7.745954\n",
      "thresh: 0.800000, max F: 0.663931\n",
      "Current loss: 7.615249\n",
      "thresh: 0.950000, max F: 0.671521\n",
      "Current loss: 7.283433\n",
      "thresh: 0.900000, max F: 0.656327\n",
      "Current loss: 7.653917\n",
      "thresh: 0.750000, max F: 0.648754\n",
      "Current loss: 7.971028\n",
      "thresh: 0.900000, max F: 0.691002\n",
      "Current loss: 7.604570\n",
      "thresh: 0.800000, max F: 0.657667\n",
      "Current loss: 7.879570\n",
      "thresh: 0.950000, max F: 0.679039\n",
      "Current loss: 7.707888\n",
      "thresh: 0.950000, max F: 0.693227\n",
      "Current loss: 7.577275\n",
      "thresh: 0.900000, max F: 0.666293\n",
      "Current loss: 7.570898\n",
      "thresh: 0.950000, max F: 0.641669\n",
      "Current loss: 7.639667\n",
      "thresh: 0.950000, max F: 0.666413\n",
      "Current loss: 7.308788\n",
      "thresh: 0.950000, max F: 0.640160\n",
      "Current loss: 7.690387\n",
      "thresh: 0.900000, max F: 0.686365\n",
      "Current loss: 7.508782\n",
      "thresh: 0.950000, max F: 0.655729\n",
      "Current loss: 7.055865\n",
      "thresh: 0.950000, max F: 0.617004\n",
      "Current loss: 7.703486\n",
      "thresh: 0.950000, max F: 0.662096\n",
      "Current loss: 7.813953\n",
      "thresh: 0.900000, max F: 0.678453\n",
      "Current loss: 7.462587\n",
      "thresh: 0.950000, max F: 0.653404\n",
      "Current loss: 7.857256\n",
      "thresh: 0.950000, max F: 0.687411\n",
      "Current loss: 7.279233\n",
      "thresh: 0.950000, max F: 0.675874\n",
      "Current loss: 7.590742\n",
      "thresh: 0.950000, max F: 0.672922\n",
      "Current loss: 6.916470\n",
      "thresh: 0.950000, max F: 0.637246\n",
      "Current loss: 8.216129\n",
      "thresh: 0.900000, max F: 0.667933\n",
      "Current loss: 7.690259\n",
      "thresh: 0.900000, max F: 0.643202\n",
      "Current loss: 6.739328\n",
      "thresh: 0.950000, max F: 0.609433\n",
      "Current loss: 7.471691\n",
      "thresh: 0.900000, max F: 0.680389\n",
      "Current loss: 7.558939\n",
      "thresh: 0.950000, max F: 0.678182\n",
      "Current loss: 7.483122\n",
      "thresh: 0.950000, max F: 0.654002\n",
      "Current loss: 7.565633\n",
      "thresh: 0.950000, max F: 0.610506\n",
      "Current loss: 7.347049\n",
      "thresh: 0.950000, max F: 0.687536\n",
      "Current loss: 7.589574\n",
      "thresh: 0.950000, max F: 0.675191\n",
      "Current loss: 7.225434\n",
      "thresh: 0.950000, max F: 0.636899\n",
      "Current loss: 7.610270\n",
      "thresh: 0.950000, max F: 0.636772\n",
      "Current loss: 8.239361\n",
      "thresh: 0.950000, max F: 0.691001\n",
      "Current loss: 7.326095\n",
      "thresh: 0.950000, max F: 0.626412\n",
      "Current loss: 6.597718\n",
      "thresh: 0.950000, max F: 0.614334\n",
      "Current loss: 7.676087\n",
      "thresh: 0.950000, max F: 0.667781\n",
      "Current loss: 7.466783\n",
      "thresh: 0.950000, max F: 0.667195\n",
      "Current loss: 7.591030\n",
      "thresh: 0.950000, max F: 0.662073\n",
      "Current loss: 7.779129\n",
      "thresh: 0.950000, max F: 0.682137\n",
      "Current loss: 7.457506\n",
      "thresh: 0.950000, max F: 0.674781\n",
      "Current loss: 7.535830\n",
      "thresh: 0.800000, max F: 0.646137\n",
      "Current loss: 7.552117\n",
      "thresh: 0.950000, max F: 0.688812\n",
      "Current loss: 7.458510\n",
      "thresh: 0.950000, max F: 0.661648\n",
      "Current loss: 7.589338\n",
      "thresh: 0.950000, max F: 0.644295\n",
      "Current loss: 7.175448\n",
      "thresh: 0.950000, max F: 0.647496\n",
      "Current loss: 7.171080\n",
      "thresh: 0.800000, max F: 0.629604\n",
      "Current loss: 7.507883\n",
      "thresh: 0.950000, max F: 0.668732\n",
      "Current loss: 6.782402\n",
      "thresh: 0.950000, max F: 0.655872\n",
      "Current loss: 7.991936\n",
      "thresh: 0.950000, max F: 0.680675\n",
      "Current loss: 7.681541\n",
      "thresh: 0.950000, max F: 0.684928\n",
      "Current loss: 7.586214\n",
      "thresh: 0.950000, max F: 0.655078\n",
      "Current loss: 7.480848\n",
      "thresh: 0.950000, max F: 0.659459\n",
      "Current loss: 7.425642\n",
      "thresh: 0.750000, max F: 0.645967\n",
      "Current loss: 8.024939\n",
      "thresh: 0.950000, max F: 0.682551\n",
      "Current loss: 7.666930\n",
      "thresh: 0.950000, max F: 0.679066\n",
      "Current loss: 7.662746\n",
      "thresh: 0.900000, max F: 0.668459\n",
      "Current loss: 7.266094\n",
      "thresh: 0.950000, max F: 0.664311\n",
      "Current loss: 7.606024\n",
      "thresh: 0.950000, max F: 0.640501\n",
      "Current loss: 7.384738\n",
      "thresh: 0.900000, max F: 0.638335\n",
      "Current loss: 7.508782\n",
      "thresh: 0.950000, max F: 0.667347\n",
      "Current loss: 7.639489\n",
      "thresh: 0.950000, max F: 0.683391\n",
      "Current loss: 7.381531\n",
      "thresh: 0.950000, max F: 0.672570\n",
      "Current loss: 7.411161\n",
      "thresh: 0.950000, max F: 0.640609\n",
      "Current loss: 7.636919\n",
      "thresh: 0.950000, max F: 0.684838\n",
      "Current loss: 8.029327\n",
      "thresh: 0.950000, max F: 0.684807\n",
      "Current loss: 7.006920\n",
      "thresh: 0.950000, max F: 0.636024\n",
      "Current loss: 7.799825\n",
      "thresh: 0.950000, max F: 0.696235\n",
      "Current loss: 7.324982\n",
      "thresh: 0.950000, max F: 0.652112\n",
      "Current loss: 7.536428\n",
      "thresh: 0.950000, max F: 0.669844\n",
      "Current loss: 7.293441\n",
      "thresh: 0.900000, max F: 0.646526\n",
      "Current loss: 7.498402\n",
      "thresh: 0.950000, max F: 0.661256\n",
      "Current loss: 7.109544\n",
      "thresh: 0.950000, max F: 0.658547\n",
      "Current loss: 7.394672\n",
      "thresh: 0.900000, max F: 0.654728\n",
      "Current loss: 7.632538\n",
      "thresh: 0.950000, max F: 0.666797\n",
      "Current loss: 7.617074\n",
      "thresh: 0.950000, max F: 0.626891\n",
      "Current loss: 7.439856\n",
      "thresh: 0.950000, max F: 0.673920\n",
      "Current loss: 7.528286\n",
      "thresh: 0.950000, max F: 0.676853\n",
      "Current loss: 7.836095\n",
      "thresh: 0.900000, max F: 0.670015\n",
      "Current loss: 7.334895\n",
      "thresh: 0.950000, max F: 0.640788\n",
      "Current loss: 7.679757\n",
      "thresh: 0.950000, max F: 0.659055\n",
      "Current loss: 8.010162\n",
      "thresh: 0.900000, max F: 0.670823\n",
      "Current loss: 7.438351\n",
      "thresh: 0.950000, max F: 0.671961\n",
      "Current loss: 7.897787\n",
      "thresh: 0.950000, max F: 0.648706\n",
      "Current loss: 7.841208\n",
      "thresh: 0.950000, max F: 0.665881\n",
      "Current loss: 7.502980\n",
      "thresh: 0.950000, max F: 0.650447\n",
      "Current loss: 7.579781\n",
      "thresh: 0.950000, max F: 0.637507\n",
      "Current loss: 7.759171\n",
      "thresh: 0.950000, max F: 0.678069\n",
      "Current loss: 7.636508\n",
      "thresh: 0.900000, max F: 0.642733\n",
      "Current loss: 7.832836\n",
      "thresh: 0.950000, max F: 0.654729\n",
      "Current loss: 6.764105\n",
      "thresh: 0.950000, max F: 0.638309\n",
      "Current loss: 7.563117\n",
      "thresh: 0.950000, max F: 0.670602\n",
      "Current loss: 7.709641\n",
      "thresh: 0.950000, max F: 0.665155\n",
      "Current loss: 7.279596\n",
      "thresh: 0.950000, max F: 0.645575\n",
      "Current loss: 7.914669\n",
      "thresh: 0.950000, max F: 0.688448\n",
      "Current loss: 7.633080\n",
      "thresh: 0.950000, max F: 0.656261\n",
      "Current loss: 7.518355\n",
      "thresh: 0.950000, max F: 0.662506\n",
      "Current loss: 7.238753\n",
      "thresh: 0.950000, max F: 0.653058\n",
      "Current loss: 7.503357\n",
      "thresh: 0.900000, max F: 0.645142\n",
      "Current loss: 7.533460\n",
      "thresh: 0.950000, max F: 0.661787\n",
      "Current loss: 8.142088\n",
      "thresh: 0.950000, max F: 0.669994\n",
      "Current loss: 7.480269\n",
      "thresh: 0.950000, max F: 0.653727\n",
      "Current loss: 7.386780\n",
      "thresh: 0.900000, max F: 0.643051\n",
      "Current loss: 7.206829\n",
      "thresh: 0.900000, max F: 0.647724\n",
      "Current loss: 7.519867\n",
      "thresh: 0.950000, max F: 0.648321\n",
      "Current loss: 7.834438\n",
      "thresh: 0.950000, max F: 0.662152\n",
      "Current loss: 7.582345\n",
      "thresh: 0.950000, max F: 0.662278\n",
      "Current loss: 8.206613\n",
      "thresh: 0.500000, max F: 0.646473\n",
      "Current loss: 7.721650\n",
      "thresh: 0.950000, max F: 0.653553\n",
      "Current loss: 7.586019\n",
      "thresh: 0.950000, max F: 0.660787\n",
      "Current loss: 7.990117\n",
      "thresh: 0.950000, max F: 0.693497\n",
      "Current loss: 7.648348\n",
      "thresh: 0.900000, max F: 0.643481\n",
      "Current loss: 7.332264\n",
      "thresh: 0.950000, max F: 0.673590\n",
      "Current loss: 7.953850\n",
      "thresh: 0.750000, max F: 0.670377\n",
      "Current loss: 7.451396\n",
      "thresh: 0.750000, max F: 0.618825\n",
      "Current loss: 7.341569\n",
      "thresh: 0.950000, max F: 0.655411\n",
      "Current loss: 8.043255\n",
      "thresh: 0.950000, max F: 0.680379\n",
      "Current loss: 7.742034\n",
      "thresh: 0.950000, max F: 0.667808\n",
      "Current loss: 7.393820\n",
      "thresh: 0.950000, max F: 0.652899\n",
      "Current loss: 7.447810\n",
      "thresh: 0.950000, max F: 0.637510\n",
      "Current loss: 7.163872\n",
      "thresh: 0.900000, max F: 0.635866\n",
      "Current loss: 7.097525\n",
      "thresh: 0.950000, max F: 0.636969\n",
      "Current loss: 8.058677\n",
      "thresh: 0.950000, max F: 0.652429\n",
      "Current loss: 7.704714\n",
      "thresh: 0.950000, max F: 0.637711\n",
      "Current loss: 7.440552\n",
      "thresh: 0.800000, max F: 0.615235\n",
      "Current loss: 7.790726\n",
      "thresh: 0.950000, max F: 0.666006\n",
      "Current loss: 7.533169\n",
      "thresh: 0.900000, max F: 0.648709\n",
      "Current loss: 7.428510\n",
      "thresh: 0.950000, max F: 0.664054\n",
      "Current loss: 7.332483\n",
      "thresh: 0.950000, max F: 0.636450\n",
      "Current loss: 7.618911\n",
      "thresh: 0.950000, max F: 0.662134\n",
      "Current loss: 7.191607\n",
      "thresh: 0.950000, max F: 0.636973\n",
      "Current loss: 7.647404\n",
      "thresh: 0.950000, max F: 0.643267\n",
      "Current loss: 8.042993\n",
      "thresh: 0.950000, max F: 0.666792\n",
      "Current loss: 7.594489\n",
      "thresh: 0.950000, max F: 0.673052\n",
      "Current loss: 7.416273\n",
      "thresh: 0.950000, max F: 0.678019\n",
      "Current loss: 7.870855\n",
      "thresh: 0.900000, max F: 0.669544\n",
      "Current loss: 7.025302\n",
      "thresh: 0.900000, max F: 0.629651\n",
      "Current loss: 7.292282\n",
      "thresh: 0.950000, max F: 0.652181\n",
      "Current loss: 7.408683\n",
      "thresh: 0.950000, max F: 0.633551\n",
      "Current loss: 7.515421\n",
      "thresh: 0.950000, max F: 0.659510\n",
      "Current loss: 7.416163\n",
      "thresh: 0.950000, max F: 0.656859\n",
      "Current loss: 7.185399\n",
      "thresh: 0.950000, max F: 0.656134\n",
      "Current loss: 7.102078\n",
      "thresh: 0.950000, max F: 0.643345\n",
      "Current loss: 7.799429\n",
      "thresh: 0.900000, max F: 0.636526\n",
      "Current loss: 7.170372\n",
      "thresh: 0.950000, max F: 0.622069\n",
      "Current loss: 8.075661\n",
      "thresh: 0.900000, max F: 0.673933\n",
      "Current loss: 7.437344\n",
      "thresh: 0.950000, max F: 0.643783\n",
      "Current loss: 7.479493\n",
      "thresh: 0.950000, max F: 0.651307\n",
      "Current loss: 7.815660\n",
      "thresh: 0.800000, max F: 0.634208\n",
      "Current loss: 8.055118\n",
      "thresh: 0.950000, max F: 0.694068\n",
      "Current loss: 7.673782\n",
      "thresh: 0.950000, max F: 0.670894\n",
      "Current loss: 8.012877\n",
      "thresh: 0.950000, max F: 0.668959\n",
      "Current loss: 7.570551\n",
      "thresh: 0.950000, max F: 0.647895\n",
      "Current loss: 7.523434\n",
      "thresh: 0.900000, max F: 0.664140\n",
      "Current loss: 7.283954\n",
      "thresh: 0.250000, max F: 0.596842\n",
      "Current loss: 7.656849\n",
      "thresh: 0.950000, max F: 0.666339\n",
      "Current loss: 8.028084\n",
      "thresh: 0.800000, max F: 0.680982\n",
      "Current loss: 7.638842\n",
      "thresh: 0.900000, max F: 0.659748\n",
      "Current loss: 8.008495\n",
      "thresh: 0.950000, max F: 0.667262\n",
      "Current loss: 7.765749\n",
      "thresh: 0.950000, max F: 0.657898\n",
      "Current loss: 7.456293\n",
      "thresh: 0.950000, max F: 0.635950\n",
      "Current loss: 7.361192\n",
      "thresh: 0.950000, max F: 0.654210\n",
      "Current loss: 7.827581\n",
      "thresh: 0.950000, max F: 0.667872\n",
      "Current loss: 7.822440\n",
      "thresh: 0.950000, max F: 0.643884\n",
      "Current loss: 7.058471\n",
      "thresh: 0.950000, max F: 0.626437\n",
      "Current loss: 7.357618\n",
      "thresh: 0.800000, max F: 0.628395\n",
      "Current loss: 7.847589\n",
      "thresh: 0.900000, max F: 0.657644\n",
      "Current loss: 7.611049\n",
      "thresh: 0.950000, max F: 0.647766\n",
      "Current loss: 7.992470\n",
      "thresh: 0.950000, max F: 0.674034\n",
      "Current loss: 7.838305\n",
      "thresh: 0.900000, max F: 0.669421\n",
      "Current loss: 7.410618\n",
      "thresh: 0.500000, max F: 0.631652\n",
      "Current loss: 7.577728\n",
      "thresh: 0.950000, max F: 0.641862\n",
      "Current loss: 7.917022\n",
      "thresh: 0.950000, max F: 0.687277\n",
      "Current loss: 7.478947\n",
      "thresh: 0.950000, max F: 0.666088\n",
      "Current loss: 7.517216\n",
      "thresh: 0.950000, max F: 0.637604\n",
      "Current loss: 8.201311\n",
      "thresh: 0.900000, max F: 0.675160\n",
      "Current loss: 7.632042\n",
      "thresh: 0.950000, max F: 0.658121\n",
      "Current loss: 7.579877\n",
      "thresh: 0.950000, max F: 0.642332\n",
      "Current loss: 7.277755\n",
      "thresh: 0.950000, max F: 0.648362\n",
      "Current loss: 7.396082\n",
      "thresh: 0.950000, max F: 0.633937\n",
      "Current loss: 7.605798\n",
      "thresh: 0.900000, max F: 0.647877\n",
      "Current loss: 7.689570\n",
      "thresh: 0.950000, max F: 0.675697\n",
      "Current loss: 7.775628\n",
      "thresh: 0.750000, max F: 0.644822\n",
      "Current loss: 7.691015\n",
      "thresh: 0.950000, max F: 0.651879\n",
      "Current loss: 7.415866\n",
      "thresh: 0.900000, max F: 0.646488\n",
      "Current loss: 7.613369\n",
      "thresh: 0.900000, max F: 0.667325\n",
      "Current loss: 7.681427\n",
      "thresh: 0.950000, max F: 0.668346\n",
      "Current loss: 7.120376\n",
      "thresh: 0.950000, max F: 0.647487\n",
      "Current loss: 7.417277\n",
      "thresh: 0.950000, max F: 0.639963\n",
      "Current loss: 8.010081\n",
      "thresh: 0.950000, max F: 0.647308\n",
      "Current loss: 7.940122\n",
      "thresh: 0.950000, max F: 0.677654\n",
      "Current loss: 7.575486\n",
      "thresh: 0.800000, max F: 0.640661\n",
      "Current loss: 7.281611\n",
      "thresh: 0.950000, max F: 0.653888\n",
      "Current loss: 7.411449\n",
      "thresh: 0.800000, max F: 0.625269\n",
      "Current loss: 8.257010\n",
      "thresh: 0.900000, max F: 0.684266\n",
      "Current loss: 7.322766\n",
      "thresh: 0.950000, max F: 0.662807\n",
      "Current loss: 7.595459\n",
      "thresh: 0.950000, max F: 0.664080\n",
      "Current loss: 7.901437\n",
      "thresh: 0.950000, max F: 0.656654\n",
      "Current loss: 7.464755\n",
      "thresh: 0.900000, max F: 0.653158\n",
      "Current loss: 7.506495\n",
      "thresh: 0.750000, max F: 0.649009\n",
      "Current loss: 7.583329\n",
      "thresh: 0.950000, max F: 0.653082\n",
      "Current loss: 7.513740\n",
      "thresh: 0.950000, max F: 0.655633\n",
      "Current loss: 7.680975\n",
      "thresh: 0.900000, max F: 0.649547\n",
      "Current loss: 8.058257\n",
      "thresh: 0.950000, max F: 0.674874\n",
      "Current loss: 7.469463\n",
      "thresh: 0.950000, max F: 0.656387\n",
      "Current loss: 7.285588\n",
      "thresh: 0.950000, max F: 0.638734\n",
      "Current loss: 7.627293\n",
      "thresh: 0.950000, max F: 0.654882\n",
      "Current loss: 7.364165\n",
      "thresh: 0.950000, max F: 0.620917\n",
      "Current loss: 8.159745\n",
      "thresh: 0.950000, max F: 0.695320\n",
      "Current loss: 7.350203\n",
      "thresh: 0.950000, max F: 0.640154\n",
      "Current loss: 7.257302\n",
      "thresh: 0.950000, max F: 0.630534\n",
      "Current loss: 7.385680\n",
      "thresh: 0.750000, max F: 0.622302\n",
      "Current loss: 7.285169\n",
      "thresh: 0.800000, max F: 0.635318\n",
      "Current loss: 8.267792\n",
      "thresh: 0.950000, max F: 0.687003\n",
      "Current loss: 7.871619\n",
      "thresh: 0.900000, max F: 0.676061\n",
      "Current loss: 7.425521\n",
      "thresh: 0.950000, max F: 0.621472\n",
      "Current loss: 7.090566\n",
      "thresh: 0.950000, max F: 0.643593\n",
      "Current loss: 7.531972\n",
      "thresh: 0.950000, max F: 0.657998\n",
      "Current loss: 7.169847\n",
      "thresh: 0.950000, max F: 0.643260\n",
      "Current loss: 7.546960\n",
      "thresh: 0.950000, max F: 0.653558\n",
      "Current loss: 7.985765\n",
      "thresh: 0.950000, max F: 0.638346\n",
      "Current loss: 7.417779\n",
      "thresh: 0.950000, max F: 0.634213\n",
      "Current loss: 7.443356\n",
      "thresh: 0.950000, max F: 0.645487\n",
      "Current loss: 7.387506\n",
      "thresh: 0.750000, max F: 0.632173\n",
      "Current loss: 7.506032\n",
      "thresh: 0.500000, max F: 0.640103\n",
      "Current loss: 7.545006\n",
      "thresh: 0.950000, max F: 0.663641\n",
      "Current loss: 7.606985\n",
      "thresh: 0.900000, max F: 0.660847\n",
      "Current loss: 7.609199\n",
      "thresh: 0.950000, max F: 0.664341\n",
      "Current loss: 7.214464\n",
      "thresh: 0.950000, max F: 0.649341\n",
      "Current loss: 7.404214\n",
      "thresh: 0.900000, max F: 0.644827\n",
      "Current loss: 7.717176\n",
      "thresh: 0.950000, max F: 0.658715\n",
      "Current loss: 7.908439\n",
      "thresh: 0.900000, max F: 0.649982\n",
      "Current loss: 7.527845\n",
      "thresh: 0.950000, max F: 0.666234\n",
      "Current loss: 7.184008\n",
      "thresh: 0.950000, max F: 0.621599\n",
      "Current loss: 7.008262\n",
      "thresh: 0.950000, max F: 0.660180\n",
      "Current loss: 7.874298\n",
      "thresh: 0.900000, max F: 0.645310\n",
      "Current loss: 7.408978\n",
      "thresh: 0.950000, max F: 0.641606\n",
      "Current loss: 8.086706\n",
      "thresh: 0.750000, max F: 0.663022\n",
      "Current loss: 7.761596\n",
      "thresh: 0.950000, max F: 0.686783\n",
      "Current loss: 7.662379\n",
      "thresh: 0.950000, max F: 0.649187\n",
      "Current loss: 7.525492\n",
      "thresh: 0.950000, max F: 0.650931\n",
      "Current loss: 7.702207\n",
      "thresh: 0.950000, max F: 0.640290\n",
      "Current loss: 7.856102\n",
      "thresh: 0.900000, max F: 0.672082\n",
      "Current loss: 7.656588\n",
      "thresh: 0.950000, max F: 0.669771\n",
      "Current loss: 8.020395\n",
      "thresh: 0.800000, max F: 0.673331\n",
      "Current loss: 7.953790\n",
      "thresh: 0.900000, max F: 0.674100\n",
      "Current loss: 7.183924\n",
      "thresh: 0.900000, max F: 0.627926\n",
      "Current loss: 7.305368\n",
      "thresh: 0.950000, max F: 0.638700\n",
      "Current loss: 8.009145\n",
      "thresh: 0.900000, max F: 0.679053\n",
      "Current loss: 7.014517\n",
      "thresh: 0.950000, max F: 0.645200\n",
      "Current epoch loss: 7.014517\n",
      "Epoch thresh: 0.950000, max F: 0.645200\n",
      "Starting epoch 2 / 10\n",
      "Current loss: 8.003559\n",
      "thresh: 0.950000, max F: 0.664064\n",
      "Current loss: 7.548864\n",
      "thresh: 0.950000, max F: 0.663642\n",
      "Current loss: 7.531161\n",
      "thresh: 0.950000, max F: 0.646648\n",
      "Current loss: 7.776833\n",
      "thresh: 0.950000, max F: 0.651136\n",
      "Current loss: 7.814857\n",
      "thresh: 0.950000, max F: 0.678501\n",
      "Current loss: 7.695518\n",
      "thresh: 0.950000, max F: 0.667695\n",
      "Current loss: 7.642651\n",
      "thresh: 0.950000, max F: 0.647131\n",
      "Current loss: 7.601919\n",
      "thresh: 0.900000, max F: 0.623644\n",
      "Current loss: 7.375936\n",
      "thresh: 0.950000, max F: 0.643409\n",
      "Current loss: 7.522383\n",
      "thresh: 0.950000, max F: 0.647222\n",
      "Current loss: 7.433964\n",
      "thresh: 0.800000, max F: 0.633701\n",
      "Current loss: 7.832428\n",
      "thresh: 0.950000, max F: 0.649923\n",
      "Current loss: 7.974141\n",
      "thresh: 0.950000, max F: 0.678445\n",
      "Current loss: 7.314204\n",
      "thresh: 0.950000, max F: 0.651964\n",
      "Current loss: 7.442047\n",
      "thresh: 0.950000, max F: 0.635038\n",
      "Current loss: 7.399616\n",
      "thresh: 0.900000, max F: 0.644280\n",
      "Current loss: 7.127569\n",
      "thresh: 0.950000, max F: 0.641092\n",
      "Current loss: 7.231628\n",
      "thresh: 0.500000, max F: 0.629420\n",
      "Current loss: 7.898022\n",
      "thresh: 0.950000, max F: 0.663084\n",
      "Current loss: 7.371682\n",
      "thresh: 0.500000, max F: 0.639462\n",
      "Current loss: 7.433044\n",
      "thresh: 0.900000, max F: 0.649384\n",
      "Current loss: 7.610425\n",
      "thresh: 0.950000, max F: 0.648596\n",
      "Current loss: 7.601510\n",
      "thresh: 0.900000, max F: 0.650008\n",
      "Current loss: 6.812212\n",
      "thresh: 0.950000, max F: 0.629324\n",
      "Current loss: 7.494296\n",
      "thresh: 0.950000, max F: 0.661028\n",
      "Current loss: 7.984045\n",
      "thresh: 0.950000, max F: 0.651848\n",
      "Current loss: 7.816244\n",
      "thresh: 0.900000, max F: 0.667889\n",
      "Current loss: 7.269268\n",
      "thresh: 0.250000, max F: 0.615173\n",
      "Current loss: 7.847383\n",
      "thresh: 0.950000, max F: 0.663549\n",
      "Current loss: 7.680596\n",
      "thresh: 0.950000, max F: 0.660250\n",
      "Current loss: 7.508126\n",
      "thresh: 0.950000, max F: 0.644131\n",
      "Current loss: 7.700222\n",
      "thresh: 0.950000, max F: 0.678721\n",
      "Current loss: 7.093236\n",
      "thresh: 0.950000, max F: 0.642190\n",
      "Current loss: 7.660797\n",
      "thresh: 0.950000, max F: 0.649825\n",
      "Current loss: 7.686201\n",
      "thresh: 0.950000, max F: 0.650164\n",
      "Current loss: 8.129066\n",
      "thresh: 0.950000, max F: 0.677933\n",
      "Current loss: 7.818274\n",
      "thresh: 0.900000, max F: 0.654881\n",
      "Current loss: 7.607844\n",
      "thresh: 0.950000, max F: 0.659576\n",
      "Current loss: 7.484643\n",
      "thresh: 0.950000, max F: 0.653236\n",
      "Current loss: 7.094770\n",
      "thresh: 0.950000, max F: 0.644125\n",
      "Current loss: 7.367590\n",
      "thresh: 0.900000, max F: 0.645581\n",
      "Current loss: 7.768890\n",
      "thresh: 0.950000, max F: 0.657885\n",
      "Current loss: 7.810740\n",
      "thresh: 0.950000, max F: 0.680830\n",
      "Current loss: 7.048680\n",
      "thresh: 0.950000, max F: 0.630030\n",
      "Current loss: 7.646942\n",
      "thresh: 0.950000, max F: 0.666045\n",
      "Current loss: 7.280221\n",
      "thresh: 0.800000, max F: 0.620229\n",
      "Current loss: 8.444868\n",
      "thresh: 0.900000, max F: 0.685309\n",
      "Current loss: 7.066628\n",
      "thresh: 0.750000, max F: 0.640388\n",
      "Current loss: 7.390957\n",
      "thresh: 0.950000, max F: 0.660733\n",
      "Current loss: 7.271055\n",
      "thresh: 0.950000, max F: 0.625019\n",
      "Current loss: 7.159420\n",
      "thresh: 0.950000, max F: 0.659181\n",
      "Current loss: 7.993678\n",
      "thresh: 0.950000, max F: 0.682846\n",
      "Current loss: 7.424170\n",
      "thresh: 0.800000, max F: 0.636922\n",
      "Current loss: 7.942597\n",
      "thresh: 0.950000, max F: 0.666658\n",
      "Current loss: 7.438351\n",
      "thresh: 0.950000, max F: 0.658909\n",
      "Current loss: 7.368536\n",
      "thresh: 0.950000, max F: 0.639380\n",
      "Current loss: 7.584001\n",
      "thresh: 0.950000, max F: 0.660948\n",
      "Current loss: 7.473089\n",
      "thresh: 0.500000, max F: 0.625776\n",
      "Current loss: 7.140671\n",
      "thresh: 0.950000, max F: 0.631978\n",
      "Current loss: 7.601598\n",
      "thresh: 0.950000, max F: 0.638865\n",
      "Current loss: 7.197143\n",
      "thresh: 0.950000, max F: 0.639751\n",
      "Current loss: 7.486723\n",
      "thresh: 0.900000, max F: 0.651867\n",
      "Current loss: 8.064297\n",
      "thresh: 0.900000, max F: 0.649148\n",
      "Current loss: 7.093959\n",
      "thresh: 0.800000, max F: 0.639582\n",
      "Current loss: 7.504471\n",
      "thresh: 0.950000, max F: 0.654161\n",
      "Current loss: 8.119396\n",
      "thresh: 0.950000, max F: 0.665312\n",
      "Current loss: 7.830698\n",
      "thresh: 0.950000, max F: 0.671714\n",
      "Current loss: 7.159453\n",
      "thresh: 0.900000, max F: 0.663927\n",
      "Current loss: 7.511082\n",
      "thresh: 0.950000, max F: 0.670506\n",
      "Current loss: 8.199832\n",
      "thresh: 0.950000, max F: 0.672752\n",
      "Current loss: 7.614400\n",
      "thresh: 0.950000, max F: 0.651137\n",
      "Current loss: 7.879893\n",
      "thresh: 0.900000, max F: 0.663334\n",
      "Current loss: 7.432920\n",
      "thresh: 0.950000, max F: 0.636011\n",
      "Current loss: 7.173850\n",
      "thresh: 0.800000, max F: 0.634077\n",
      "Current loss: 7.333269\n",
      "thresh: 0.950000, max F: 0.638220\n",
      "Current loss: 7.056868\n",
      "thresh: 0.950000, max F: 0.628077\n",
      "Current loss: 7.571265\n",
      "thresh: 0.900000, max F: 0.645997\n",
      "Current loss: 7.939274\n",
      "thresh: 0.950000, max F: 0.680218\n",
      "Current loss: 7.817556\n",
      "thresh: 0.950000, max F: 0.680157\n",
      "Current loss: 7.381304\n",
      "thresh: 0.950000, max F: 0.645660\n",
      "Current loss: 7.434827\n",
      "thresh: 0.900000, max F: 0.627105\n",
      "Current loss: 7.938098\n",
      "thresh: 0.950000, max F: 0.673035\n",
      "Current loss: 7.152642\n",
      "thresh: 0.950000, max F: 0.643729\n",
      "Current loss: 7.418286\n",
      "thresh: 0.950000, max F: 0.619586\n",
      "Current loss: 7.532381\n",
      "thresh: 0.800000, max F: 0.641162\n",
      "Current loss: 7.870466\n",
      "thresh: 0.950000, max F: 0.674076\n",
      "Current loss: 7.410165\n",
      "thresh: 0.750000, max F: 0.647263\n",
      "Current loss: 7.485446\n",
      "thresh: 0.250000, max F: 0.630760\n",
      "Current loss: 7.325355\n",
      "thresh: 0.950000, max F: 0.618075\n",
      "Current loss: 7.369992\n",
      "thresh: 0.950000, max F: 0.654292\n",
      "Current loss: 7.059254\n",
      "thresh: 0.950000, max F: 0.641054\n",
      "Current loss: 7.329971\n",
      "thresh: 0.950000, max F: 0.652838\n",
      "Current loss: 7.606207\n",
      "thresh: 0.950000, max F: 0.651624\n",
      "Current loss: 7.734863\n",
      "thresh: 0.900000, max F: 0.648945\n",
      "Current loss: 7.476881\n",
      "thresh: 0.750000, max F: 0.654497\n",
      "Current loss: 8.244530\n",
      "thresh: 0.950000, max F: 0.704618\n",
      "Current loss: 7.480144\n",
      "thresh: 0.950000, max F: 0.673816\n",
      "Current loss: 7.991476\n",
      "thresh: 0.950000, max F: 0.678569\n",
      "Current loss: 7.230524\n",
      "thresh: 0.950000, max F: 0.644468\n",
      "Current loss: 7.330162\n",
      "thresh: 0.950000, max F: 0.648306\n",
      "Current loss: 7.603521\n",
      "thresh: 0.950000, max F: 0.656766\n",
      "Current loss: 7.883805\n",
      "thresh: 0.950000, max F: 0.658101\n",
      "Current loss: 7.683291\n",
      "thresh: 0.900000, max F: 0.643128\n",
      "Current loss: 7.177356\n",
      "thresh: 0.950000, max F: 0.611338\n",
      "Current loss: 7.732610\n",
      "thresh: 0.950000, max F: 0.628976\n",
      "Current loss: 7.673070\n",
      "thresh: 0.950000, max F: 0.658957\n",
      "Current loss: 8.135746\n",
      "thresh: 0.950000, max F: 0.661677\n",
      "Current loss: 7.592305\n",
      "thresh: 0.950000, max F: 0.679464\n",
      "Current loss: 7.497766\n",
      "thresh: 0.500000, max F: 0.647540\n",
      "Current loss: 7.342661\n",
      "thresh: 0.950000, max F: 0.647530\n",
      "Current loss: 7.275909\n",
      "thresh: 0.950000, max F: 0.635863\n",
      "Current loss: 7.867530\n",
      "thresh: 0.900000, max F: 0.615453\n",
      "Current loss: 7.783094\n",
      "thresh: 0.950000, max F: 0.654112\n",
      "Current loss: 7.309992\n",
      "thresh: 0.500000, max F: 0.627185\n",
      "Current loss: 7.190609\n",
      "thresh: 0.900000, max F: 0.596829\n",
      "Current loss: 7.169201\n",
      "thresh: 0.950000, max F: 0.632286\n",
      "Current loss: 7.384601\n",
      "thresh: 0.950000, max F: 0.631100\n",
      "Current loss: 7.775182\n",
      "thresh: 0.950000, max F: 0.662242\n",
      "Current loss: 7.378906\n",
      "thresh: 0.950000, max F: 0.623185\n",
      "Current loss: 7.513387\n",
      "thresh: 0.950000, max F: 0.639516\n",
      "Current loss: 7.349376\n",
      "thresh: 0.950000, max F: 0.648923\n",
      "Current loss: 7.024457\n",
      "thresh: 0.750000, max F: 0.631869\n",
      "Current loss: 7.435566\n",
      "thresh: 0.950000, max F: 0.637824\n",
      "Current loss: 7.757521\n",
      "thresh: 0.950000, max F: 0.668565\n",
      "Current loss: 7.172664\n",
      "thresh: 0.950000, max F: 0.618026\n",
      "Current loss: 7.727829\n",
      "thresh: 0.900000, max F: 0.663032\n",
      "Current loss: 7.024199\n",
      "thresh: 0.950000, max F: 0.635421\n",
      "Current loss: 7.322161\n",
      "thresh: 0.750000, max F: 0.635810\n",
      "Current loss: 7.458211\n",
      "thresh: 0.950000, max F: 0.640769\n",
      "Current loss: 7.182869\n",
      "thresh: 0.950000, max F: 0.643501\n",
      "Current loss: 7.402494\n",
      "thresh: 0.900000, max F: 0.645819\n",
      "Current loss: 7.102644\n",
      "thresh: 0.950000, max F: 0.647576\n",
      "Current loss: 7.722785\n",
      "thresh: 0.900000, max F: 0.632852\n",
      "Current loss: 7.126328\n",
      "thresh: 0.900000, max F: 0.646961\n",
      "Current loss: 7.557449\n",
      "thresh: 0.250000, max F: 0.620139\n",
      "Current loss: 7.392202\n",
      "thresh: 0.950000, max F: 0.640978\n",
      "Current loss: 7.779911\n",
      "thresh: 0.950000, max F: 0.669695\n",
      "Current loss: 8.090710\n",
      "thresh: 0.950000, max F: 0.678216\n",
      "Current loss: 7.809360\n",
      "thresh: 0.950000, max F: 0.673756\n",
      "Current loss: 7.666269\n",
      "thresh: 0.950000, max F: 0.638636\n",
      "Current loss: 7.633301\n",
      "thresh: 0.950000, max F: 0.639028\n",
      "Current loss: 7.209930\n",
      "thresh: 0.950000, max F: 0.631458\n",
      "Current loss: 7.533428\n",
      "thresh: 0.950000, max F: 0.650342\n",
      "Current loss: 7.817575\n",
      "thresh: 0.950000, max F: 0.664362\n",
      "Current loss: 7.581339\n",
      "thresh: 0.950000, max F: 0.628044\n",
      "Current loss: 8.071144\n",
      "thresh: 0.950000, max F: 0.676799\n",
      "Current loss: 8.030162\n",
      "thresh: 0.950000, max F: 0.668806\n",
      "Current loss: 7.337733\n",
      "thresh: 0.750000, max F: 0.621148\n",
      "Current loss: 7.586884\n",
      "thresh: 0.800000, max F: 0.661204\n",
      "Current loss: 7.459056\n",
      "thresh: 0.800000, max F: 0.642544\n",
      "Current loss: 7.280972\n",
      "thresh: 0.950000, max F: 0.611913\n",
      "Current loss: 7.985320\n",
      "thresh: 0.500000, max F: 0.656644\n",
      "Current loss: 7.499530\n",
      "thresh: 0.950000, max F: 0.661366\n",
      "Current loss: 7.971317\n",
      "thresh: 0.950000, max F: 0.666504\n",
      "Current loss: 8.017809\n",
      "thresh: 0.950000, max F: 0.660307\n",
      "Current loss: 7.430648\n",
      "thresh: 0.500000, max F: 0.633611\n",
      "Current loss: 7.273526\n",
      "thresh: 0.950000, max F: 0.628183\n",
      "Current loss: 7.615352\n",
      "thresh: 0.950000, max F: 0.641144\n",
      "Current loss: 7.314555\n",
      "thresh: 0.950000, max F: 0.634106\n",
      "Current loss: 7.514747\n",
      "thresh: 0.500000, max F: 0.624768\n",
      "Current loss: 7.767858\n",
      "thresh: 0.950000, max F: 0.633370\n",
      "Current loss: 7.503144\n",
      "thresh: 0.950000, max F: 0.640952\n",
      "Current loss: 7.785452\n",
      "thresh: 0.950000, max F: 0.639724\n",
      "Current loss: 7.948025\n",
      "thresh: 0.950000, max F: 0.639710\n",
      "Current loss: 7.505527\n",
      "thresh: 0.950000, max F: 0.650827\n",
      "Current loss: 7.557527\n",
      "thresh: 0.950000, max F: 0.660099\n",
      "Current loss: 7.248688\n",
      "thresh: 0.900000, max F: 0.642469\n",
      "Current loss: 7.932761\n",
      "thresh: 0.950000, max F: 0.664554\n",
      "Current loss: 7.629847\n",
      "thresh: 0.950000, max F: 0.666949\n",
      "Current loss: 8.021864\n",
      "thresh: 0.950000, max F: 0.668911\n",
      "Current loss: 7.383901\n",
      "thresh: 0.900000, max F: 0.653764\n",
      "Current loss: 7.639697\n",
      "thresh: 0.800000, max F: 0.637604\n",
      "Current loss: 8.148256\n",
      "thresh: 0.950000, max F: 0.671996\n",
      "Current loss: 7.658679\n",
      "thresh: 0.950000, max F: 0.651161\n",
      "Current loss: 8.051976\n",
      "thresh: 0.900000, max F: 0.672908\n",
      "Current loss: 7.882765\n",
      "thresh: 0.950000, max F: 0.667898\n",
      "Current loss: 7.630208\n",
      "thresh: 0.950000, max F: 0.661183\n",
      "Current loss: 7.422659\n",
      "thresh: 0.950000, max F: 0.638763\n",
      "Current loss: 7.702879\n",
      "thresh: 0.950000, max F: 0.663505\n",
      "Current loss: 7.451637\n",
      "thresh: 0.950000, max F: 0.629974\n",
      "Current loss: 7.836634\n",
      "thresh: 0.950000, max F: 0.639616\n",
      "Current loss: 7.374943\n",
      "thresh: 0.900000, max F: 0.635078\n",
      "Current loss: 7.917391\n",
      "thresh: 0.800000, max F: 0.683052\n",
      "Current loss: 7.824999\n",
      "thresh: 0.950000, max F: 0.673129\n",
      "Current loss: 7.882991\n",
      "thresh: 0.950000, max F: 0.673485\n",
      "Current loss: 7.608402\n",
      "thresh: 0.950000, max F: 0.666059\n",
      "Current loss: 7.639426\n",
      "thresh: 0.900000, max F: 0.649404\n",
      "Current loss: 7.389203\n",
      "thresh: 0.950000, max F: 0.637189\n",
      "Current loss: 7.664418\n",
      "thresh: 0.950000, max F: 0.656005\n",
      "Current loss: 7.627426\n",
      "thresh: 0.900000, max F: 0.647294\n",
      "Current loss: 7.837531\n",
      "thresh: 0.900000, max F: 0.642451\n",
      "Current loss: 7.445868\n",
      "thresh: 0.950000, max F: 0.654372\n",
      "Current loss: 7.318542\n",
      "thresh: 0.900000, max F: 0.632628\n",
      "Current loss: 7.350943\n",
      "thresh: 0.950000, max F: 0.636041\n",
      "Current loss: 7.623496\n",
      "thresh: 0.950000, max F: 0.651510\n",
      "Current loss: 7.345347\n",
      "thresh: 0.950000, max F: 0.620884\n",
      "Current loss: 6.870705\n",
      "thresh: 0.950000, max F: 0.609657\n",
      "Current loss: 7.681360\n",
      "thresh: 0.900000, max F: 0.636454\n",
      "Current loss: 7.459038\n",
      "thresh: 0.950000, max F: 0.655068\n",
      "Current loss: 7.745930\n",
      "thresh: 0.950000, max F: 0.656242\n",
      "Current loss: 7.577032\n",
      "thresh: 0.950000, max F: 0.640414\n",
      "Current loss: 7.300747\n",
      "thresh: 0.500000, max F: 0.621264\n",
      "Current loss: 8.199689\n",
      "thresh: 0.900000, max F: 0.678274\n",
      "Current loss: 7.715006\n",
      "thresh: 0.950000, max F: 0.652990\n",
      "Current loss: 8.052354\n",
      "thresh: 0.950000, max F: 0.688733\n",
      "Current loss: 7.718371\n",
      "thresh: 0.800000, max F: 0.636831\n",
      "Current loss: 7.312346\n",
      "thresh: 0.950000, max F: 0.645237\n",
      "Current loss: 7.434486\n",
      "thresh: 0.950000, max F: 0.644255\n",
      "Current loss: 7.506344\n",
      "thresh: 0.950000, max F: 0.629894\n",
      "Current loss: 6.997692\n",
      "thresh: 0.100000, max F: 0.600423\n",
      "Current loss: 7.621811\n",
      "thresh: 0.950000, max F: 0.655701\n",
      "Current loss: 7.778854\n",
      "thresh: 0.950000, max F: 0.666095\n",
      "Current loss: 7.380040\n",
      "thresh: 0.950000, max F: 0.632161\n",
      "Current loss: 7.322351\n",
      "thresh: 0.950000, max F: 0.648323\n",
      "Current loss: 7.730278\n",
      "thresh: 0.950000, max F: 0.676689\n",
      "Current loss: 7.338880\n",
      "thresh: 0.950000, max F: 0.650098\n",
      "Current loss: 7.323052\n",
      "thresh: 0.950000, max F: 0.645712\n",
      "Current loss: 8.218860\n",
      "thresh: 0.950000, max F: 0.662514\n",
      "Current loss: 7.588168\n",
      "thresh: 0.950000, max F: 0.648411\n",
      "Current loss: 7.243710\n",
      "thresh: 0.950000, max F: 0.657598\n",
      "Current loss: 7.354218\n",
      "thresh: 0.500000, max F: 0.617833\n",
      "Current loss: 7.083289\n",
      "thresh: 0.950000, max F: 0.618888\n",
      "Current loss: 7.907826\n",
      "thresh: 0.950000, max F: 0.660887\n",
      "Current loss: 7.958899\n",
      "thresh: 0.950000, max F: 0.657491\n",
      "Current loss: 7.354222\n",
      "thresh: 0.950000, max F: 0.633539\n",
      "Current loss: 7.579967\n",
      "thresh: 0.900000, max F: 0.642286\n",
      "Current loss: 7.443738\n",
      "thresh: 0.950000, max F: 0.641575\n",
      "Current loss: 8.029984\n",
      "thresh: 0.950000, max F: 0.659665\n",
      "Current loss: 7.894802\n",
      "thresh: 0.950000, max F: 0.651163\n",
      "Current loss: 8.155132\n",
      "thresh: 0.950000, max F: 0.679777\n",
      "Current loss: 7.539375\n",
      "thresh: 0.950000, max F: 0.638861\n",
      "Current loss: 7.391444\n",
      "thresh: 0.950000, max F: 0.634413\n",
      "Current loss: 7.896591\n",
      "thresh: 0.950000, max F: 0.670103\n",
      "Current loss: 7.891229\n",
      "thresh: 0.950000, max F: 0.671835\n",
      "Current loss: 7.860981\n",
      "thresh: 0.950000, max F: 0.679845\n",
      "Current loss: 7.710281\n",
      "thresh: 0.950000, max F: 0.660275\n",
      "Current loss: 7.320688\n",
      "thresh: 0.900000, max F: 0.607073\n",
      "Current loss: 7.493975\n",
      "thresh: 0.950000, max F: 0.619570\n",
      "Current loss: 7.635560\n",
      "thresh: 0.900000, max F: 0.629566\n",
      "Current loss: 7.462918\n",
      "thresh: 0.950000, max F: 0.646614\n",
      "Current loss: 7.459452\n",
      "thresh: 0.900000, max F: 0.656614\n",
      "Current loss: 8.496069\n",
      "thresh: 0.950000, max F: 0.704316\n",
      "Current loss: 7.303679\n",
      "thresh: 0.950000, max F: 0.664717\n",
      "Current loss: 8.020540\n",
      "thresh: 0.500000, max F: 0.644634\n",
      "Current loss: 7.457844\n",
      "thresh: 0.900000, max F: 0.633193\n",
      "Current loss: 7.851853\n",
      "thresh: 0.900000, max F: 0.673984\n",
      "Current loss: 7.738642\n",
      "thresh: 0.950000, max F: 0.652634\n",
      "Current loss: 8.038575\n",
      "thresh: 0.950000, max F: 0.658892\n",
      "Current loss: 7.214420\n",
      "thresh: 0.950000, max F: 0.629736\n",
      "Current loss: 7.638042\n",
      "thresh: 0.950000, max F: 0.663139\n",
      "Current loss: 7.329256\n",
      "thresh: 0.950000, max F: 0.647716\n",
      "Current loss: 7.988248\n",
      "thresh: 0.950000, max F: 0.665588\n",
      "Current loss: 7.636370\n",
      "thresh: 0.900000, max F: 0.643931\n",
      "Current loss: 7.776132\n",
      "thresh: 0.950000, max F: 0.672721\n",
      "Current loss: 7.143702\n",
      "thresh: 0.950000, max F: 0.645531\n",
      "Current loss: 7.680752\n",
      "thresh: 0.950000, max F: 0.672752\n",
      "Current loss: 7.379710\n",
      "thresh: 0.950000, max F: 0.645326\n",
      "Current loss: 8.369730\n",
      "thresh: 0.950000, max F: 0.698138\n",
      "Current loss: 7.919665\n",
      "thresh: 0.950000, max F: 0.670182\n",
      "Current loss: 7.804710\n",
      "thresh: 0.950000, max F: 0.667630\n",
      "Current loss: 7.727871\n",
      "thresh: 0.800000, max F: 0.657547\n",
      "Current loss: 7.417387\n",
      "thresh: 0.950000, max F: 0.667582\n",
      "Current loss: 7.955437\n",
      "thresh: 0.800000, max F: 0.655304\n",
      "Current loss: 7.665942\n",
      "thresh: 0.950000, max F: 0.658611\n",
      "Current loss: 7.987717\n",
      "thresh: 0.950000, max F: 0.671564\n",
      "Current loss: 7.417429\n",
      "thresh: 0.950000, max F: 0.653505\n",
      "Current loss: 7.633202\n",
      "thresh: 0.950000, max F: 0.651774\n",
      "Current loss: 7.362812\n",
      "thresh: 0.950000, max F: 0.655598\n",
      "Current loss: 7.148524\n",
      "thresh: 0.950000, max F: 0.617094\n",
      "Current loss: 7.922391\n",
      "thresh: 0.950000, max F: 0.671426\n",
      "Current epoch loss: 7.922391\n",
      "Epoch thresh: 0.950000, max F: 0.671426\n",
      "Starting epoch 3 / 10\n",
      "Current loss: 7.863423\n",
      "thresh: 0.950000, max F: 0.641408\n",
      "Current loss: 7.601725\n",
      "thresh: 0.250000, max F: 0.627939\n",
      "Current loss: 7.705583\n",
      "thresh: 0.950000, max F: 0.679080\n",
      "Current loss: 7.706517\n",
      "thresh: 0.950000, max F: 0.655330\n",
      "Current loss: 7.232011\n",
      "thresh: 0.950000, max F: 0.622194\n",
      "Current loss: 7.534262\n",
      "thresh: 0.950000, max F: 0.646025\n",
      "Current loss: 7.978387\n",
      "thresh: 0.950000, max F: 0.662583\n",
      "Current loss: 7.324764\n",
      "thresh: 0.800000, max F: 0.641928\n",
      "Current loss: 7.191489\n",
      "thresh: 0.950000, max F: 0.645084\n",
      "Current loss: 7.304375\n",
      "thresh: 0.900000, max F: 0.629175\n",
      "Current loss: 7.895018\n",
      "thresh: 0.950000, max F: 0.680084\n",
      "Current loss: 7.840625\n",
      "thresh: 0.950000, max F: 0.675135\n",
      "Current loss: 7.886621\n",
      "thresh: 0.950000, max F: 0.672375\n",
      "Current loss: 7.378788\n",
      "thresh: 0.950000, max F: 0.637404\n",
      "Current loss: 7.757771\n",
      "thresh: 0.950000, max F: 0.666597\n",
      "Current loss: 8.189507\n",
      "thresh: 0.800000, max F: 0.663083\n",
      "Current loss: 7.371244\n",
      "thresh: 0.950000, max F: 0.644974\n",
      "Current loss: 7.826322\n",
      "thresh: 0.950000, max F: 0.652468\n",
      "Current loss: 8.185203\n",
      "thresh: 0.950000, max F: 0.677410\n",
      "Current loss: 7.396974\n",
      "thresh: 0.950000, max F: 0.616817\n",
      "Current loss: 7.577898\n",
      "thresh: 0.950000, max F: 0.624620\n",
      "Current loss: 7.037905\n",
      "thresh: 0.950000, max F: 0.659483\n",
      "Current loss: 6.937925\n",
      "thresh: 0.100000, max F: 0.603235\n",
      "Current loss: 8.589369\n",
      "thresh: 0.800000, max F: 0.689710\n",
      "Current loss: 7.727046\n",
      "thresh: 0.950000, max F: 0.659887\n",
      "Current loss: 7.212493\n",
      "thresh: 0.950000, max F: 0.645064\n",
      "Current loss: 7.665673\n",
      "thresh: 0.950000, max F: 0.645074\n",
      "Current loss: 7.894195\n",
      "thresh: 0.950000, max F: 0.668674\n",
      "Current loss: 7.443857\n",
      "thresh: 0.900000, max F: 0.629824\n",
      "Current loss: 7.480263\n",
      "thresh: 0.950000, max F: 0.681274\n",
      "Current loss: 7.381456\n",
      "thresh: 0.950000, max F: 0.633733\n",
      "Current loss: 7.232860\n",
      "thresh: 0.900000, max F: 0.638666\n",
      "Current loss: 7.638132\n",
      "thresh: 0.950000, max F: 0.657590\n",
      "Current loss: 7.276525\n",
      "thresh: 0.950000, max F: 0.656068\n",
      "Current loss: 7.365323\n",
      "thresh: 0.950000, max F: 0.633813\n",
      "Current loss: 7.407819\n",
      "thresh: 0.950000, max F: 0.629031\n",
      "Current loss: 7.422007\n",
      "thresh: 0.950000, max F: 0.656132\n",
      "Current loss: 7.491374\n",
      "thresh: 0.950000, max F: 0.653757\n",
      "Current loss: 7.690241\n",
      "thresh: 0.950000, max F: 0.657774\n",
      "Current loss: 7.606567\n",
      "thresh: 0.950000, max F: 0.654376\n",
      "Current loss: 7.459748\n",
      "thresh: 0.950000, max F: 0.650702\n",
      "Current loss: 7.798728\n",
      "thresh: 0.950000, max F: 0.645685\n",
      "Current loss: 6.976917\n",
      "thresh: 0.900000, max F: 0.609970\n",
      "Current loss: 7.379795\n",
      "thresh: 0.950000, max F: 0.644398\n",
      "Current loss: 7.817767\n",
      "thresh: 0.950000, max F: 0.657543\n",
      "Current loss: 7.460235\n",
      "thresh: 0.950000, max F: 0.625386\n",
      "Current loss: 8.066301\n",
      "thresh: 0.950000, max F: 0.664072\n",
      "Current loss: 7.277735\n",
      "thresh: 0.950000, max F: 0.655819\n",
      "Current loss: 7.582146\n",
      "thresh: 0.950000, max F: 0.646569\n",
      "Current loss: 8.170825\n",
      "thresh: 0.950000, max F: 0.688161\n",
      "Current loss: 7.071154\n",
      "thresh: 0.950000, max F: 0.623538\n",
      "Current loss: 7.355165\n",
      "thresh: 0.950000, max F: 0.612985\n",
      "Current loss: 7.526167\n",
      "thresh: 0.900000, max F: 0.647599\n",
      "Current loss: 7.697593\n",
      "thresh: 0.800000, max F: 0.663406\n",
      "Current loss: 7.605809\n",
      "thresh: 0.900000, max F: 0.661640\n",
      "Current loss: 7.508513\n",
      "thresh: 0.950000, max F: 0.656789\n",
      "Current loss: 7.848065\n",
      "thresh: 0.900000, max F: 0.651412\n",
      "Current loss: 7.357391\n",
      "thresh: 0.950000, max F: 0.616214\n",
      "Current loss: 7.773802\n",
      "thresh: 0.950000, max F: 0.651776\n",
      "Current loss: 7.505262\n",
      "thresh: 0.950000, max F: 0.653382\n",
      "Current loss: 6.965060\n",
      "thresh: 0.950000, max F: 0.614768\n",
      "Current loss: 7.007893\n",
      "thresh: 0.950000, max F: 0.627433\n",
      "Current loss: 7.272790\n",
      "thresh: 0.950000, max F: 0.637748\n",
      "Current loss: 7.422544\n",
      "thresh: 0.950000, max F: 0.657695\n",
      "Current loss: 8.200177\n",
      "thresh: 0.950000, max F: 0.682612\n",
      "Current loss: 7.556501\n",
      "thresh: 0.950000, max F: 0.646529\n",
      "Current loss: 7.512910\n",
      "thresh: 0.950000, max F: 0.643635\n",
      "Current loss: 7.375175\n",
      "thresh: 0.950000, max F: 0.641289\n",
      "Current loss: 7.665998\n",
      "thresh: 0.950000, max F: 0.666792\n",
      "Current loss: 7.598947\n",
      "thresh: 0.900000, max F: 0.653788\n",
      "Current loss: 7.872774\n",
      "thresh: 0.900000, max F: 0.669560\n",
      "Current loss: 6.623291\n",
      "thresh: 0.950000, max F: 0.609224\n",
      "Current loss: 7.270334\n",
      "thresh: 0.750000, max F: 0.616359\n",
      "Current loss: 7.959551\n",
      "thresh: 0.900000, max F: 0.659568\n",
      "Current loss: 7.521193\n",
      "thresh: 0.950000, max F: 0.662866\n",
      "Current loss: 7.204384\n",
      "thresh: 0.950000, max F: 0.648077\n",
      "Current loss: 7.720027\n",
      "thresh: 0.950000, max F: 0.656283\n",
      "Current loss: 7.710989\n",
      "thresh: 0.950000, max F: 0.668967\n",
      "Current loss: 7.273144\n",
      "thresh: 0.950000, max F: 0.645657\n",
      "Current loss: 8.355639\n",
      "thresh: 0.950000, max F: 0.686856\n",
      "Current loss: 6.991313\n",
      "thresh: 0.950000, max F: 0.642692\n",
      "Current loss: 7.629442\n",
      "thresh: 0.950000, max F: 0.673102\n",
      "Current loss: 7.449071\n",
      "thresh: 0.500000, max F: 0.638554\n",
      "Current loss: 7.102904\n",
      "thresh: 0.950000, max F: 0.627898\n",
      "Current loss: 7.389742\n",
      "thresh: 0.950000, max F: 0.637271\n",
      "Current loss: 8.013891\n",
      "thresh: 0.950000, max F: 0.664226\n",
      "Current loss: 7.272858\n",
      "thresh: 0.950000, max F: 0.617728\n",
      "Current loss: 7.726762\n",
      "thresh: 0.900000, max F: 0.652271\n",
      "Current loss: 7.278522\n",
      "thresh: 0.950000, max F: 0.641835\n",
      "Current loss: 7.792130\n",
      "thresh: 0.950000, max F: 0.686484\n",
      "Current loss: 7.737131\n",
      "thresh: 0.800000, max F: 0.656920\n",
      "Current loss: 7.422933\n",
      "thresh: 0.950000, max F: 0.643597\n",
      "Current loss: 7.902077\n",
      "thresh: 0.950000, max F: 0.660388\n",
      "Current loss: 7.048404\n",
      "thresh: 0.900000, max F: 0.626853\n",
      "Current loss: 7.147481\n",
      "thresh: 0.900000, max F: 0.642237\n",
      "Current loss: 7.860729\n",
      "thresh: 0.950000, max F: 0.653763\n",
      "Current loss: 8.007943\n",
      "thresh: 0.950000, max F: 0.676928\n",
      "Current loss: 7.560292\n",
      "thresh: 0.900000, max F: 0.663285\n",
      "Current loss: 7.929780\n",
      "thresh: 0.950000, max F: 0.668463\n",
      "Current loss: 8.112655\n",
      "thresh: 0.950000, max F: 0.666615\n",
      "Current loss: 7.671283\n",
      "thresh: 0.900000, max F: 0.641587\n",
      "Current loss: 7.767694\n",
      "thresh: 0.950000, max F: 0.643937\n",
      "Current loss: 7.495684\n",
      "thresh: 0.950000, max F: 0.662159\n",
      "Current loss: 7.816202\n",
      "thresh: 0.950000, max F: 0.651559\n",
      "Current loss: 7.522333\n",
      "thresh: 0.800000, max F: 0.644941\n",
      "Current loss: 7.410651\n",
      "thresh: 0.950000, max F: 0.637543\n",
      "Current loss: 8.509312\n",
      "thresh: 0.950000, max F: 0.704762\n",
      "Current loss: 7.846138\n",
      "thresh: 0.950000, max F: 0.655412\n",
      "Current loss: 7.550553\n",
      "thresh: 0.950000, max F: 0.654282\n",
      "Current loss: 7.042520\n",
      "thresh: 0.500000, max F: 0.619910\n",
      "Current loss: 7.356044\n",
      "thresh: 0.950000, max F: 0.652119\n",
      "Current loss: 8.167945\n",
      "thresh: 0.800000, max F: 0.670886\n",
      "Current loss: 7.579535\n",
      "thresh: 0.950000, max F: 0.650135\n",
      "Current loss: 8.002607\n",
      "thresh: 0.950000, max F: 0.671355\n",
      "Current loss: 7.543794\n",
      "thresh: 0.950000, max F: 0.671437\n",
      "Current loss: 8.249424\n",
      "thresh: 0.900000, max F: 0.654190\n",
      "Current loss: 7.292574\n",
      "thresh: 0.950000, max F: 0.635053\n",
      "Current loss: 7.949535\n",
      "thresh: 0.950000, max F: 0.642839\n",
      "Current loss: 7.689094\n",
      "thresh: 0.950000, max F: 0.640119\n",
      "Current loss: 7.447160\n",
      "thresh: 0.800000, max F: 0.627318\n",
      "Current loss: 7.601995\n",
      "thresh: 0.800000, max F: 0.648689\n",
      "Current loss: 7.924296\n",
      "thresh: 0.900000, max F: 0.663236\n",
      "Current loss: 7.642560\n",
      "thresh: 0.950000, max F: 0.663987\n",
      "Current loss: 7.904422\n",
      "thresh: 0.900000, max F: 0.664974\n",
      "Current loss: 7.245056\n",
      "thresh: 0.950000, max F: 0.625328\n",
      "Current loss: 7.368082\n",
      "thresh: 0.950000, max F: 0.675992\n",
      "Current loss: 7.657767\n",
      "thresh: 0.950000, max F: 0.662778\n",
      "Current loss: 7.464121\n",
      "thresh: 0.950000, max F: 0.651764\n",
      "Current loss: 7.349447\n",
      "thresh: 0.950000, max F: 0.657129\n",
      "Current loss: 7.324176\n",
      "thresh: 0.950000, max F: 0.635666\n",
      "Current loss: 8.010653\n",
      "thresh: 0.950000, max F: 0.658257\n",
      "Current loss: 7.974675\n",
      "thresh: 0.950000, max F: 0.671267\n",
      "Current loss: 7.420080\n",
      "thresh: 0.900000, max F: 0.669681\n",
      "Current loss: 6.996116\n",
      "thresh: 0.950000, max F: 0.631918\n",
      "Current loss: 7.391945\n",
      "thresh: 0.900000, max F: 0.629126\n",
      "Current loss: 7.287231\n",
      "thresh: 0.950000, max F: 0.620498\n",
      "Current loss: 7.199677\n",
      "thresh: 0.950000, max F: 0.616409\n",
      "Current loss: 7.513813\n",
      "thresh: 0.950000, max F: 0.656618\n",
      "Current loss: 8.162775\n",
      "thresh: 0.800000, max F: 0.664609\n",
      "Current loss: 7.446294\n",
      "thresh: 0.950000, max F: 0.628907\n",
      "Current loss: 7.117365\n",
      "thresh: 0.950000, max F: 0.632250\n",
      "Current loss: 7.562470\n",
      "thresh: 0.900000, max F: 0.649402\n",
      "Current loss: 7.894301\n",
      "thresh: 0.800000, max F: 0.661237\n",
      "Current loss: 7.533369\n",
      "thresh: 0.800000, max F: 0.639772\n",
      "Current loss: 7.336744\n",
      "thresh: 0.950000, max F: 0.644872\n",
      "Current loss: 7.945628\n",
      "thresh: 0.950000, max F: 0.673701\n",
      "Current loss: 7.171795\n",
      "thresh: 0.950000, max F: 0.641816\n",
      "Current loss: 7.041245\n",
      "thresh: 0.950000, max F: 0.620119\n",
      "Current loss: 7.619834\n",
      "thresh: 0.900000, max F: 0.650055\n",
      "Current loss: 7.549138\n",
      "thresh: 0.900000, max F: 0.630659\n",
      "Current loss: 7.943068\n",
      "thresh: 0.950000, max F: 0.665990\n",
      "Current loss: 7.731272\n",
      "thresh: 0.500000, max F: 0.648982\n",
      "Current loss: 7.592498\n",
      "thresh: 0.250000, max F: 0.615607\n",
      "Current loss: 7.149554\n",
      "thresh: 0.250000, max F: 0.611078\n",
      "Current loss: 7.691840\n",
      "thresh: 0.750000, max F: 0.639196\n",
      "Current loss: 7.560328\n",
      "thresh: 0.900000, max F: 0.624521\n",
      "Current loss: 7.312747\n",
      "thresh: 0.950000, max F: 0.646432\n",
      "Current loss: 8.223022\n",
      "thresh: 0.950000, max F: 0.666482\n",
      "Current loss: 7.705654\n",
      "thresh: 0.950000, max F: 0.660198\n",
      "Current loss: 7.567019\n",
      "thresh: 0.950000, max F: 0.673796\n",
      "Current loss: 7.823761\n",
      "thresh: 0.500000, max F: 0.645919\n",
      "Current loss: 7.225837\n",
      "thresh: 0.950000, max F: 0.648853\n",
      "Current loss: 7.226838\n",
      "thresh: 0.950000, max F: 0.632223\n",
      "Current loss: 7.139179\n",
      "thresh: 0.950000, max F: 0.619791\n",
      "Current loss: 7.934027\n",
      "thresh: 0.950000, max F: 0.662444\n",
      "Current loss: 7.463696\n",
      "thresh: 0.500000, max F: 0.628734\n",
      "Current loss: 7.403230\n",
      "thresh: 0.950000, max F: 0.675244\n",
      "Current loss: 7.908476\n",
      "thresh: 0.950000, max F: 0.670684\n",
      "Current loss: 7.270242\n",
      "thresh: 0.950000, max F: 0.631532\n",
      "Current loss: 8.487846\n",
      "thresh: 0.950000, max F: 0.680387\n",
      "Current loss: 7.564816\n",
      "thresh: 0.900000, max F: 0.640709\n",
      "Current loss: 7.281229\n",
      "thresh: 0.950000, max F: 0.644292\n",
      "Current loss: 7.656534\n",
      "thresh: 0.900000, max F: 0.670506\n",
      "Current loss: 7.962968\n",
      "thresh: 0.900000, max F: 0.673681\n",
      "Current loss: 6.967230\n",
      "thresh: 0.950000, max F: 0.632349\n",
      "Current loss: 7.748299\n",
      "thresh: 0.950000, max F: 0.641701\n",
      "Current loss: 7.452051\n",
      "thresh: 0.950000, max F: 0.634695\n",
      "Current loss: 7.336490\n",
      "thresh: 0.750000, max F: 0.634108\n",
      "Current loss: 8.104256\n",
      "thresh: 0.950000, max F: 0.660031\n",
      "Current loss: 7.468976\n",
      "thresh: 0.800000, max F: 0.640733\n",
      "Current loss: 7.430298\n",
      "thresh: 0.950000, max F: 0.632504\n",
      "Current loss: 7.127680\n",
      "thresh: 0.950000, max F: 0.634378\n",
      "Current loss: 7.309382\n",
      "thresh: 0.950000, max F: 0.640520\n",
      "Current loss: 6.884339\n",
      "thresh: 0.250000, max F: 0.609111\n",
      "Current loss: 7.602239\n",
      "thresh: 0.950000, max F: 0.671451\n",
      "Current loss: 7.744430\n",
      "thresh: 0.950000, max F: 0.666217\n",
      "Current loss: 7.947172\n",
      "thresh: 0.950000, max F: 0.641352\n",
      "Current loss: 7.874517\n",
      "thresh: 0.950000, max F: 0.660420\n",
      "Current loss: 7.971717\n",
      "thresh: 0.950000, max F: 0.662055\n",
      "Current loss: 8.021277\n",
      "thresh: 0.950000, max F: 0.661959\n",
      "Current loss: 7.300740\n",
      "thresh: 0.250000, max F: 0.623637\n",
      "Current loss: 7.760874\n",
      "thresh: 0.750000, max F: 0.658435\n",
      "Current loss: 7.507623\n",
      "thresh: 0.950000, max F: 0.638632\n",
      "Current loss: 7.434164\n",
      "thresh: 0.950000, max F: 0.644642\n",
      "Current loss: 7.610390\n",
      "thresh: 0.800000, max F: 0.656505\n",
      "Current loss: 7.488198\n",
      "thresh: 0.950000, max F: 0.642057\n",
      "Current loss: 7.472445\n",
      "thresh: 0.950000, max F: 0.655567\n",
      "Current loss: 7.532103\n",
      "thresh: 0.950000, max F: 0.649189\n",
      "Current loss: 7.913775\n",
      "thresh: 0.800000, max F: 0.656231\n",
      "Current loss: 7.853319\n",
      "thresh: 0.950000, max F: 0.630164\n",
      "Current loss: 7.572401\n",
      "thresh: 0.500000, max F: 0.625696\n",
      "Current loss: 7.610678\n",
      "thresh: 0.500000, max F: 0.632168\n",
      "Current loss: 7.401351\n",
      "thresh: 0.900000, max F: 0.662701\n",
      "Current loss: 8.004605\n",
      "thresh: 0.950000, max F: 0.662536\n",
      "Current loss: 7.573742\n",
      "thresh: 0.950000, max F: 0.645058\n",
      "Current loss: 7.323126\n",
      "thresh: 0.500000, max F: 0.623067\n",
      "Current loss: 7.574870\n",
      "thresh: 0.950000, max F: 0.624046\n",
      "Current loss: 7.614640\n",
      "thresh: 0.750000, max F: 0.644138\n",
      "Current loss: 7.568959\n",
      "thresh: 0.950000, max F: 0.669138\n",
      "Current loss: 7.608350\n",
      "thresh: 0.950000, max F: 0.661633\n",
      "Current loss: 7.821036\n",
      "thresh: 0.950000, max F: 0.651771\n",
      "Current loss: 7.385251\n",
      "thresh: 0.950000, max F: 0.653843\n",
      "Current loss: 8.027463\n",
      "thresh: 0.950000, max F: 0.660275\n",
      "Current loss: 7.490204\n",
      "thresh: 0.950000, max F: 0.635663\n",
      "Current loss: 7.503518\n",
      "thresh: 0.050000, max F: 0.621014\n",
      "Current loss: 7.895043\n",
      "thresh: 0.950000, max F: 0.653603\n",
      "Current loss: 7.925142\n",
      "thresh: 0.900000, max F: 0.655761\n",
      "Current loss: 7.426397\n",
      "thresh: 0.950000, max F: 0.659558\n",
      "Current loss: 7.619615\n",
      "thresh: 0.500000, max F: 0.644201\n",
      "Current loss: 7.610591\n",
      "thresh: 0.900000, max F: 0.648905\n",
      "Current loss: 8.082541\n",
      "thresh: 0.100000, max F: 0.644157\n",
      "Current loss: 7.571919\n",
      "thresh: 0.950000, max F: 0.643454\n",
      "Current loss: 7.459600\n",
      "thresh: 0.900000, max F: 0.648903\n",
      "Current loss: 8.042167\n",
      "thresh: 0.950000, max F: 0.671068\n",
      "Current loss: 7.930904\n",
      "thresh: 0.950000, max F: 0.655508\n",
      "Current loss: 7.534027\n",
      "thresh: 0.950000, max F: 0.639055\n",
      "Current loss: 7.619375\n",
      "thresh: 0.950000, max F: 0.649068\n",
      "Current loss: 7.548847\n",
      "thresh: 0.950000, max F: 0.662120\n",
      "Current loss: 8.040988\n",
      "thresh: 0.950000, max F: 0.675758\n",
      "Current loss: 6.818531\n",
      "thresh: 0.950000, max F: 0.619201\n",
      "Current loss: 7.501337\n",
      "thresh: 0.950000, max F: 0.652042\n",
      "Current loss: 7.541877\n",
      "thresh: 0.950000, max F: 0.653925\n",
      "Current loss: 7.650917\n",
      "thresh: 0.950000, max F: 0.626933\n",
      "Current loss: 7.579246\n",
      "thresh: 0.950000, max F: 0.672971\n",
      "Current loss: 7.051035\n",
      "thresh: 0.750000, max F: 0.605357\n",
      "Current loss: 7.544023\n",
      "thresh: 0.900000, max F: 0.651822\n",
      "Current loss: 7.773600\n",
      "thresh: 0.900000, max F: 0.637350\n",
      "Current loss: 7.779530\n",
      "thresh: 0.950000, max F: 0.645411\n",
      "Current loss: 7.092973\n",
      "thresh: 0.900000, max F: 0.614855\n",
      "Current loss: 7.401068\n",
      "thresh: 0.500000, max F: 0.629222\n",
      "Current loss: 7.973745\n",
      "thresh: 0.950000, max F: 0.668300\n",
      "Current loss: 7.752305\n",
      "thresh: 0.950000, max F: 0.672142\n",
      "Current loss: 7.661053\n",
      "thresh: 0.950000, max F: 0.653353\n",
      "Current loss: 7.925041\n",
      "thresh: 0.750000, max F: 0.671450\n",
      "Current loss: 7.310963\n",
      "thresh: 0.800000, max F: 0.634617\n",
      "Current loss: 7.245160\n",
      "thresh: 0.800000, max F: 0.621325\n",
      "Current loss: 7.569534\n",
      "thresh: 0.950000, max F: 0.644104\n",
      "Current loss: 7.776144\n",
      "thresh: 0.950000, max F: 0.661801\n",
      "Current loss: 7.815281\n",
      "thresh: 0.950000, max F: 0.658422\n",
      "Current loss: 7.230641\n",
      "thresh: 0.950000, max F: 0.612585\n",
      "Current loss: 8.184093\n",
      "thresh: 0.950000, max F: 0.679036\n",
      "Current loss: 7.622622\n",
      "thresh: 0.950000, max F: 0.643621\n",
      "Current loss: 7.352025\n",
      "thresh: 0.950000, max F: 0.646816\n",
      "Current loss: 7.931878\n",
      "thresh: 0.950000, max F: 0.667329\n",
      "Current loss: 7.811966\n",
      "thresh: 0.950000, max F: 0.659317\n",
      "Current loss: 7.181355\n",
      "thresh: 0.750000, max F: 0.638748\n",
      "Current loss: 7.436207\n",
      "thresh: 0.950000, max F: 0.641999\n",
      "Current loss: 7.897306\n",
      "thresh: 0.950000, max F: 0.660116\n",
      "Current loss: 7.607736\n",
      "thresh: 0.800000, max F: 0.634849\n",
      "Current loss: 7.471575\n",
      "thresh: 0.950000, max F: 0.674520\n",
      "Current loss: 7.538481\n",
      "thresh: 0.950000, max F: 0.640931\n",
      "Current loss: 7.322475\n",
      "thresh: 0.950000, max F: 0.631841\n",
      "Current loss: 7.438076\n",
      "thresh: 0.950000, max F: 0.640784\n",
      "Current loss: 7.508073\n",
      "thresh: 0.950000, max F: 0.667569\n",
      "Current loss: 7.585145\n",
      "thresh: 0.950000, max F: 0.651023\n",
      "Current loss: 7.541471\n",
      "thresh: 0.900000, max F: 0.651047\n",
      "Current loss: 7.397159\n",
      "thresh: 0.950000, max F: 0.640206\n",
      "Current loss: 7.216444\n",
      "thresh: 0.950000, max F: 0.625843\n",
      "Current loss: 7.537101\n",
      "thresh: 0.900000, max F: 0.648023\n",
      "Current loss: 7.707983\n",
      "thresh: 0.950000, max F: 0.640014\n",
      "Current epoch loss: 7.707983\n",
      "Epoch thresh: 0.950000, max F: 0.640014\n",
      "Starting epoch 4 / 10\n",
      "Current loss: 7.415465\n",
      "thresh: 0.750000, max F: 0.634829\n",
      "Current loss: 7.489878\n",
      "thresh: 0.950000, max F: 0.642315\n",
      "Current loss: 7.837912\n",
      "thresh: 0.950000, max F: 0.640532\n",
      "Current loss: 7.453960\n",
      "thresh: 0.950000, max F: 0.649306\n",
      "Current loss: 7.548822\n",
      "thresh: 0.950000, max F: 0.657551\n",
      "Current loss: 7.344257\n",
      "thresh: 0.950000, max F: 0.629590\n",
      "Current loss: 7.406846\n",
      "thresh: 0.950000, max F: 0.617766\n",
      "Current loss: 7.738758\n",
      "thresh: 0.500000, max F: 0.635110\n",
      "Current loss: 7.389159\n",
      "thresh: 0.950000, max F: 0.644524\n",
      "Current loss: 7.378218\n",
      "thresh: 0.950000, max F: 0.649565\n",
      "Current loss: 7.620626\n",
      "thresh: 0.950000, max F: 0.668356\n",
      "Current loss: 7.970933\n",
      "thresh: 0.950000, max F: 0.676849\n",
      "Current loss: 7.133838\n",
      "thresh: 0.950000, max F: 0.641142\n",
      "Current loss: 7.415881\n",
      "thresh: 0.950000, max F: 0.636824\n",
      "Current loss: 7.355313\n",
      "thresh: 0.950000, max F: 0.646005\n",
      "Current loss: 7.029359\n",
      "thresh: 0.500000, max F: 0.623294\n",
      "Current loss: 8.048091\n",
      "thresh: 0.900000, max F: 0.660555\n",
      "Current loss: 7.660749\n",
      "thresh: 0.950000, max F: 0.657430\n",
      "Current loss: 7.598707\n",
      "thresh: 0.800000, max F: 0.643891\n",
      "Current loss: 7.821315\n",
      "thresh: 0.950000, max F: 0.655184\n",
      "Current loss: 7.353067\n",
      "thresh: 0.900000, max F: 0.654139\n",
      "Current loss: 7.654789\n",
      "thresh: 0.950000, max F: 0.645373\n",
      "Current loss: 7.804378\n",
      "thresh: 0.900000, max F: 0.634471\n",
      "Current loss: 8.519847\n",
      "thresh: 0.950000, max F: 0.670455\n",
      "Current loss: 7.838170\n",
      "thresh: 0.100000, max F: 0.626798\n",
      "Current loss: 8.182581\n",
      "thresh: 0.950000, max F: 0.672729\n",
      "Current loss: 7.228597\n",
      "thresh: 0.950000, max F: 0.633040\n",
      "Current loss: 7.410152\n",
      "thresh: 0.950000, max F: 0.631690\n",
      "Current loss: 7.244963\n",
      "thresh: 0.900000, max F: 0.624324\n",
      "Current loss: 7.401343\n",
      "thresh: 0.950000, max F: 0.652987\n",
      "Current loss: 7.603915\n",
      "thresh: 0.950000, max F: 0.655816\n",
      "Current loss: 7.379292\n",
      "thresh: 0.950000, max F: 0.638374\n",
      "Current loss: 7.955338\n",
      "thresh: 0.950000, max F: 0.690755\n",
      "Current loss: 7.859017\n",
      "thresh: 0.950000, max F: 0.642440\n",
      "Current loss: 7.621803\n",
      "thresh: 0.950000, max F: 0.642226\n",
      "Current loss: 7.775940\n",
      "thresh: 0.950000, max F: 0.650198\n",
      "Current loss: 7.336673\n",
      "thresh: 0.950000, max F: 0.629916\n",
      "Current loss: 7.138950\n",
      "thresh: 0.900000, max F: 0.631380\n",
      "Current loss: 7.343776\n",
      "thresh: 0.950000, max F: 0.627979\n",
      "Current loss: 7.457610\n",
      "thresh: 0.750000, max F: 0.646673\n",
      "Current loss: 7.615941\n",
      "thresh: 0.950000, max F: 0.676848\n",
      "Current loss: 7.671245\n",
      "thresh: 0.950000, max F: 0.662858\n",
      "Current loss: 7.258440\n",
      "thresh: 0.250000, max F: 0.598007\n",
      "Current loss: 7.605802\n",
      "thresh: 0.950000, max F: 0.630901\n",
      "Current loss: 7.733912\n",
      "thresh: 0.950000, max F: 0.672630\n",
      "Current loss: 7.695743\n",
      "thresh: 0.950000, max F: 0.646181\n",
      "Current loss: 7.930232\n",
      "thresh: 0.950000, max F: 0.669346\n",
      "Current loss: 6.941190\n",
      "thresh: 0.900000, max F: 0.602770\n",
      "Current loss: 7.608981\n",
      "thresh: 0.950000, max F: 0.658455\n",
      "Current loss: 7.121985\n",
      "thresh: 0.950000, max F: 0.642784\n",
      "Current loss: 7.672877\n",
      "thresh: 0.900000, max F: 0.645986\n",
      "Current loss: 7.873826\n",
      "thresh: 0.950000, max F: 0.631505\n",
      "Current loss: 7.503619\n",
      "thresh: 0.950000, max F: 0.643275\n",
      "Current loss: 7.452260\n",
      "thresh: 0.950000, max F: 0.628009\n",
      "Current loss: 7.719050\n",
      "thresh: 0.900000, max F: 0.660209\n",
      "Current loss: 7.529363\n",
      "thresh: 0.900000, max F: 0.646773\n",
      "Current loss: 7.940979\n",
      "thresh: 0.950000, max F: 0.673819\n",
      "Current loss: 7.366379\n",
      "thresh: 0.800000, max F: 0.618841\n",
      "Current loss: 7.562926\n",
      "thresh: 0.750000, max F: 0.656673\n",
      "Current loss: 7.505411\n",
      "thresh: 0.950000, max F: 0.654736\n",
      "Current loss: 7.184216\n",
      "thresh: 0.950000, max F: 0.654235\n",
      "Current loss: 8.011796\n",
      "thresh: 0.950000, max F: 0.681738\n",
      "Current loss: 7.898080\n",
      "thresh: 0.950000, max F: 0.655204\n",
      "Current loss: 7.189567\n",
      "thresh: 0.900000, max F: 0.629575\n",
      "Current loss: 8.073610\n",
      "thresh: 0.950000, max F: 0.680124\n",
      "Current loss: 7.763644\n",
      "thresh: 0.950000, max F: 0.657649\n",
      "Current loss: 7.506270\n",
      "thresh: 0.950000, max F: 0.653467\n",
      "Current loss: 7.330096\n",
      "thresh: 0.950000, max F: 0.641427\n",
      "Current loss: 7.482644\n",
      "thresh: 0.950000, max F: 0.639399\n",
      "Current loss: 7.608068\n",
      "thresh: 0.900000, max F: 0.649362\n",
      "Current loss: 7.503114\n",
      "thresh: 0.800000, max F: 0.646560\n",
      "Current loss: 7.843678\n",
      "thresh: 0.950000, max F: 0.661400\n",
      "Current loss: 7.839924\n",
      "thresh: 0.950000, max F: 0.668602\n",
      "Current loss: 7.807474\n",
      "thresh: 0.950000, max F: 0.692031\n",
      "Current loss: 7.476676\n",
      "thresh: 0.950000, max F: 0.619753\n",
      "Current loss: 7.203119\n",
      "thresh: 0.950000, max F: 0.644124\n",
      "Current loss: 8.389928\n",
      "thresh: 0.950000, max F: 0.708026\n",
      "Current loss: 7.641789\n",
      "thresh: 0.950000, max F: 0.655444\n",
      "Current loss: 7.131646\n",
      "thresh: 0.950000, max F: 0.660774\n",
      "Current loss: 7.305444\n",
      "thresh: 0.900000, max F: 0.627850\n",
      "Current loss: 7.641130\n",
      "thresh: 0.950000, max F: 0.642513\n",
      "Current loss: 7.534049\n",
      "thresh: 0.950000, max F: 0.657422\n",
      "Current loss: 7.806108\n",
      "thresh: 0.950000, max F: 0.655251\n",
      "Current loss: 8.208897\n",
      "thresh: 0.950000, max F: 0.680876\n",
      "Current loss: 7.336553\n",
      "thresh: 0.900000, max F: 0.636832\n",
      "Current loss: 7.439667\n",
      "thresh: 0.950000, max F: 0.634240\n",
      "Current loss: 6.992887\n",
      "thresh: 0.950000, max F: 0.650019\n",
      "Current loss: 7.870598\n",
      "thresh: 0.950000, max F: 0.676600\n",
      "Current loss: 8.103619\n",
      "thresh: 0.750000, max F: 0.662202\n",
      "Current loss: 7.246233\n",
      "thresh: 0.900000, max F: 0.649645\n",
      "Current loss: 7.949574\n",
      "thresh: 0.950000, max F: 0.663108\n",
      "Current loss: 7.886597\n",
      "thresh: 0.950000, max F: 0.656441\n",
      "Current loss: 7.430620\n",
      "thresh: 0.900000, max F: 0.644723\n",
      "Current loss: 8.105175\n",
      "thresh: 0.950000, max F: 0.667505\n",
      "Current loss: 7.634874\n",
      "thresh: 0.900000, max F: 0.660941\n",
      "Current loss: 7.113019\n",
      "thresh: 0.800000, max F: 0.607872\n",
      "Current loss: 8.087827\n",
      "thresh: 0.950000, max F: 0.677676\n",
      "Current loss: 6.941107\n",
      "thresh: 0.950000, max F: 0.623702\n",
      "Current loss: 8.032679\n",
      "thresh: 0.950000, max F: 0.654453\n",
      "Current loss: 8.035015\n",
      "thresh: 0.950000, max F: 0.678627\n",
      "Current loss: 7.702237\n",
      "thresh: 0.950000, max F: 0.660009\n",
      "Current loss: 7.431877\n",
      "thresh: 0.900000, max F: 0.647675\n",
      "Current loss: 8.190558\n",
      "thresh: 0.950000, max F: 0.668185\n",
      "Current loss: 7.500240\n",
      "thresh: 0.950000, max F: 0.651909\n",
      "Current loss: 7.470883\n",
      "thresh: 0.950000, max F: 0.652478\n",
      "Current loss: 7.359438\n",
      "thresh: 0.950000, max F: 0.652637\n",
      "Current loss: 7.445016\n",
      "thresh: 0.950000, max F: 0.650238\n",
      "Current loss: 7.420870\n",
      "thresh: 0.950000, max F: 0.641713\n",
      "Current loss: 7.236070\n",
      "thresh: 0.800000, max F: 0.628011\n",
      "Current loss: 7.538699\n",
      "thresh: 0.950000, max F: 0.659897\n",
      "Current loss: 7.388525\n",
      "thresh: 0.950000, max F: 0.652283\n",
      "Current loss: 7.471279\n",
      "thresh: 0.950000, max F: 0.641640\n",
      "Current loss: 7.172558\n",
      "thresh: 0.950000, max F: 0.644844\n",
      "Current loss: 7.286913\n",
      "thresh: 0.900000, max F: 0.644241\n",
      "Current loss: 7.508046\n",
      "thresh: 0.950000, max F: 0.644220\n",
      "Current loss: 7.805341\n",
      "thresh: 0.950000, max F: 0.668126\n",
      "Current loss: 7.682255\n",
      "thresh: 0.500000, max F: 0.641995\n",
      "Current loss: 7.065508\n",
      "thresh: 0.900000, max F: 0.630054\n",
      "Current loss: 7.622327\n",
      "thresh: 0.950000, max F: 0.662010\n",
      "Current loss: 7.718652\n",
      "thresh: 0.950000, max F: 0.666928\n",
      "Current loss: 7.606284\n",
      "thresh: 0.950000, max F: 0.673509\n",
      "Current loss: 7.776689\n",
      "thresh: 0.950000, max F: 0.674741\n",
      "Current loss: 7.693048\n",
      "thresh: 0.950000, max F: 0.659214\n",
      "Current loss: 7.589464\n",
      "thresh: 0.950000, max F: 0.642729\n",
      "Current loss: 8.113237\n",
      "thresh: 0.950000, max F: 0.654481\n",
      "Current loss: 7.387476\n",
      "thresh: 0.900000, max F: 0.641386\n",
      "Current loss: 7.015572\n",
      "thresh: 0.800000, max F: 0.629275\n",
      "Current loss: 7.347508\n",
      "thresh: 0.950000, max F: 0.631504\n",
      "Current loss: 8.236444\n",
      "thresh: 0.950000, max F: 0.651753\n",
      "Current loss: 7.780044\n",
      "thresh: 0.950000, max F: 0.648018\n",
      "Current loss: 7.802420\n",
      "thresh: 0.950000, max F: 0.675421\n",
      "Current loss: 7.950347\n",
      "thresh: 0.950000, max F: 0.638656\n",
      "Current loss: 7.309829\n",
      "thresh: 0.800000, max F: 0.636451\n",
      "Current loss: 7.652761\n",
      "thresh: 0.950000, max F: 0.665184\n",
      "Current loss: 7.668668\n",
      "thresh: 0.950000, max F: 0.656286\n",
      "Current loss: 7.150831\n",
      "thresh: 0.500000, max F: 0.625907\n",
      "Current loss: 8.064428\n",
      "thresh: 0.900000, max F: 0.653806\n",
      "Current loss: 7.985584\n",
      "thresh: 0.800000, max F: 0.661706\n",
      "Current loss: 7.634261\n",
      "thresh: 0.950000, max F: 0.655330\n",
      "Current loss: 7.526744\n",
      "thresh: 0.950000, max F: 0.647270\n",
      "Current loss: 7.604385\n",
      "thresh: 0.950000, max F: 0.663875\n",
      "Current loss: 8.143128\n",
      "thresh: 0.900000, max F: 0.682045\n",
      "Current loss: 6.923661\n",
      "thresh: 0.950000, max F: 0.637849\n",
      "Current loss: 7.083638\n",
      "thresh: 0.950000, max F: 0.641773\n",
      "Current loss: 6.902871\n",
      "thresh: 0.950000, max F: 0.623274\n",
      "Current loss: 7.014442\n",
      "thresh: 0.900000, max F: 0.608623\n",
      "Current loss: 7.577731\n",
      "thresh: 0.950000, max F: 0.650479\n",
      "Current loss: 7.263300\n",
      "thresh: 0.950000, max F: 0.640768\n",
      "Current loss: 7.497441\n",
      "thresh: 0.950000, max F: 0.641919\n",
      "Current loss: 7.715322\n",
      "thresh: 0.950000, max F: 0.643439\n",
      "Current loss: 7.957777\n",
      "thresh: 0.950000, max F: 0.670931\n",
      "Current loss: 7.972937\n",
      "thresh: 0.900000, max F: 0.663349\n",
      "Current loss: 7.463791\n",
      "thresh: 0.900000, max F: 0.618815\n",
      "Current loss: 7.248428\n",
      "thresh: 0.950000, max F: 0.641844\n",
      "Current loss: 7.544124\n",
      "thresh: 0.950000, max F: 0.637201\n",
      "Current loss: 7.969766\n",
      "thresh: 0.950000, max F: 0.661050\n",
      "Current loss: 7.428084\n",
      "thresh: 0.950000, max F: 0.639833\n",
      "Current loss: 7.390356\n",
      "thresh: 0.950000, max F: 0.645047\n",
      "Current loss: 8.014253\n",
      "thresh: 0.950000, max F: 0.662908\n",
      "Current loss: 7.419833\n",
      "thresh: 0.950000, max F: 0.655041\n",
      "Current loss: 7.345939\n",
      "thresh: 0.250000, max F: 0.632870\n",
      "Current loss: 7.879680\n",
      "thresh: 0.250000, max F: 0.651113\n",
      "Current loss: 8.332254\n",
      "thresh: 0.950000, max F: 0.692779\n",
      "Current loss: 8.032205\n",
      "thresh: 0.900000, max F: 0.668216\n",
      "Current loss: 7.582734\n",
      "thresh: 0.950000, max F: 0.639276\n",
      "Current loss: 7.703282\n",
      "thresh: 0.750000, max F: 0.635132\n",
      "Current loss: 7.498824\n",
      "thresh: 0.950000, max F: 0.643872\n",
      "Current loss: 7.780768\n",
      "thresh: 0.900000, max F: 0.654272\n",
      "Current loss: 7.266388\n",
      "thresh: 0.950000, max F: 0.654870\n",
      "Current loss: 7.038128\n",
      "thresh: 0.750000, max F: 0.630739\n",
      "Current loss: 7.371460\n",
      "thresh: 0.950000, max F: 0.665242\n",
      "Current loss: 7.535592\n",
      "thresh: 0.750000, max F: 0.653575\n",
      "Current loss: 7.168824\n",
      "thresh: 0.950000, max F: 0.611517\n",
      "Current loss: 7.392512\n",
      "thresh: 0.950000, max F: 0.643657\n",
      "Current loss: 7.691074\n",
      "thresh: 0.800000, max F: 0.626217\n",
      "Current loss: 7.630236\n",
      "thresh: 0.950000, max F: 0.648136\n",
      "Current loss: 7.919337\n",
      "thresh: 0.800000, max F: 0.644349\n",
      "Current loss: 7.346056\n",
      "thresh: 0.950000, max F: 0.641869\n",
      "Current loss: 7.345098\n",
      "thresh: 0.950000, max F: 0.654714\n",
      "Current loss: 7.280030\n",
      "thresh: 0.900000, max F: 0.629742\n",
      "Current loss: 7.439935\n",
      "thresh: 0.900000, max F: 0.643360\n",
      "Current loss: 7.874952\n",
      "thresh: 0.900000, max F: 0.662615\n",
      "Current loss: 7.480548\n",
      "thresh: 0.950000, max F: 0.633879\n",
      "Current loss: 6.863050\n",
      "thresh: 0.950000, max F: 0.596258\n",
      "Current loss: 7.428085\n",
      "thresh: 0.950000, max F: 0.647857\n",
      "Current loss: 7.546259\n",
      "thresh: 0.950000, max F: 0.648637\n",
      "Current loss: 7.251950\n",
      "thresh: 0.950000, max F: 0.626769\n",
      "Current loss: 7.494425\n",
      "thresh: 0.950000, max F: 0.639054\n",
      "Current loss: 7.723687\n",
      "thresh: 0.950000, max F: 0.665729\n",
      "Current loss: 8.068866\n",
      "thresh: 0.950000, max F: 0.662864\n",
      "Current loss: 7.396952\n",
      "thresh: 0.950000, max F: 0.662760\n",
      "Current loss: 7.475262\n",
      "thresh: 0.900000, max F: 0.642139\n",
      "Current loss: 7.663551\n",
      "thresh: 0.950000, max F: 0.641144\n",
      "Current loss: 7.229487\n",
      "thresh: 0.950000, max F: 0.628859\n",
      "Current loss: 7.643915\n",
      "thresh: 0.950000, max F: 0.633056\n",
      "Current loss: 7.267162\n",
      "thresh: 0.950000, max F: 0.640408\n",
      "Current loss: 7.163693\n",
      "thresh: 0.800000, max F: 0.627856\n",
      "Current loss: 7.168875\n",
      "thresh: 0.900000, max F: 0.627828\n",
      "Current loss: 7.236131\n",
      "thresh: 0.950000, max F: 0.653234\n",
      "Current loss: 7.586746\n",
      "thresh: 0.950000, max F: 0.662969\n",
      "Current loss: 7.788133\n",
      "thresh: 0.950000, max F: 0.664877\n",
      "Current loss: 7.257900\n",
      "thresh: 0.950000, max F: 0.644125\n",
      "Current loss: 7.039075\n",
      "thresh: 0.950000, max F: 0.616653\n",
      "Current loss: 7.750348\n",
      "thresh: 0.950000, max F: 0.657102\n",
      "Current loss: 7.682254\n",
      "thresh: 0.950000, max F: 0.644656\n",
      "Current loss: 7.521386\n",
      "thresh: 0.950000, max F: 0.644144\n",
      "Current loss: 7.952355\n",
      "thresh: 0.950000, max F: 0.686047\n",
      "Current loss: 8.457084\n",
      "thresh: 0.950000, max F: 0.704209\n",
      "Current loss: 7.992171\n",
      "thresh: 0.900000, max F: 0.663564\n",
      "Current loss: 7.779842\n",
      "thresh: 0.950000, max F: 0.670046\n",
      "Current loss: 7.893805\n",
      "thresh: 0.950000, max F: 0.644355\n",
      "Current loss: 7.738339\n",
      "thresh: 0.950000, max F: 0.660601\n",
      "Current loss: 7.237829\n",
      "thresh: 0.950000, max F: 0.659043\n",
      "Current loss: 7.336156\n",
      "thresh: 0.900000, max F: 0.619400\n",
      "Current loss: 7.981822\n",
      "thresh: 0.950000, max F: 0.658286\n",
      "Current loss: 8.028622\n",
      "thresh: 0.900000, max F: 0.644555\n",
      "Current loss: 7.618879\n",
      "thresh: 0.900000, max F: 0.635725\n",
      "Current loss: 7.609056\n",
      "thresh: 0.950000, max F: 0.647576\n",
      "Current loss: 7.421630\n",
      "thresh: 0.900000, max F: 0.644704\n",
      "Current loss: 8.138565\n",
      "thresh: 0.750000, max F: 0.654996\n",
      "Current loss: 7.758896\n",
      "thresh: 0.250000, max F: 0.637057\n",
      "Current loss: 7.655342\n",
      "thresh: 0.800000, max F: 0.654565\n",
      "Current loss: 7.607215\n",
      "thresh: 0.950000, max F: 0.642722\n",
      "Current loss: 7.610909\n",
      "thresh: 0.950000, max F: 0.660873\n",
      "Current loss: 8.047585\n",
      "thresh: 0.950000, max F: 0.676596\n",
      "Current loss: 7.791831\n",
      "thresh: 0.950000, max F: 0.649494\n",
      "Current loss: 7.417142\n",
      "thresh: 0.900000, max F: 0.648053\n",
      "Current loss: 8.073887\n",
      "thresh: 0.950000, max F: 0.667259\n",
      "Current loss: 7.405935\n",
      "thresh: 0.950000, max F: 0.620870\n",
      "Current loss: 7.347990\n",
      "thresh: 0.900000, max F: 0.633515\n",
      "Current loss: 7.811065\n",
      "thresh: 0.950000, max F: 0.666645\n",
      "Current loss: 7.811832\n",
      "thresh: 0.950000, max F: 0.665943\n",
      "Current loss: 7.490524\n",
      "thresh: 0.950000, max F: 0.640174\n",
      "Current loss: 8.047979\n",
      "thresh: 0.900000, max F: 0.676074\n",
      "Current loss: 7.885942\n",
      "thresh: 0.950000, max F: 0.659808\n",
      "Current loss: 7.152184\n",
      "thresh: 0.950000, max F: 0.620480\n",
      "Current loss: 7.544350\n",
      "thresh: 0.900000, max F: 0.659850\n",
      "Current loss: 7.436420\n",
      "thresh: 0.950000, max F: 0.615863\n",
      "Current loss: 7.512727\n",
      "thresh: 0.500000, max F: 0.633062\n",
      "Current loss: 7.588195\n",
      "thresh: 0.950000, max F: 0.651308\n",
      "Current loss: 6.942954\n",
      "thresh: 0.100000, max F: 0.605814\n",
      "Current loss: 7.821737\n",
      "thresh: 0.950000, max F: 0.640840\n",
      "Current loss: 7.720342\n",
      "thresh: 0.750000, max F: 0.651478\n",
      "Current loss: 7.060894\n",
      "thresh: 0.950000, max F: 0.628843\n",
      "Current loss: 7.733764\n",
      "thresh: 0.750000, max F: 0.649063\n",
      "Current loss: 7.130298\n",
      "thresh: 0.950000, max F: 0.632401\n",
      "Current loss: 7.290068\n",
      "thresh: 0.950000, max F: 0.622081\n",
      "Current loss: 7.737543\n",
      "thresh: 0.950000, max F: 0.663409\n",
      "Current loss: 7.524035\n",
      "thresh: 0.950000, max F: 0.642521\n",
      "Current loss: 7.475026\n",
      "thresh: 0.800000, max F: 0.634677\n",
      "Current loss: 7.480005\n",
      "thresh: 0.950000, max F: 0.647237\n",
      "Current loss: 7.479968\n",
      "thresh: 0.950000, max F: 0.660573\n",
      "Current loss: 6.885107\n",
      "thresh: 0.950000, max F: 0.619239\n",
      "Current loss: 7.670606\n",
      "thresh: 0.750000, max F: 0.646258\n",
      "Current loss: 7.821509\n",
      "thresh: 0.900000, max F: 0.658301\n",
      "Current loss: 8.076638\n",
      "thresh: 0.950000, max F: 0.678156\n",
      "Current loss: 7.601138\n",
      "thresh: 0.950000, max F: 0.666898\n",
      "Current loss: 7.975179\n",
      "thresh: 0.900000, max F: 0.652841\n",
      "Current loss: 7.374192\n",
      "thresh: 0.950000, max F: 0.646447\n",
      "Current loss: 7.893885\n",
      "thresh: 0.950000, max F: 0.642184\n",
      "Current loss: 7.592023\n",
      "thresh: 0.900000, max F: 0.651543\n",
      "Current loss: 7.772259\n",
      "thresh: 0.950000, max F: 0.660826\n",
      "Current loss: 8.093088\n",
      "thresh: 0.950000, max F: 0.693441\n",
      "Current loss: 6.851698\n",
      "thresh: 0.950000, max F: 0.621357\n",
      "Current loss: 7.972817\n",
      "thresh: 0.950000, max F: 0.656527\n",
      "Current loss: 7.497018\n",
      "thresh: 0.950000, max F: 0.636020\n",
      "Current loss: 7.947915\n",
      "thresh: 0.900000, max F: 0.664871\n",
      "Current loss: 6.990582\n",
      "thresh: 0.750000, max F: 0.608592\n",
      "Current loss: 7.195750\n",
      "thresh: 0.800000, max F: 0.639666\n",
      "Current loss: 7.378255\n",
      "thresh: 0.950000, max F: 0.619237\n",
      "Current epoch loss: 7.378255\n",
      "Epoch thresh: 0.950000, max F: 0.619237\n",
      "Starting epoch 5 / 10\n",
      "Current loss: 7.748226\n",
      "thresh: 0.950000, max F: 0.677475\n",
      "Current loss: 7.615250\n",
      "thresh: 0.950000, max F: 0.654869\n",
      "Current loss: 7.466649\n",
      "thresh: 0.950000, max F: 0.614452\n",
      "Current loss: 7.534146\n",
      "thresh: 0.800000, max F: 0.645452\n",
      "Current loss: 7.062984\n",
      "thresh: 0.950000, max F: 0.654082\n",
      "Current loss: 7.847854\n",
      "thresh: 0.950000, max F: 0.663724\n",
      "Current loss: 7.402055\n",
      "thresh: 0.900000, max F: 0.646234\n",
      "Current loss: 7.850789\n",
      "thresh: 0.950000, max F: 0.648888\n",
      "Current loss: 7.305311\n",
      "thresh: 0.900000, max F: 0.617065\n",
      "Current loss: 7.414777\n",
      "thresh: 0.950000, max F: 0.635461\n",
      "Current loss: 7.281616\n",
      "thresh: 0.950000, max F: 0.634435\n",
      "Current loss: 7.287628\n",
      "thresh: 0.950000, max F: 0.632739\n",
      "Current loss: 8.141428\n",
      "thresh: 0.900000, max F: 0.671589\n",
      "Current loss: 8.197514\n",
      "thresh: 0.900000, max F: 0.631781\n",
      "Current loss: 7.597827\n",
      "thresh: 0.950000, max F: 0.678512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6a542bacc539>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m                     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurr_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurr_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurr_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfc876_train_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m                     \u001b[0mloss_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mcurr_loss\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiments = [] # list with dict of params for each experiment\n",
    "\n",
    "lr1s = [1e-3] # 5e-5, \n",
    "lr2s = [1e-5] # 1e-6, 1e-7, \n",
    "dropout_probs = [0.4] # 0.5, 0.3\n",
    "weight_decays = [1e-4] # 5e-4, \n",
    "\n",
    "# create a dict of experiments\n",
    "for lr1 in lr1s:\n",
    "    for lr2 in lr2s:\n",
    "        for dp in dropout_probs:\n",
    "            for wd in weight_decays:\n",
    "                experiments.append({'lr1': lr1, 'lr2': lr2, 'dp': dp, 'wd': wd})\n",
    "\n",
    "print(experiments)\n",
    "\n",
    "loss_log = []\n",
    "f_log = []\n",
    "thresh_log = []\n",
    "\n",
    "for params_dict in experiments:\n",
    "    print(params_dict)\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train_dir', default='data/train-jpg/')\n",
    "    parser.add_argument('--model_path', default='vgg_16.ckpt', type=str)\n",
    "    parser.add_argument('--batch_size', default=100, type=int) #32\n",
    "    parser.add_argument('--num_workers', default=50, type=int) #4\n",
    "    parser.add_argument('--num_epochs1', default=10, type=int) #10\n",
    "    parser.add_argument('--num_epochs2', default=1, type=int) #10\n",
    "    parser.add_argument('--learning_rate1', default = params_dict['lr1'], type=float) #1e-3\n",
    "    parser.add_argument('--learning_rate2', default = params_dict['lr2'], type=float)\n",
    "    parser.add_argument('--dropout_keep_prob', default = params_dict['dp'], type=float)\n",
    "    parser.add_argument('--weight_decay', default = params_dict['wd'], type=float)\n",
    "    \n",
    "    # For accessing args in an ipython notebook\n",
    "    import sys; sys.argv=['']; del sys\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Get the list of filenames and corresponding list of labels for training et validation\n",
    "    # train_filenames, train_labels = list_images(args.train_dir)\n",
    "    # val_filenames, val_labels = list_images(args.val_dir)\n",
    "    \n",
    "    all_filenames, all_labels = list_images(args.train_dir)\n",
    "    \n",
    "    train_filenames, train_labels, val_filenames, val_labels = split_samples(all_filenames, all_labels)\n",
    "    \n",
    "    num_classes = 17\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # In TensorFlow, you first want to define the computation graph with all the\n",
    "    # necessary operations: loss, training op, accuracy...\n",
    "    # Any tensor created in the `graph.as_default()` scope will be part of `graph`\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # Standard preprocessing for VGG on ImageNet taken from here:\n",
    "        # https://github.com/tensorflow/models/blob/master/slim/preprocessing/vgg_preprocessing.py\n",
    "        # Also see the VGG paper for more details: https://arxiv.org/pdf/1409.1556.pdf\n",
    "    \n",
    "        # Preprocessing (for both training and validation):\n",
    "        # (1) Decode the image from jpg format\n",
    "        # (2) Resize the image so its smaller side is 256 pixels long\n",
    "        def _parse_function(filename, label):\n",
    "            image_string = tf.read_file(filename)\n",
    "            image_decoded = tf.image.decode_jpeg(image_string, channels=3)          # (1)\n",
    "            image = tf.cast(image_decoded, tf.float32)\n",
    "    \n",
    "            smallest_side = 256.0\n",
    "            height, width = tf.shape(image)[0], tf.shape(image)[1]\n",
    "            height = tf.to_float(height)\n",
    "            width = tf.to_float(width)\n",
    "    \n",
    "            scale = tf.cond(tf.greater(height, width),\n",
    "                            lambda: smallest_side / width,\n",
    "                             lambda: smallest_side / height)\n",
    "            new_height = tf.to_int32(height * scale)\n",
    "            new_width = tf.to_int32(width * scale)\n",
    "    \n",
    "            resized_image = tf.image.resize_images(image, [new_height, new_width])  # (2)\n",
    "            return resized_image, label\n",
    "\n",
    "        # Preprocessing (for training)\n",
    "        # (3) Take a random 224x224 crop to the scaled image\n",
    "        # (4) Horizontally flip the image with probability 1/2\n",
    "        # (5) Substract the per color mean `VGG_MEAN`\n",
    "        # Note: we don't normalize the data here, as VGG was trained without normalization\n",
    "        def training_preprocess(image, label):\n",
    "            crop_image = tf.random_crop(image, [224, 224, 3])                       # (3)\n",
    "            flip_image = tf.image.random_flip_left_right(crop_image)                # (4)\n",
    "    \n",
    "            means = tf.reshape(tf.constant(VGG_MEAN), [1, 1, 3])\n",
    "            centered_image = flip_image - means                                     # (5)\n",
    "    \n",
    "            return centered_image, label\n",
    "    \n",
    "        # Preprocessing (for validation)\n",
    "        # (3) Take a central 224x224 crop to the scaled image\n",
    "        # (4) Substract the per color mean `VGG_MEAN`\n",
    "        # Note: we don't normalize the data here, as VGG was trained without normalization\n",
    "        def val_preprocess(image, label):\n",
    "            crop_image = tf.image.resize_image_with_crop_or_pad(image, 224, 224)    # (3)\n",
    "    \n",
    "            means = tf.reshape(tf.constant(VGG_MEAN), [1, 1, 3])\n",
    "            centered_image = crop_image - means                                     # (4)\n",
    "    \n",
    "            return centered_image, label\n",
    "    \n",
    "            # ----------------------------------------------------------------------\n",
    "            # DATASET CREATION using tf.contrib.data.Dataset\n",
    "            # https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data\n",
    "        \n",
    "            # The tf.contrib.data.Dataset framework uses queues in the background to feed in\n",
    "            # data to the model.\n",
    "            # We initialize the dataset with a list of filenames and labels, and then apply\n",
    "        # the preprocessing functions described above.\n",
    "        # Behind the scenes, queues will load the filenames, preprocess them with multiple\n",
    "        # threads and apply the preprocessing in parallel, and then batch the data\n",
    "    \n",
    "        # Training dataset\n",
    "        train_filenames = tf.constant(train_filenames)\n",
    "        train_labels = tf.constant(train_labels)\n",
    "        train_dataset = tf.contrib.data.Dataset.from_tensor_slices((train_filenames, train_labels))\n",
    "        train_dataset = train_dataset.map(_parse_function,\n",
    "           num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        train_dataset = train_dataset.map(training_preprocess,\n",
    "           num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=10000)  # don't forget to shuffle\n",
    "        batched_train_dataset = train_dataset.batch(args.batch_size)\n",
    "    \n",
    "        # Validation dataset\n",
    "        val_filenames = tf.constant(val_filenames)\n",
    "        val_labels = tf.constant(val_labels)\n",
    "        val_dataset = tf.contrib.data.Dataset.from_tensor_slices((val_filenames, val_labels))\n",
    "        val_dataset = val_dataset.map(_parse_function,\n",
    "        num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        val_dataset = val_dataset.map(val_preprocess,\n",
    "        num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        batched_val_dataset = val_dataset.batch(args.batch_size)\n",
    "\n",
    "        print(\"dataset created\")\n",
    "        # Now we define an iterator that can operator on either dataset.\n",
    "        # The iterator can be reinitialized by calling:\n",
    "        #     - sess.run(train_init_op) for 1 epoch on the training set\n",
    "        #     - sess.run(val_init_op)   for 1 epoch on the valiation set\n",
    "        # Once this is done, we don't need to feed any value for images and labels\n",
    "        # as they are automatically pulled out from the iterator queues.\n",
    "    \n",
    "        # A reinitializable iterator is defined by its structure. We could use the\n",
    "        # `output_types` and `output_shapes` properties of either `train_dataset`\n",
    "        # or `validation_dataset` here, because they are compatible.\n",
    "        iterator = tf.contrib.data.Iterator.from_structure(batched_train_dataset.output_types,\n",
    "                                                           batched_train_dataset.output_shapes)\n",
    "        images, labels = iterator.get_next()\n",
    "        train_init_op = iterator.make_initializer(batched_train_dataset)\n",
    "        val_init_op = iterator.make_initializer(batched_val_dataset)\n",
    "    \n",
    "        # Indicates whether we are in training or in test mode\n",
    "        is_training = tf.placeholder(tf.bool)\n",
    "    \n",
    "        # ---------------------------------------------------------------------\n",
    "        # Now that we have set up the data, it's time to set up the model.\n",
    "        # For this example, we'll use VGG-16 pretrained on ImageNet. We will remove the\n",
    "        # last fully connected layer (fc8) and replace it with our own, with an\n",
    "        # output size num_classes=8\n",
    "        # We will first train the last layer for a few epochs.\n",
    "        # Then we will train the entire model on our dataset for a few epochs.\n",
    "    \n",
    "        # Get the pretrained model, specifying the num_classes argument to create a new\n",
    "        # fully connected replacing the last one, called \"vgg_16/fc8\"\n",
    "        # Each model has a different architecture, so \"vgg_16/fc8\" will change in another model.\n",
    "        # Here, logits gives us directly the predicted scores we wanted from the images.\n",
    "        # We pass a scope to initialize \"vgg_16/fc8\" weights with he_initializer\n",
    "        vgg = tf.contrib.slim.nets.vgg\n",
    "        with slim.arg_scope(vgg.vgg_arg_scope(weight_decay=args.weight_decay)):\n",
    "            logits, _ = vgg.vgg_16(images, num_classes=num_classes, is_training=is_training,\n",
    "                                       dropout_keep_prob=args.dropout_keep_prob)\n",
    "            logits = tf.sigmoid(logits) # add a sigmoid layer to make scores be 0-1\n",
    "    \n",
    "        # Specify where the model checkpoint is (pretrained weights).\n",
    "        model_path = args.model_path\n",
    "        assert(os.path.isfile(model_path))\n",
    "    \n",
    "        # Restore only the layers up to fc6 (included)\n",
    "        # Calling function `init_fn(sess)` will load all the pretrained weights.\n",
    "        variables_to_restore = tf.contrib.framework.get_variables_to_restore(exclude=['vgg_16/fc8', 'vgg_16/fc7', 'vgg_16/fc6'])\n",
    "        init_fn = tf.contrib.framework.assign_from_checkpoint_fn(model_path, variables_to_restore)\n",
    "    \n",
    "        # Initialization operation from scratch for the new \"fc6\" layers\n",
    "        # `get_variables` will only return the variables whose name starts with the given pattern\n",
    "        fc6_variables = tf.contrib.framework.get_variables('vgg_16/fc6')\n",
    "        fc6_init = tf.variables_initializer(fc6_variables)\n",
    "        \n",
    "        # Initialization operation from scratch for the new \"fc7\" layers\n",
    "        # `get_variables` will only return the variables whose name starts with the given pattern\n",
    "        fc7_variables = tf.contrib.framework.get_variables('vgg_16/fc7')\n",
    "        fc7_init = tf.variables_initializer(fc7_variables)\n",
    "        \n",
    "        # Initialization operation from scratch for the new \"fc8\" layers\n",
    "        # `get_variables` will only return the variables whose name starts with the given pattern\n",
    "        fc8_variables = tf.contrib.framework.get_variables('vgg_16/fc8')\n",
    "        fc8_init = tf.variables_initializer(fc8_variables)\n",
    "        \n",
    "        # Initialize additional fully connected layer\n",
    "        fc9_variables = \n",
    "    \n",
    "        # ---------------------------------------------------------------------\n",
    "        # Using tf.losses, any loss is added to the tf.GraphKeys.LOSSES collection\n",
    "        # We can then call the total loss easily\n",
    "        # tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits) \n",
    "        tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits) # softmax cross entropy loss so can have labels with multiple classes\n",
    "        loss = tf.losses.get_total_loss()  \n",
    "    \n",
    "        # First we want to train only the reinitialized last layer fc8 for a few epochs.\n",
    "        # We run minimize the loss only with respect to the fc8 variables (weight and bias).\n",
    "        fc876_optimizer = tf.train.GradientDescentOptimizer(args.learning_rate1)\n",
    "        fc876_train_op = fc876_optimizer.minimize(loss, var_list=[fc8_variables, fc7_variables, fc6_variables])\n",
    "\n",
    "        # Then we want to finetune the entire model for a few epochs.\n",
    "        # We run minimize the loss only with respect to all the variables.\n",
    "        full_optimizer = tf.train.GradientDescentOptimizer(args.learning_rate2)\n",
    "        full_train_op = full_optimizer.minimize(loss)\n",
    "    \n",
    "        # Evaluation metrics\n",
    "        \n",
    "        tf.get_default_graph().finalize()\n",
    "    \n",
    "    # --------------------------------------------------------------------------\n",
    "    # Now that we have built the graph and finalized it, we define the session.\n",
    "    # The session is the interface to *run* the computational graph.\n",
    "    # We can call our training operations with `sess.run(train_op)` for instance\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        init_fn(sess)  # load the pretrained weights\n",
    "        sess.run(fc8_init)  # initialize the new fc8 layer\n",
    "        sess.run(fc7_init) # initialize fc7\n",
    "        sess.run(fc6_init) # initialize fc6\n",
    "\n",
    "        # Update only the last layer for a few epochs.\n",
    "        for epoch in range(args.num_epochs1):\n",
    "            # Run an epoch over the training data.\n",
    "            print('Starting epoch %d / %d' % (epoch + 1, args.num_epochs1))\n",
    "            # Here we initialize the iterator with the training set.\n",
    "            # This means that we can go through an entire epoch until the iterator becomes empty.\n",
    "            sess.run(train_init_op)\n",
    "            while True:\n",
    "                try:\n",
    "                    _, curr_loss, curr_logits, curr_labels = sess.run([fc876_train_op, loss, logits, labels], {is_training: True})\n",
    "                    loss_log.append(curr_loss)\n",
    "                    if curr_loss < 100:\n",
    "                        print('Current loss: %f' % curr_loss)\n",
    "\n",
    "                        # Check F score on logits\n",
    "                        threshs = [0.05, 0.1, 0.25, 0.5, 0.75, 0.8, 0.9, 0.95]\n",
    "                        Fs = []\n",
    "                        for i in range(len(threshs)):\n",
    "                            Fs.append(fbeta_score(curr_labels, np.array(curr_logits) > threshs[i], beta=2, average='samples'))\n",
    "                        max_i = Fs.index(max(Fs))\n",
    "                        print('thresh: %f, max F: %f' %(threshs[max_i], Fs[max_i]))\n",
    "                        thresh_log.append(threshs[max_i])\n",
    "                        f_log.append(Fs[max_i])\n",
    "                    else:\n",
    "                        print(\"EXPLODING LOSS\")\n",
    "                        break\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "            \n",
    "            # Print current loss\n",
    "            print('Current epoch loss: %f' % curr_loss)\n",
    "            \n",
    "            # Check F score on logits\n",
    "            threshs = [0.05, 0.1, 0.25, 0.5, 0.75, 0.8, 0.9, 0.95]\n",
    "            Fs = []\n",
    "            for i in range(len(threshs)):\n",
    "                Fs.append(fbeta_score(curr_labels, np.array(curr_logits) > threshs[i], beta=2, average='samples'))\n",
    "            max_i = Fs.index(max(Fs))\n",
    "            print('Epoch thresh: %f, max F: %f' %(threshs[max_i], Fs[max_i]))\n",
    "            \n",
    "            # Check accuracy on the train and val sets every epoch.\n",
    "            # train_acc = check_accuracy(sess, correct_prediction, is_training, train_init_op)\n",
    "            # val_acc = check_accuracy(sess, correct_prediction, is_training, val_init_op)\n",
    "            # print('Train accuracy: %f' % train_acc)\n",
    "            # print('Val accuracy: %f\\n' % val_acc)\n",
    "    \n",
    "    \n",
    "        # Train the entire model for a few more epochs, continuing with the *same* weights.\n",
    "        for epoch in range(args.num_epochs2):\n",
    "            print('Starting epoch %d / %d' % (epoch + 1, args.num_epochs2))\n",
    "            sess.run(train_init_op)\n",
    "            while True:\n",
    "                try:\n",
    "                    _, curr_loss, curr_logits, curr_labels = sess.run([full_train_op, loss, logits, labels], {is_training: True})\n",
    "                    loss_log.append(curr_loss)\n",
    "\n",
    "                    if curr_loss < 100:\n",
    "                        print('Current loss: %f' % curr_loss)\n",
    "\n",
    "                        # Check F score on logits\n",
    "                        threshs = [0.5, 0.1, 0.25, 0.5, 0.75, 0.8, 0.9, 0.95]\n",
    "                        Fs = []\n",
    "                        for i in range(len(threshs)):\n",
    "                            Fs.append(fbeta_score(curr_labels, np.array(curr_logits) > threshs[i], beta=2, average='samples'))\n",
    "                        max_i = Fs.index(max(Fs))\n",
    "                        print('thresh: %f, max F: %f' %(threshs[max_i], Fs[max_i]))\n",
    "                        thresh_log.append(threshs[max_i])\n",
    "                        f_log.append(Fs[max_i])\n",
    "                    else:\n",
    "                        print(\"EXPLODING LOSS\")\n",
    "                        break\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "    \n",
    "            # Print current loss\n",
    "            print('Entire model epoch loss: %f' % curr_loss)\n",
    "    \n",
    "            # Check F score on logits\n",
    "            threshs = [0.05, 0.1, 0.25, 0.5, 0.75, 0.8, 0.9, 0.95]\n",
    "            Fs = []\n",
    "            for i in range(len(threshs)):\n",
    "                Fs.append(fbeta_score(curr_labels, np.array(curr_logits) > threshs[i], beta=2, average='samples'))\n",
    "            max_i = Fs.index(max(Fs))\n",
    "            print('Entire model epoch thresh: %f, max F: %f' %(threshs[max_i], Fs[max_i]))\n",
    "            \n",
    "            # Check accuracy on the train and val sets every epoch\n",
    "            # train_acc = check_accuracy(sess, correct_prediction, is_training, train_init_op)\n",
    "            # val_acc = check_accuracy(sess, correct_prediction, is_training, val_init_op)\n",
    "            # print('Train accuracy: %f' % train_acc)\n",
    "            # print('Val accuracy: %f\\n' % val_acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.4865713,\n",
       " 8.9777699,\n",
       " 8.3237562,\n",
       " 8.3305616,\n",
       " 8.3337154,\n",
       " 8.0930071,\n",
       " 8.8884449,\n",
       " 7.9526343,\n",
       " 8.2214165,\n",
       " 7.9075079,\n",
       " 7.837399,\n",
       " 7.8236284,\n",
       " 8.1950054,\n",
       " 8.2363329,\n",
       " 7.5359364,\n",
       " 7.8460698,\n",
       " 8.1068268,\n",
       " 8.0083027,\n",
       " 7.6284266,\n",
       " 7.6762023,\n",
       " 7.8359299,\n",
       " 8.247345,\n",
       " 7.7166495,\n",
       " 7.9537516,\n",
       " 7.7317286,\n",
       " 8.2916603,\n",
       " 7.4644785,\n",
       " 7.9027176,\n",
       " 7.4496465,\n",
       " 7.3289752,\n",
       " 7.4514861,\n",
       " 7.4237981,\n",
       " 7.7085338,\n",
       " 8.0786133,\n",
       " 8.1121902,\n",
       " 8.4150343,\n",
       " 7.5011468,\n",
       " 7.5444694,\n",
       " 7.5887737,\n",
       " 7.4624319,\n",
       " 7.8495746,\n",
       " 8.3187094,\n",
       " 7.6243014,\n",
       " 7.4161825,\n",
       " 7.3927355,\n",
       " 7.4336648,\n",
       " 7.6829796,\n",
       " 7.925106,\n",
       " 7.0129528,\n",
       " 6.9112325,\n",
       " 7.5184927,\n",
       " 7.7016068,\n",
       " 7.9828238,\n",
       " 6.8553009,\n",
       " 7.3367553,\n",
       " 7.4809208,\n",
       " 7.1702213,\n",
       " 7.702527,\n",
       " 7.6048265,\n",
       " 7.6174836,\n",
       " 7.7716861,\n",
       " 7.6493282,\n",
       " 7.1154957,\n",
       " 7.558239,\n",
       " 7.0838046,\n",
       " 7.6624026,\n",
       " 7.420279,\n",
       " 7.4077821,\n",
       " 7.3571291,\n",
       " 7.3151789,\n",
       " 6.7448716,\n",
       " 7.5804701,\n",
       " 7.8100247,\n",
       " 7.4837108,\n",
       " 7.4721327,\n",
       " 8.1705723,\n",
       " 7.4240775,\n",
       " 7.6582222,\n",
       " 7.5887871,\n",
       " 7.1351242,\n",
       " 7.3274717,\n",
       " 7.5731592,\n",
       " 7.881537,\n",
       " 7.1880417,\n",
       " 7.2625141,\n",
       " 7.0432758,\n",
       " 7.3468685,\n",
       " 8.1690712,\n",
       " 7.9264841,\n",
       " 7.8409147,\n",
       " 8.3769379,\n",
       " 7.5017891,\n",
       " 7.8047123,\n",
       " 8.1760931,\n",
       " 7.3851757,\n",
       " 7.5366077,\n",
       " 7.3690615,\n",
       " 7.6046619,\n",
       " 7.436933,\n",
       " 7.6048594,\n",
       " 7.3466878,\n",
       " 7.9517269,\n",
       " 7.6776299,\n",
       " 7.7126937,\n",
       " 7.9502258,\n",
       " 7.6277156,\n",
       " 7.6484504,\n",
       " 7.7048926,\n",
       " 7.2480798,\n",
       " 7.4405265,\n",
       " 7.6842871,\n",
       " 7.8492475,\n",
       " 7.5279441,\n",
       " 7.3339038,\n",
       " 7.7087622,\n",
       " 7.6808624,\n",
       " 7.9474378,\n",
       " 7.6334753,\n",
       " 7.4134064,\n",
       " 7.4383678,\n",
       " 7.8463321,\n",
       " 7.1617999,\n",
       " 7.8836031,\n",
       " 7.5434155,\n",
       " 7.2038636,\n",
       " 7.3164778,\n",
       " 7.8073525,\n",
       " 7.4460154,\n",
       " 7.4311109,\n",
       " 7.653244,\n",
       " 7.3475642,\n",
       " 7.7144265,\n",
       " 7.0640283,\n",
       " 7.5118446,\n",
       " 6.8334284,\n",
       " 7.1962872,\n",
       " 7.6308656,\n",
       " 7.2480984,\n",
       " 8.1379366,\n",
       " 7.5242262,\n",
       " 7.445713,\n",
       " 7.3902354,\n",
       " 7.4866881,\n",
       " 7.5728607,\n",
       " 8.0613241,\n",
       " 7.522718,\n",
       " 7.0701203,\n",
       " 7.9917774,\n",
       " 7.2108765,\n",
       " 8.0044661,\n",
       " 7.5646515,\n",
       " 7.3726277,\n",
       " 8.0458431,\n",
       " 7.3845167,\n",
       " 7.8347735,\n",
       " 6.9095893,\n",
       " 7.6223292,\n",
       " 7.5052509,\n",
       " 6.8506494,\n",
       " 7.8775029,\n",
       " 7.4208956,\n",
       " 7.6815953,\n",
       " 7.2572842,\n",
       " 7.9888306,\n",
       " 7.2887959,\n",
       " 7.3586774,\n",
       " 6.9025025,\n",
       " 7.7800126,\n",
       " 7.7052016,\n",
       " 7.3886027,\n",
       " 7.3262315,\n",
       " 6.8747735,\n",
       " 7.4033546,\n",
       " 7.080822,\n",
       " 7.2093391,\n",
       " 7.3788104,\n",
       " 7.6795964,\n",
       " 7.3441033,\n",
       " 6.8913298,\n",
       " 7.1138444,\n",
       " 7.3790331,\n",
       " 7.2268915,\n",
       " 7.8918142,\n",
       " 7.4941387,\n",
       " 7.1603928,\n",
       " 7.6825871,\n",
       " 7.4396195,\n",
       " 6.9995036,\n",
       " 7.4148216,\n",
       " 7.4421268,\n",
       " 7.7171249,\n",
       " 7.0799437,\n",
       " 7.6675682,\n",
       " 7.5611529,\n",
       " 7.959888,\n",
       " 7.1628075,\n",
       " 7.7728152,\n",
       " 7.0886588,\n",
       " 7.4034791,\n",
       " 7.0937595,\n",
       " 6.7689004,\n",
       " 7.3562112,\n",
       " 7.7039628,\n",
       " 7.420763,\n",
       " 7.2183084,\n",
       " 7.9102216,\n",
       " 7.3837094,\n",
       " 7.7717748,\n",
       " 6.8676386,\n",
       " 7.5452366,\n",
       " 7.2831144,\n",
       " 7.0633245,\n",
       " 7.5900121,\n",
       " 7.5685596,\n",
       " 7.5322185,\n",
       " 7.8982925,\n",
       " 7.2015982,\n",
       " 7.4266987,\n",
       " 6.9339623,\n",
       " 7.2097049,\n",
       " 7.5071111,\n",
       " 7.1708031,\n",
       " 7.0089569,\n",
       " 7.9117289,\n",
       " 7.1600938,\n",
       " 7.8189063,\n",
       " 7.4111681,\n",
       " 7.5591388,\n",
       " 7.2881284,\n",
       " 7.6230235,\n",
       " 6.9064898,\n",
       " 7.8607502,\n",
       " 7.4380307,\n",
       " 7.2295585,\n",
       " 7.1295409,\n",
       " 7.4293175,\n",
       " 7.0703039,\n",
       " 7.5026441,\n",
       " 7.2669659,\n",
       " 7.0686336,\n",
       " 7.0994616,\n",
       " 7.1575327,\n",
       " 7.5641942,\n",
       " 7.4253216,\n",
       " 7.5823588,\n",
       " 7.2193203,\n",
       " 6.9826574,\n",
       " 7.4355803,\n",
       " 7.9412093,\n",
       " 6.9667687,\n",
       " 7.1420965,\n",
       " 7.3867874,\n",
       " 7.599719,\n",
       " 7.9527035,\n",
       " 7.7872777,\n",
       " 7.1022019,\n",
       " 8.0245323,\n",
       " 7.6288724,\n",
       " 7.1667647,\n",
       " 6.6804171,\n",
       " 7.2161107,\n",
       " 7.2391243,\n",
       " 7.4296856,\n",
       " 7.3718619,\n",
       " 7.0406084,\n",
       " 7.150176,\n",
       " 7.5903807,\n",
       " 7.2625771,\n",
       " 7.0559487,\n",
       " 7.2133241,\n",
       " 7.3239408,\n",
       " 7.2184319,\n",
       " 7.2862535,\n",
       " 7.1801977,\n",
       " 7.6034622,\n",
       " 7.1532521,\n",
       " 7.1811962,\n",
       " 7.2953868,\n",
       " 7.3041501,\n",
       " 6.9313388,\n",
       " 7.5786433,\n",
       " 7.2944779,\n",
       " 7.1617184,\n",
       " 7.3356743,\n",
       " 7.4733896,\n",
       " 7.782537,\n",
       " 7.6714091,\n",
       " 7.6085258,\n",
       " 6.8994279,\n",
       " 7.6898317,\n",
       " 7.2696371,\n",
       " 7.1261692,\n",
       " 7.6628618,\n",
       " 7.4906039,\n",
       " 7.6459751,\n",
       " 7.2161722,\n",
       " 7.2174082,\n",
       " 6.9367685,\n",
       " 7.1213198,\n",
       " 7.3360739,\n",
       " 7.2808661,\n",
       " 6.9959116,\n",
       " 7.1850662,\n",
       " 7.068006,\n",
       " 7.7212024,\n",
       " 7.9280787,\n",
       " 7.7702541,\n",
       " 7.0587373,\n",
       " 7.3976254,\n",
       " 7.6223035,\n",
       " 7.506454,\n",
       " 7.1715961,\n",
       " 7.1200309,\n",
       " 7.2367311,\n",
       " 7.2475181,\n",
       " 7.3768916,\n",
       " 7.2834115,\n",
       " 7.3526554,\n",
       " 7.2639518,\n",
       " 7.1795511,\n",
       " 7.6544161,\n",
       " 7.3410549,\n",
       " 7.3545589,\n",
       " 6.9921494,\n",
       " 7.9982748,\n",
       " 6.7458744,\n",
       " 7.2092762,\n",
       " 7.6126022,\n",
       " 7.638238,\n",
       " 7.5128541,\n",
       " 7.302969,\n",
       " 7.4012809,\n",
       " 7.4529805,\n",
       " 7.1712451,\n",
       " 7.2883596,\n",
       " 7.3711495,\n",
       " 7.4238729,\n",
       " 7.1656857,\n",
       " 7.1177945,\n",
       " 6.996202,\n",
       " 7.7449398,\n",
       " 7.5898271,\n",
       " 7.7185297,\n",
       " 7.5423055,\n",
       " 7.4147267,\n",
       " 8.0756979,\n",
       " 7.1138916,\n",
       " 7.3790107,\n",
       " 7.4544373,\n",
       " 7.4840064,\n",
       " 7.9123588,\n",
       " 6.9981089,\n",
       " 7.1291728,\n",
       " 7.8243942,\n",
       " 7.2650981,\n",
       " 7.4833364,\n",
       " 6.8162122,\n",
       " 7.2007599,\n",
       " 7.8388095,\n",
       " 7.3659134,\n",
       " 7.2984676,\n",
       " 7.7183371,\n",
       " 6.7658734,\n",
       " 7.0030837,\n",
       " 7.3729815,\n",
       " 7.0936527,\n",
       " 7.1309552,\n",
       " 7.7012663,\n",
       " 7.4158363,\n",
       " 7.5979314,\n",
       " 7.2551665,\n",
       " 7.0216599,\n",
       " 7.4436493,\n",
       " 7.4383316,\n",
       " 7.5736713,\n",
       " 7.6753168,\n",
       " 7.0162401,\n",
       " 7.5548506,\n",
       " 7.412673,\n",
       " 7.149179,\n",
       " 7.3186359,\n",
       " 7.4746456,\n",
       " 7.4984317,\n",
       " 7.397676,\n",
       " 6.9635463,\n",
       " 7.5861197,\n",
       " 7.5229483,\n",
       " 7.2700157,\n",
       " 7.0464406,\n",
       " 7.9696732,\n",
       " 6.9806595,\n",
       " 7.6428127,\n",
       " 7.1121106,\n",
       " 7.8483925,\n",
       " 7.3393459,\n",
       " 7.2148128,\n",
       " 7.6129732,\n",
       " 7.2847857,\n",
       " 7.2165461,\n",
       " 7.5591006,\n",
       " 7.322145,\n",
       " 7.4351745,\n",
       " 7.795002,\n",
       " 7.2613611,\n",
       " 7.4606233,\n",
       " 7.3792653,\n",
       " 6.8477097,\n",
       " 6.9111304,\n",
       " 7.6352973,\n",
       " 7.4878631,\n",
       " 7.176404,\n",
       " 7.5342903,\n",
       " 6.955863,\n",
       " 7.2837892,\n",
       " 7.1992311,\n",
       " 7.1627121,\n",
       " 7.2351575,\n",
       " 7.249876,\n",
       " 7.4254389,\n",
       " 7.4601703,\n",
       " 6.9948268,\n",
       " 7.5444393,\n",
       " 6.9594302,\n",
       " 7.2410603,\n",
       " 6.9400115,\n",
       " 7.2585707,\n",
       " 7.5296273,\n",
       " 7.1258545,\n",
       " 7.5017409,\n",
       " 7.496819,\n",
       " 7.4929309,\n",
       " 7.4644923,\n",
       " 7.0539098,\n",
       " 7.2232976,\n",
       " 7.1087027,\n",
       " 7.0683651,\n",
       " 7.3625574,\n",
       " 7.6975365,\n",
       " 7.7713637,\n",
       " 7.8187799,\n",
       " 7.1478987,\n",
       " 7.8279791,\n",
       " 6.9628592,\n",
       " 6.9004946,\n",
       " 7.1452031,\n",
       " 7.6342468,\n",
       " 7.7403584,\n",
       " 7.5891762,\n",
       " 7.9623456,\n",
       " 7.3371291,\n",
       " 7.4443135,\n",
       " 7.5005741,\n",
       " 7.4629779,\n",
       " 7.0768213,\n",
       " 7.2810845,\n",
       " 7.1144195,\n",
       " 7.3556976,\n",
       " 7.622613,\n",
       " 7.6945896,\n",
       " 7.3368511,\n",
       " 7.7635736,\n",
       " 7.3914652,\n",
       " 7.6115122,\n",
       " 7.5641904,\n",
       " 7.3438396,\n",
       " 6.9852796,\n",
       " 6.8625379,\n",
       " 6.8525419,\n",
       " 7.6316056,\n",
       " 7.3873644,\n",
       " 6.9180207,\n",
       " 7.1986871,\n",
       " 7.0546803,\n",
       " 7.4000697,\n",
       " 7.2714243,\n",
       " 7.5564628,\n",
       " 7.6858311,\n",
       " 7.781394,\n",
       " 7.1414275,\n",
       " 7.8239589,\n",
       " 7.6506486,\n",
       " 7.3941898,\n",
       " 7.731657,\n",
       " 7.3265843,\n",
       " 7.5771136,\n",
       " 7.691699,\n",
       " 7.5946527,\n",
       " 7.5884809,\n",
       " 7.2086682,\n",
       " 7.0764241,\n",
       " 7.5523181,\n",
       " 7.3507414,\n",
       " 6.9087062,\n",
       " 7.2327409,\n",
       " 7.6446004,\n",
       " 7.4352703,\n",
       " 7.511517,\n",
       " 7.3157969,\n",
       " 7.0348253,\n",
       " 7.5990901,\n",
       " 7.6715965,\n",
       " 7.2555017,\n",
       " 8.0008097,\n",
       " 7.9883075,\n",
       " 7.6371741,\n",
       " 7.6558795,\n",
       " 7.8712921,\n",
       " 7.070075,\n",
       " 7.2499084,\n",
       " 7.2302299,\n",
       " 7.4867382,\n",
       " 7.4712076,\n",
       " 7.547091,\n",
       " 7.1688972,\n",
       " 7.6012025,\n",
       " 7.7715845,\n",
       " 7.2080894,\n",
       " 7.5657182,\n",
       " 7.5334544,\n",
       " 8.3323488,\n",
       " 6.9462438,\n",
       " 7.2670002,\n",
       " 7.6960478,\n",
       " 7.4522352,\n",
       " 6.7858934,\n",
       " 7.4384246,\n",
       " 7.0788054,\n",
       " 7.6331925,\n",
       " 7.5215549,\n",
       " 7.7913289,\n",
       " 7.1101189,\n",
       " 7.3883128,\n",
       " 7.1364341,\n",
       " 7.671845,\n",
       " 6.9340754,\n",
       " 7.1163378,\n",
       " 7.2279558,\n",
       " 6.6392598,\n",
       " 7.5322046,\n",
       " 7.7317648,\n",
       " 7.5064983,\n",
       " 7.197237,\n",
       " 7.18995,\n",
       " 7.5159845,\n",
       " 6.7800183,\n",
       " 7.3915491,\n",
       " 6.5942211,\n",
       " 7.8929949,\n",
       " 7.9358196,\n",
       " 7.5196848,\n",
       " 7.2408714,\n",
       " 6.905695,\n",
       " 7.2275443,\n",
       " 7.6356187,\n",
       " 7.1161876,\n",
       " 7.0582581,\n",
       " 7.8101916,\n",
       " 7.0237012,\n",
       " 7.3115892,\n",
       " 7.7205272,\n",
       " 7.3324823,\n",
       " 7.7713137,\n",
       " 7.0041223,\n",
       " 7.2753148,\n",
       " 7.1716876,\n",
       " 7.4340701,\n",
       " 7.6903057,\n",
       " 7.6930323,\n",
       " 7.3022771,\n",
       " 7.1673441,\n",
       " 7.5788074,\n",
       " 7.4863877,\n",
       " 7.4136343,\n",
       " 7.1822839,\n",
       " 7.0388727,\n",
       " 7.3259554,\n",
       " 7.1482587,\n",
       " 7.5187149,\n",
       " 7.3078971,\n",
       " 7.3657618,\n",
       " 7.5780692,\n",
       " 7.5153098,\n",
       " 7.3278341,\n",
       " 7.3833313,\n",
       " 7.4154143,\n",
       " 7.4598618,\n",
       " 7.4457684,\n",
       " 6.6144414,\n",
       " 7.8111029,\n",
       " 7.178041,\n",
       " 7.4135013,\n",
       " 8.4854641,\n",
       " 6.9983172,\n",
       " 7.0245676,\n",
       " 7.0315423,\n",
       " 7.609117,\n",
       " 7.5731683,\n",
       " 7.9098544,\n",
       " 7.081286,\n",
       " 7.0088487,\n",
       " 7.7635632,\n",
       " 7.4954748,\n",
       " 7.2694383,\n",
       " 7.5185509,\n",
       " 7.1674576,\n",
       " 7.9542503,\n",
       " 7.5195956,\n",
       " 7.6318178,\n",
       " 6.9910345,\n",
       " 7.8826041,\n",
       " 7.510169,\n",
       " 7.10778,\n",
       " 7.2834258,\n",
       " 7.1753359,\n",
       " 7.599009,\n",
       " 7.3825469,\n",
       " 7.8064556,\n",
       " 7.648602,\n",
       " 6.9700942,\n",
       " 7.3396301,\n",
       " 6.9696741,\n",
       " 7.3843017,\n",
       " 7.6015282,\n",
       " 7.3302135,\n",
       " 6.9552197,\n",
       " 6.9127135,\n",
       " 7.573494,\n",
       " 7.2390909,\n",
       " 7.1639185,\n",
       " 7.2694287,\n",
       " 7.5702353,\n",
       " 7.4010706,\n",
       " 7.3134646,\n",
       " 7.142673,\n",
       " 7.1571946,\n",
       " 7.7227359,\n",
       " 7.5615816,\n",
       " 7.1228952,\n",
       " 7.4324169,\n",
       " 7.1108899,\n",
       " 7.9566941,\n",
       " 7.8416662,\n",
       " 7.3418984,\n",
       " 7.32901,\n",
       " 7.0321779,\n",
       " 7.9217877,\n",
       " 7.0875859,\n",
       " 7.2733088,\n",
       " 7.3124857,\n",
       " 7.558764,\n",
       " 7.5519137,\n",
       " 7.1142206,\n",
       " 7.4977026,\n",
       " 6.9708962,\n",
       " 6.6713052,\n",
       " 7.2551336,\n",
       " 8.2025251,\n",
       " 6.9012561,\n",
       " 7.0779166,\n",
       " 6.7907853,\n",
       " 7.2080951,\n",
       " 7.9171672,\n",
       " 7.2260394,\n",
       " 7.608151,\n",
       " 7.1248236,\n",
       " 7.8375735,\n",
       " 7.2634287,\n",
       " 6.9431214,\n",
       " 7.4461718,\n",
       " 7.335701,\n",
       " 8.2496605,\n",
       " 7.7736735,\n",
       " 7.5637503,\n",
       " 6.8724465,\n",
       " 7.6592302,\n",
       " 8.0070486,\n",
       " 6.8989263,\n",
       " 7.9307284,\n",
       " 7.4387436,\n",
       " 6.8813658,\n",
       " 7.5582991,\n",
       " 7.056644,\n",
       " 6.8478303,\n",
       " 7.6220183,\n",
       " 6.9721546,\n",
       " 7.6179738,\n",
       " 7.5282168,\n",
       " 7.3521342,\n",
       " 8.2150936,\n",
       " 7.50418,\n",
       " 7.8004007,\n",
       " 7.1936316,\n",
       " 7.3557591,\n",
       " 7.3394389,\n",
       " 6.7035203,\n",
       " 7.3834705,\n",
       " 6.7457328,\n",
       " 7.4950423,\n",
       " 6.9856868,\n",
       " 7.0433183,\n",
       " 7.2188158,\n",
       " 7.3127432,\n",
       " 7.6971397,\n",
       " 7.5222902,\n",
       " 7.4001713,\n",
       " 7.8633208,\n",
       " 7.3457885,\n",
       " 7.632967,\n",
       " 7.252924,\n",
       " 7.0040407,\n",
       " 6.6712141,\n",
       " 7.1925731,\n",
       " 8.1682358,\n",
       " 7.1186314,\n",
       " 7.0895381,\n",
       " 7.7347169,\n",
       " 6.6368093,\n",
       " 7.489171,\n",
       " 7.4668431,\n",
       " 8.1987906,\n",
       " 7.0427604,\n",
       " 7.2768855,\n",
       " 7.7361417,\n",
       " 6.9966788,\n",
       " 7.7557921,\n",
       " 7.693007,\n",
       " 7.1513205,\n",
       " 7.1735196,\n",
       " 7.221662,\n",
       " 7.0614257,\n",
       " 7.3141303,\n",
       " 7.7812662,\n",
       " 7.6336503,\n",
       " 6.9875841,\n",
       " 7.6319003,\n",
       " 7.6929145,\n",
       " 7.4128761,\n",
       " 7.2444463,\n",
       " 7.3015018,\n",
       " 7.5644593,\n",
       " 7.7493801,\n",
       " 7.1689286,\n",
       " 7.623497,\n",
       " 7.9190273,\n",
       " 7.2515011,\n",
       " 7.3990722,\n",
       " 7.2564144,\n",
       " 7.4773207,\n",
       " 7.4541788,\n",
       " 7.1585002,\n",
       " 7.3628135,\n",
       " 7.0417795,\n",
       " 6.8607125,\n",
       " 7.2927408,\n",
       " 7.6042137,\n",
       " 7.3585,\n",
       " 7.5362391,\n",
       " 7.3991857,\n",
       " 7.2951069,\n",
       " 7.1634517,\n",
       " 7.3283763,\n",
       " 6.8988128,\n",
       " 6.8146424,\n",
       " 7.7084022,\n",
       " 7.3136253,\n",
       " 6.8746705,\n",
       " 7.5673399,\n",
       " 7.575325,\n",
       " 7.6536522,\n",
       " 7.5824533,\n",
       " 8.0728579,\n",
       " 7.2779708,\n",
       " 7.3149319,\n",
       " 6.8046474,\n",
       " 7.7965665,\n",
       " 7.3037367,\n",
       " 7.32797,\n",
       " 7.4681778,\n",
       " 7.4332218,\n",
       " 7.2396879,\n",
       " 7.2141881,\n",
       " 7.6242232,\n",
       " 7.3260183,\n",
       " 7.3572526,\n",
       " 7.5029063,\n",
       " 7.1373396,\n",
       " 6.7167454,\n",
       " 7.6240973,\n",
       " 7.4778156,\n",
       " 8.1090574,\n",
       " 6.9426827,\n",
       " 7.0013151,\n",
       " 7.1307149,\n",
       " 7.364893,\n",
       " 6.9050231,\n",
       " 7.4042678,\n",
       " 7.4951124,\n",
       " 7.6301169,\n",
       " 7.1505103,\n",
       " 6.727582,\n",
       " 7.4637227,\n",
       " 7.5276532,\n",
       " 7.4030099,\n",
       " 7.3674927,\n",
       " 7.1673932,\n",
       " 7.1059442,\n",
       " 7.2302837,\n",
       " 7.4138818,\n",
       " 7.7154431,\n",
       " 7.3037052,\n",
       " 7.2936482,\n",
       " 7.4398623,\n",
       " 7.6629024,\n",
       " 7.6399074,\n",
       " 7.315167,\n",
       " 7.2181692,\n",
       " 7.4719763,\n",
       " 7.6434493,\n",
       " 7.3519254,\n",
       " 7.4102774,\n",
       " 6.8665247,\n",
       " 7.8931332,\n",
       " 6.8407559,\n",
       " 7.5050368,\n",
       " 7.2820253,\n",
       " 7.5175819,\n",
       " 7.5839181,\n",
       " 7.3342514,\n",
       " 7.4747715,\n",
       " 6.8478293,\n",
       " 7.6744909,\n",
       " 7.6385603,\n",
       " 7.5048542,\n",
       " 7.3479977,\n",
       " 7.2620673,\n",
       " 7.5235844,\n",
       " 7.4834003,\n",
       " 7.2369208,\n",
       " 7.6079993,\n",
       " 7.3846393,\n",
       " 7.0986166,\n",
       " 7.7610354,\n",
       " 7.464602,\n",
       " 7.495697,\n",
       " 7.7401438,\n",
       " 7.6624017,\n",
       " 6.9466882,\n",
       " 7.5109549,\n",
       " 7.2937469,\n",
       " 6.7995005,\n",
       " 7.4494667,\n",
       " 7.4776993,\n",
       " 7.2981815,\n",
       " 7.4460816,\n",
       " 7.3376307,\n",
       " 7.4687185,\n",
       " 7.8831306,\n",
       " 7.0085883,\n",
       " 7.2891955,\n",
       " 7.6330819,\n",
       " 6.9950771,\n",
       " 7.8266268,\n",
       " 7.4543328,\n",
       " 7.3366494,\n",
       " 7.2915468,\n",
       " 6.5928712,\n",
       " 7.8885708,\n",
       " 6.8719673,\n",
       " 7.0433483,\n",
       " 7.0786667,\n",
       " 7.1635566,\n",
       " 7.2210231,\n",
       " 6.9585867,\n",
       " 6.9537945,\n",
       " 7.1884637,\n",
       " 7.0715518,\n",
       " 7.8683639,\n",
       " 7.4112625,\n",
       " 7.6501436,\n",
       " 7.3984222,\n",
       " 7.1177044,\n",
       " 7.1490173,\n",
       " 7.345726,\n",
       " 7.2279286,\n",
       " 7.1330547,\n",
       " 7.638545,\n",
       " 6.8941293,\n",
       " 7.6009045,\n",
       " 7.0998445,\n",
       " 7.5438666,\n",
       " 7.4444528,\n",
       " 7.0528336,\n",
       " 7.4840732,\n",
       " 7.408844,\n",
       " 7.659585,\n",
       " 7.4042311,\n",
       " 7.3842258,\n",
       " 7.7434244,\n",
       " 7.0721817,\n",
       " 7.7425451,\n",
       " 7.4920883,\n",
       " 7.116806,\n",
       " 7.579361,\n",
       " 7.2499118,\n",
       " 7.1853976,\n",
       " 7.3042307,\n",
       " 7.4550362,\n",
       " 8.1287546,\n",
       " 7.6134639,\n",
       " 7.8518538,\n",
       " 7.2845807,\n",
       " 7.2579103,\n",
       " 7.39289,\n",
       " 6.6536031,\n",
       " 7.4404664,\n",
       " 7.2365513,\n",
       " 7.4089847,\n",
       " 6.8425541,\n",
       " 7.3644948,\n",
       " 6.7248921,\n",
       " 7.2353272,\n",
       " 7.4833069,\n",
       " 7.0330625,\n",
       " 7.3376875,\n",
       " 7.6230698,\n",
       " 6.8168716,\n",
       " 7.1445546,\n",
       " 7.6117063,\n",
       " 7.1474957,\n",
       " 7.7135153,\n",
       " 7.223403,\n",
       " 7.6139493,\n",
       " 7.3814893,\n",
       " 7.2235055,\n",
       " 7.5743012,\n",
       " 7.6191244,\n",
       " 7.6980495,\n",
       " 7.2337966,\n",
       " 7.7713795,\n",
       " 7.2033076,\n",
       " 7.0865459,\n",
       " 7.5831904,\n",
       " 7.225317,\n",
       " 7.1741719,\n",
       " 7.5746274,\n",
       " 7.1849074,\n",
       " 7.1675949,\n",
       " 7.5687337,\n",
       " 7.4218354,\n",
       " 7.385294,\n",
       " 7.9289465,\n",
       " 6.9819279,\n",
       " 7.3296623,\n",
       " 7.68859,\n",
       " 7.8208318,\n",
       " 7.265696,\n",
       " 7.3171644,\n",
       " 6.9664855,\n",
       " 7.8278761,\n",
       " 7.4949975,\n",
       " 7.3730788,\n",
       " 6.9759669,\n",
       " 7.5471058,\n",
       " 7.7309914,\n",
       " 7.5771546,\n",
       " 7.0326881,\n",
       " 7.4024563,\n",
       " 7.1286492,\n",
       " 7.6157174,\n",
       " 6.9027247,\n",
       " 7.1319728,\n",
       " 7.5593286,\n",
       " 7.0970702,\n",
       " 7.2772956,\n",
       " 7.4311781,\n",
       " 7.0400295,\n",
       " 7.7340693,\n",
       " 7.4344025,\n",
       " 7.6006708,\n",
       " 7.1685228,\n",
       " 7.7511992,\n",
       " 7.0163631,\n",
       " 7.94138,\n",
       " 6.9334359,\n",
       " 7.5032177,\n",
       " 6.914588,\n",
       " 7.3920884,\n",
       " 7.0152173,\n",
       " 7.3951654,\n",
       " 7.4406624,\n",
       " 7.0337553,\n",
       " 7.5525389,\n",
       " 6.942409,\n",
       " 6.9583964,\n",
       " 7.9643693,\n",
       " 7.414753,\n",
       " 7.6066985,\n",
       " 6.7915206,\n",
       " 7.2546277,\n",
       " 7.6294079,\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05, 0.05, 0.05, 0.1, 0.1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46531563784031454,\n",
       " 0.44781595830271975,\n",
       " 0.48591363878800875,\n",
       " 0.4691980017305285,\n",
       " 0.48949742574814081]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
