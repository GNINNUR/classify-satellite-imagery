{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0-rc1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Uses tf.contrib.data module which is in release candidate 1.2.0rc0\n",
    "Based on:\n",
    "    - PyTorch example from Justin Johnson:\n",
    "      https://gist.github.com/jcjohnson/6e41e8512c17eae5da50aebef3378a4c\n",
    "      - https://gist.github.com/omoindrot/dedc857cdc0e680dfb1be99762990c9c\n",
    "Required packages: tensorflow (v1.2)\n",
    "You can install the release candidate 1.2.0rc0 here:\n",
    "https://www.tensorflow.org/versions/r1.2/install/\n",
    "\n",
    "Download the weights trained on ImageNet for VGG:\n",
    "```\n",
    "wget http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz\n",
    "tar -xvf vgg_16_2016_08_28.tar.gz\n",
    "rm vgg_16_2016_08_28.tar.gz\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "\n",
    "from vggnet_utils import *\n",
    "\n",
    "VGG_MEAN = [123.68, 116.78, 103.94]\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu(x, alpha=0.01):\n",
    "    \"\"\"Compute the leaky ReLU activation function.\n",
    "    \n",
    "    Inputs:\n",
    "    - x: TensorFlow Tensor with arbitrary shape\n",
    "    - alpha: leak parameter for leaky ReLU\n",
    "    \n",
    "    Returns:\n",
    "    TensorFlow Tensor with the same shape as x\n",
    "    \"\"\"\n",
    "    # TODO: implement leaky ReLU\n",
    "    return(tf.maximum((alpha*x), x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:00<00:00, 415168.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dp': 0.4, 'lr1': 0.001, 'lr2': 1e-05, 'wd': 0.0001}]\n",
      "listed\n",
      "{'dp': 0.4, 'lr1': 0.001, 'lr2': 1e-05, 'wd': 0.0001}\n",
      "(?, 13, 13, 64)\n",
      "WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'dict' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'dict' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 1\n",
      "Current loss: 8.667623\n",
      "thresh: 0.050000, max F: 0.493058\n",
      "Current loss: 8.979131\n",
      "thresh: 0.500000, max F: 0.621919\n",
      "Current loss: 8.129011\n",
      "thresh: 0.500000, max F: 0.580693\n",
      "Current loss: 7.958862\n",
      "thresh: 0.500000, max F: 0.571616\n",
      "Current loss: 7.986983\n",
      "thresh: 0.500000, max F: 0.579042\n",
      "Current loss: 8.468454\n",
      "thresh: 0.500000, max F: 0.586938\n",
      "Current loss: 7.986660\n",
      "thresh: 0.500000, max F: 0.589358\n",
      "Current loss: 7.419818\n",
      "thresh: 0.500000, max F: 0.563082\n",
      "Current loss: 8.382886\n",
      "thresh: 0.500000, max F: 0.599135\n",
      "Current loss: 8.269392\n",
      "thresh: 0.500000, max F: 0.591613\n",
      "Current loss: 8.665930\n",
      "thresh: 0.500000, max F: 0.591004\n",
      "Current loss: 8.495670\n",
      "thresh: 0.500000, max F: 0.592419\n",
      "Current loss: 9.147067\n",
      "thresh: 0.500000, max F: 0.614040\n",
      "Current loss: 8.863603\n",
      "thresh: 0.500000, max F: 0.597990\n",
      "Current loss: 8.240089\n",
      "thresh: 0.500000, max F: 0.593044\n",
      "Current loss: 8.636561\n",
      "thresh: 0.500000, max F: 0.592481\n",
      "Current loss: 8.211617\n",
      "thresh: 0.500000, max F: 0.599412\n",
      "Current loss: 8.097915\n",
      "thresh: 0.500000, max F: 0.594474\n",
      "Current loss: 8.607780\n",
      "thresh: 0.500000, max F: 0.616537\n",
      "Current loss: 8.210943\n",
      "thresh: 0.500000, max F: 0.594836\n",
      "Current loss: 8.522420\n",
      "thresh: 0.500000, max F: 0.614521\n",
      "Current loss: 8.068851\n",
      "thresh: 0.500000, max F: 0.587926\n",
      "Current loss: 8.436934\n",
      "thresh: 0.500000, max F: 0.604177\n",
      "Current loss: 9.088345\n",
      "thresh: 0.500000, max F: 0.631061\n",
      "Current loss: 8.210053\n",
      "thresh: 0.500000, max F: 0.606938\n",
      "Current loss: 8.804680\n",
      "thresh: 0.500000, max F: 0.614911\n",
      "Current loss: 8.521464\n",
      "thresh: 0.500000, max F: 0.598390\n",
      "Current loss: 8.124322\n",
      "thresh: 0.500000, max F: 0.602465\n",
      "Current loss: 8.577392\n",
      "thresh: 0.500000, max F: 0.605684\n",
      "Current loss: 8.180672\n",
      "thresh: 0.500000, max F: 0.600693\n",
      "Current loss: 8.265377\n",
      "thresh: 0.500000, max F: 0.592421\n",
      "Current loss: 8.293719\n",
      "thresh: 0.500000, max F: 0.606797\n",
      "Current loss: 8.350175\n",
      "thresh: 0.500000, max F: 0.603176\n",
      "Current loss: 8.038915\n",
      "thresh: 0.500000, max F: 0.560731\n",
      "Current loss: 7.953069\n",
      "thresh: 0.500000, max F: 0.586972\n",
      "Current loss: 7.924973\n",
      "thresh: 0.500000, max F: 0.596572\n",
      "Current loss: 8.066258\n",
      "thresh: 0.500000, max F: 0.592408\n",
      "Current loss: 8.349531\n",
      "thresh: 0.500000, max F: 0.579039\n",
      "Current loss: 8.915733\n",
      "thresh: 0.500000, max F: 0.605864\n",
      "Current loss: 8.178852\n",
      "thresh: 0.500000, max F: 0.622223\n",
      "Current loss: 8.263517"
     ]
    }
   ],
   "source": [
    "experiments = [] # list with dict of params for each experiment\n",
    "\n",
    "lr1s = [1e-3] # 5e-5, \n",
    "lr2s = [1e-5] # 1e-6, 1e-7, \n",
    "dropout_probs = [0.4] # 0.5, 0.3\n",
    "weight_decays = [1e-4] # 5e-4, \n",
    "\n",
    "# create a dict of experiments\n",
    "for lr1 in lr1s:\n",
    "    for lr2 in lr2s:\n",
    "        for dp in dropout_probs:\n",
    "            for wd in weight_decays:\n",
    "                experiments.append({'lr1': lr1, 'lr2': lr2, 'dp': dp, 'wd': wd})\n",
    "\n",
    "print(experiments)\n",
    "\n",
    "\n",
    "# Get the list of filenames and corresponding list of labels for training et validation\n",
    "# train_filenames, train_labels = list_images(args.train_dir)\n",
    "# val_filenames, val_labels = list_images(args.val_dir)\n",
    "\n",
    "all_filenames, all_labels = list_images(args.train_dir)\n",
    "\n",
    "train_filenames, train_labels, val_filenames, val_labels = split_samples(all_filenames, all_labels)\n",
    "\n",
    "num_classes = 17\n",
    "num_val = len(val_labels)\n",
    "    \n",
    "# Training log\n",
    "loss_log = []\n",
    "f_log = []\n",
    "thresh_log = []\n",
    "predicted_logits = []\n",
    "actual_labels = []\n",
    "\n",
    "for params_dict in experiments:\n",
    "    print(params_dict)\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train_dir', default='data/train-jpg/')\n",
    "    parser.add_argument('--model_path', default='vgg_16.ckpt', type=str)\n",
    "    parser.add_argument('--batch_size', default=100, type=int) #32\n",
    "    parser.add_argument('--num_workers', default=50, type=int) #4\n",
    "    parser.add_argument('--num_epochs1', default=1, type=int) #10\n",
    "    parser.add_argument('--num_epochs2', default=1, type=int) #10\n",
    "    parser.add_argument('--learning_rate1', default = params_dict['lr1'], type=float) #1e-3\n",
    "    parser.add_argument('--learning_rate2', default = params_dict['lr2'], type=float)\n",
    "    parser.add_argument('--dropout_keep_prob', default = params_dict['dp'], type=float)\n",
    "    parser.add_argument('--weight_decay', default = params_dict['wd'], type=float)\n",
    "    \n",
    "    # For accessing args in an ipython notebook\n",
    "    import sys; sys.argv=['']; del sys\n",
    "    args = parser.parse_args()\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # In TensorFlow, you first want to define the computation graph with all the\n",
    "    # necessary operations: loss, training op, accuracy...\n",
    "    # Any tensor created in the `graph.as_default()` scope will be part of `graph`\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # Standard preprocessing for VGG on ImageNet taken from here:\n",
    "        # https://github.com/tensorflow/models/blob/master/slim/preprocessing/vgg_preprocessing.py\n",
    "        # Also see the VGG paper for more details: https://arxiv.org/pdf/1409.1556.pdf\n",
    "    \n",
    "        # Preprocessing (for both training and validation):\n",
    "        # (1) Decode the image from jpg format\n",
    "        # (2) Resize the image so its smaller side is 256 pixels long\n",
    "        def _parse_function(filename, label):\n",
    "            image_string = tf.read_file(filename)\n",
    "            image_decoded = tf.image.decode_jpeg(image_string, channels=3)          # (1)\n",
    "            image = tf.cast(image_decoded, tf.float32)\n",
    "    \n",
    "            smallest_side = 256.0\n",
    "            height, width = tf.shape(image)[0], tf.shape(image)[1]\n",
    "            height = tf.to_float(height)\n",
    "            width = tf.to_float(width)\n",
    "    \n",
    "            scale = tf.cond(tf.greater(height, width),\n",
    "                            lambda: smallest_side / width,\n",
    "                             lambda: smallest_side / height)\n",
    "            new_height = tf.to_int32(height * scale)\n",
    "            new_width = tf.to_int32(width * scale)\n",
    "    \n",
    "            resized_image = tf.image.resize_images(image, [new_height, new_width])  # (2)\n",
    "            return resized_image, label\n",
    "\n",
    "        # Preprocessing (for training)\n",
    "        # (3) Take a random 224x224 crop to the scaled image\n",
    "        # (4) Horizontally flip the image with probability 1/2\n",
    "        # (5) Substract the per color mean `VGG_MEAN`\n",
    "        # Note: we don't normalize the data here, as VGG was trained without normalization\n",
    "        def training_preprocess(image, label):\n",
    "            crop_image = tf.random_crop(image, [224, 224, 3])                       # (3)\n",
    "            flip_image = tf.image.random_flip_left_right(crop_image)                # (4)\n",
    "    \n",
    "            means = tf.reshape(tf.constant(VGG_MEAN), [1, 1, 3])\n",
    "            centered_image = flip_image - means                                     # (5)\n",
    "    \n",
    "            return centered_image, label\n",
    "    \n",
    "        # Preprocessing (for validation)\n",
    "        # (3) Take a central 224x224 crop to the scaled image\n",
    "        # (4) Substract the per color mean `VGG_MEAN`\n",
    "        # Note: we don't normalize the data here, as VGG was trained without normalization\n",
    "        def val_preprocess(image, label):\n",
    "            crop_image = tf.image.resize_image_with_crop_or_pad(image, 224, 224)    # (3)\n",
    "    \n",
    "            means = tf.reshape(tf.constant(VGG_MEAN), [1, 1, 3])\n",
    "            centered_image = crop_image - means                                     # (4)\n",
    "    \n",
    "            return centered_image, label\n",
    "    \n",
    "            # ----------------------------------------------------------------------\n",
    "            # DATASET CREATION using tf.contrib.data.Dataset\n",
    "            # https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data\n",
    "        \n",
    "            # The tf.contrib.data.Dataset framework uses queues in the background to feed in\n",
    "            # data to the model.\n",
    "            # We initialize the dataset with a list of filenames and labels, and then apply\n",
    "        # the preprocessing functions described above.\n",
    "        # Behind the scenes, queues will load the filenames, preprocess them with multiple\n",
    "        # threads and apply the preprocessing in parallel, and then batch the data\n",
    "    \n",
    "        # Training dataset\n",
    "        train_filenames = tf.constant(train_filenames)\n",
    "        train_labels = tf.constant(train_labels)\n",
    "        train_dataset = tf.contrib.data.Dataset.from_tensor_slices((train_filenames, train_labels))\n",
    "        train_dataset = train_dataset.map(_parse_function,\n",
    "           num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        train_dataset = train_dataset.map(training_preprocess,\n",
    "           num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=10000)  # don't forget to shuffle\n",
    "        batched_train_dataset = train_dataset.batch(args.batch_size)\n",
    "    \n",
    "        # Validation dataset\n",
    "        val_filenames = tf.constant(val_filenames)\n",
    "        val_labels = tf.constant(val_labels)\n",
    "        val_dataset = tf.contrib.data.Dataset.from_tensor_slices((val_filenames, val_labels))\n",
    "        val_dataset = val_dataset.map(_parse_function,\n",
    "        num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        val_dataset = val_dataset.map(val_preprocess,\n",
    "        num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        batched_val_dataset = val_dataset.batch(args.batch_size)\n",
    "\n",
    "        # Now we define an iterator that can operator on either dataset.\n",
    "        # The iterator can be reinitialized by calling:\n",
    "        #     - sess.run(train_init_op) for 1 epoch on the training set\n",
    "        #     - sess.run(val_init_op)   for 1 epoch on the valiation set\n",
    "        # Once this is done, we don't need to feed any value for images and labels\n",
    "        # as they are automatically pulled out from the iterator queues.\n",
    "    \n",
    "        # A reinitializable iterator is defined by its structure. We could use the\n",
    "        # `output_types` and `output_shapes` properties of either `train_dataset`\n",
    "        # or `validation_dataset` here, because they are compatible.\n",
    "        iterator = tf.contrib.data.Iterator.from_structure(batched_train_dataset.output_types,\n",
    "                                                           batched_train_dataset.output_shapes)\n",
    "        images, labels = iterator.get_next()\n",
    "        train_init_op = iterator.make_initializer(batched_train_dataset)\n",
    "        val_init_op = iterator.make_initializer(batched_val_dataset)\n",
    "    \n",
    "        # Indicates whether we are in training or in test mode\n",
    "        is_training = tf.placeholder(tf.bool)\n",
    "    \n",
    "        # ---------------------------------------------------------------------\n",
    "        # Now that we have set up the data, it's time to set up the model.\n",
    "        # For this example, we'll use VGG-16 pretrained on ImageNet. We will remove the\n",
    "        # last fully connected layer (fc8) and replace it with our own, with an\n",
    "        # output size num_classes=8\n",
    "        # We will first train the last layer for a few epochs.\n",
    "        # Then we will train the entire model on our dataset for a few epochs.\n",
    "    \n",
    "        # Get the pretrained model, specifying the num_classes argument to create a new\n",
    "        # fully connected replacing the last one, called \"vgg_16/fc8\"\n",
    "        # Each model has a different architecture, so \"vgg_16/fc8\" will change in another model.\n",
    "        # Here, logits gives us directly the predicted scores we wanted from the images.\n",
    "        # We pass a scope to initialize \"vgg_16/fc8\" weights with he_initializer\n",
    "        vgg = tf.contrib.slim.nets.vgg\n",
    "        with slim.arg_scope(vgg.vgg_arg_scope(weight_decay=args.weight_decay)):\n",
    "            _, layers = vgg.vgg_16(images, num_classes=num_classes, is_training=is_training,\n",
    "                                       dropout_keep_prob=args.dropout_keep_prob)\n",
    "            # _ output logits\n",
    "        # add some extra layers after fc6\n",
    "        # Out of the arg scope\n",
    "        vgg_fc6_tensor = layers['vgg_16/fc6']\n",
    "        # print(vgg_fc6_tensor.shape)\n",
    "\n",
    "        with tf.variable_scope(\"extra_layers\"):\n",
    "            extra_fc1 = tf.layers.dense(vgg_fc6_tensor, 4096, name=\"extra_fc1\", activation = tf.nn.relu, trainable = True) #1024\n",
    "            extra_bn1 = tf.layers.batch_normalization(extra_fc1, axis = -1, training=True, name = \"extra_bn1\")\n",
    "            extra_conv1 = tf.layers.conv2d(tf.reshape(extra_bn1, shape = [-1, 64, 64, 1]), filters = 32, kernel_size = [5, 5],\n",
    "                                 strides = 1, activation = leaky_relu, name = \"extra_conv1\")\n",
    "            extra_pool1 = tf.layers.max_pooling2d(extra_conv1, pool_size = [2, 2], strides = 2, name = \"extra_pool1\")\n",
    "            extra_conv2 = tf.layers.conv2d(extra_pool1, filters = 64, kernel_size = [5, 5],\n",
    "                                 strides = 1, activation = leaky_relu, name = \"extra_conv2\")\n",
    "            extra_pool2 = tf.layers.max_pooling2d(extra_conv2, pool_size = [2, 2], strides = 2, name = \"extra_pool2\")\n",
    "            print(extra_pool2.shape)\n",
    "            extra_pool2_flat = tf.reshape(extra_pool2, [-1, 13*13*64], name = \"extra_pool2_flat\")\n",
    "            extra_conn1 = tf.layers.dense(extra_pool2_flat, units = 13*13*64, activation = leaky_relu, name = \"extra_conn1\")\n",
    "            logits = tf.layers.dense(extra_conn1, num_classes, name=\"logits\", activation = tf.sigmoid, trainable = True)\n",
    "\n",
    "            # extra_fc2 = tf.layers.dense(extra_fc1, 1024, name=\"extra_fc2\", trainable = True)\n",
    "            # extra_fc3 = tf.layers.dense(extra_fc2, 1024, name=\"extra_fc3\", trainable = True)\n",
    "            # extra_fc4 = tf.layers.dense(extra_fc3, 256, name=\"extra_fc4\", trainable = True)\n",
    "            # logits = tf.layers.dense(extra_fc4, num_classes, name=\"logits\", activation = tf.sigmoid, trainable = True)\n",
    "    \n",
    "        # Specify where the model checkpoint is (pretrained weights).\n",
    "        model_path = args.model_path\n",
    "        assert(os.path.isfile(model_path))\n",
    "    \n",
    "        # Restore only the layers up to fc6 (included)\n",
    "        # Calling function `init_fn(sess)` will load all the pretrained weights.\n",
    "        variables_to_restore = tf.contrib.framework.get_variables_to_restore(exclude=['vgg_16/fc8', 'vgg_16/fc7', \n",
    "                                                                                      \"extra_layers/extra_fc1\",\n",
    "                                                                                      \"extra_layers/extra_fc1\", \n",
    "                                                                                      \"extra_layers/extra_bn1\", \n",
    "                                                                                      \"extra_layers/extra_conv1\", \n",
    "                                                                                      \"extra_layers/extra_pool1\", \n",
    "                                                                                      \"extra_layers/extra_conv2\", \n",
    "                                                                                      \"extra_layers/extra_pool2\",\n",
    "                                                                                      \"extra_layers/extra_pool2_flat\",\n",
    "                                                                                      \"extra_layers/extra_conn1\",\n",
    "                                                                                     # \"extra_layers/extra_fc2\",\n",
    "                                                                                     # \"extra_layers/extra_fc3\",\n",
    "                                                                                     # \"extra_layers/extra_fc4\",\n",
    "                                                                                     # \"extra_layers/extra_fc5\",\n",
    "                                                                                     # \"extra_layers/extra_fc6\",\n",
    "                                                                                      \"extra_layers/logits\"]) #, 'vgg_16/fc6'])\n",
    "        init_fn = tf.contrib.framework.assign_from_checkpoint_fn(model_path, variables_to_restore)\n",
    "    \n",
    "        # Initialization operation from scratch for the new \"fc6\" layers\n",
    "        # `get_variables` will only return the variables whose name starts with the given pattern\n",
    "        # fc6_variables = tf.contrib.framework.get_variables('vgg_16/fc6')\n",
    "        # fc6_init = tf.variables_initializer(fc6_variables)\n",
    "        \n",
    "        # Initialization operation from scratch for the new \"fc7\" layers\n",
    "        # `get_variables` will only return the variables whose name starts with the given pattern\n",
    "        fc7_variables = tf.contrib.framework.get_variables('vgg_16/fc7')\n",
    "        fc7_init = tf.variables_initializer(fc7_variables)\n",
    "        \n",
    "        # Initialization operation from scratch for the new \"fc8\" layers\n",
    "        # `get_variables` will only return the variables whose name starts with the given pattern\n",
    "        fc8_variables = tf.contrib.framework.get_variables('vgg_16/fc8')\n",
    "        fc8_init = tf.variables_initializer(fc8_variables)\n",
    "        \n",
    "        # Initialize extra layer variables\n",
    "        extras_init = tf.variables_initializer(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'extra*'))\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # Using tf.losses, any loss is added to the tf.GraphKeys.LOSSES collection\n",
    "        # We can then call the total loss easily\n",
    "        # tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits) \n",
    "        \n",
    "        tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=tf.reshape(logits, shape = [-1, num_classes])) # softmax cross entropy loss so can have labels with multiple classes\n",
    "        loss = tf.losses.get_total_loss()\n",
    "        \n",
    "        tf.summary.scalar(\"loss\", loss) # log the loss in summary\n",
    "    \n",
    "        # First we want to train only the reinitialized last layer fc8 for a few epochs.\n",
    "        # We run minimize the loss only with respect to the fc8 variables (weight and bias).\n",
    "        # fc876_optimizer = tf.train.GradientDescentOptimizer(args.learning_rate1)\n",
    "        # fc876_train_op = fc876_optimizer.minimize(loss, var_list=[fc8_variables, fc7_variables, fc6_variables])\n",
    "    \n",
    "    \n",
    "        # First we want to train only the last extra layers for a few epochs.\n",
    "        # We minimize the loss only with respect to the extra variables (weight and bias).\n",
    "        extra_optimizer = tf.train.GradientDescentOptimizer(args.learning_rate1)\n",
    "        extra_train_op = extra_optimizer.minimize(loss, var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'extra*')) # [logits, extra_fc1, extra_fc2]) ### fc8_variables, fc7_variables])\n",
    "        # print(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'extra*'))\n",
    "        \n",
    "        \n",
    "        # Then we want to finetune the entire model for a few epochs.\n",
    "        # We run minimize the loss only with respect to all the variables.\n",
    "        full_optimizer = tf.train.GradientDescentOptimizer(args.learning_rate2)\n",
    "        full_train_op = full_optimizer.minimize(loss)\n",
    "        \n",
    "   \n",
    "        # Evaluation metrics\n",
    "        # Merge all logged summaries together\n",
    "        merged_summary_op = tf.summary.merge_all()\n",
    "    \n",
    "        tf.get_default_graph().finalize()\n",
    "    \n",
    "    # --------------------------------------------------------------------------\n",
    "    # Now that we have built the graph and finalized it, we define the session.\n",
    "    # The session is the interface to *run* the computational graph.\n",
    "    # We can call our training operations with `sess.run(train_op)` for instance\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "    \n",
    "        now = datetime.datetime.now()\n",
    "        # start summary of session\n",
    "        train_writer = tf.summary.FileWriter('./summaries/' +\n",
    "                                             '{}-{}-{}-{}-{}'.format(now.year, now.month, now.day, now.hour, now.minute) , sess.graph)\n",
    "        # sess.run(tf.global_variables_initializer())\n",
    "        init_fn(sess)  # load the pretrained weights\n",
    "        \n",
    "        # For debugging\n",
    "        # for v in tf.global_variables():\n",
    "        #     print(v.name)\n",
    "        \n",
    "        sess.run(extras_init) # initialize extra variables\n",
    "        sess.run(fc8_init)  # initialize the unused fc8 layer\n",
    "        sess.run(fc7_init) # initialize unused fc7\n",
    "        # sess.run(fc6_init) # initialize fc6\n",
    "        \n",
    "        iteration = 0\n",
    "        # Update only the last layer for a few epochs.\n",
    "        for epoch in range(args.num_epochs1):\n",
    "            # Run an epoch over the training data.\n",
    "            print('Starting epoch %d / %d' % (epoch + 1, args.num_epochs1))\n",
    "            # Here we initialize the iterator with the training set.\n",
    "            # This means that we can go through an entire epoch until the iterator becomes empty.\n",
    "            sess.run(train_init_op)\n",
    "            while True: # and iteration < 10:\n",
    "                try:\n",
    "                    _, curr_loss, curr_logits, curr_labels, summary = sess.run([extra_train_op, loss, logits, labels, merged_summary_op], {is_training: True}) # fc876_train_op,\n",
    "                    loss_log.append(curr_loss)\n",
    "                    train_writer.add_summary(summary, iteration)\n",
    "                    curr_logits = np.reshape(curr_logits, [-1, num_classes])\n",
    "                    \n",
    "                    if curr_loss < 100:\n",
    "                        print('Current loss: %f' % curr_loss)\n",
    "\n",
    "                        # Check F score on logits\n",
    "                        threshs = [0.05, 0.1, 0.25, 0.5, 0.75, 0.8, 0.9, 0.95]\n",
    "                        Fs = []\n",
    "                        \n",
    "                        for i in range(len(threshs)):\n",
    "                            Fs.append(fbeta_score(curr_labels, np.array(curr_logits) > threshs[i], beta=2, average='samples'))\n",
    "                        max_i = Fs.index(max(Fs))\n",
    "                        print('thresh: %f, max F: %f' %(threshs[max_i], Fs[max_i]))\n",
    "                        thresh_log.append(threshs[max_i])\n",
    "                        f_log.append(Fs[max_i])\n",
    "                        \n",
    "                        iteration += 1\n",
    "                    else:\n",
    "                        print(\"EXPLODING LOSS\")\n",
    "                        break\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "            \n",
    "            # Print current loss\n",
    "            print('Current epoch loss: %f' % curr_loss)\n",
    "            \n",
    "            # Check F score on logits\n",
    "            threshs = [0.05, 0.1, 0.25, 0.5, 0.75, 0.8, 0.9, 0.95]\n",
    "            Fs = []\n",
    "            for i in range(len(threshs)):\n",
    "                Fs.append(fbeta_score(curr_labels, np.array(curr_logits) > threshs[i], beta=2, average='samples'))\n",
    "            max_i = Fs.index(max(Fs))\n",
    "            print('Epoch thresh: %f, max F: %f' %(threshs[max_i], Fs[max_i]))\n",
    "            \n",
    "            # Check accuracy on the train and val sets every epoch.\n",
    "            # train_acc = check_accuracy(sess, correct_prediction, is_training, train_init_op)\n",
    "            # val_acc = check_accuracy(sess, correct_prediction, is_training, val_init_op)\n",
    "            # print('Train accuracy: %f' % train_acc)\n",
    "            # print('Val accuracy: %f\\n' % val_acc)\n",
    "    \n",
    "    \n",
    "        # Train the entire model for a few more epochs, continuing with the *same* weights.\n",
    "        for epoch in range(args.num_epochs2):\n",
    "            print('Starting epoch %d / %d' % (epoch + 1, args.num_epochs2))\n",
    "            sess.run(train_init_op)\n",
    "            while True: #  and iteration < 20:\n",
    "                try:\n",
    "                    _, curr_loss, curr_logits, curr_labels, summary = sess.run([full_train_op, loss, logits, labels, merged_summary_op], {is_training: True})\n",
    "                    loss_log.append(curr_loss)\n",
    "                    train_writer.add_summary(summary, iteration)\n",
    "\n",
    "                    curr_logits = np.reshape(curr_logits, [-1, num_classes])\n",
    "\n",
    "                    if curr_loss < 100:\n",
    "                        print('Current loss: %f' % curr_loss)\n",
    "\n",
    "                        # Check F score on logits\n",
    "                        threshs = [0.5, 0.1, 0.25, 0.5, 0.75, 0.8, 0.9, 0.95]\n",
    "                        Fs = []\n",
    "                        for i in range(len(threshs)):\n",
    "                            Fs.append(fbeta_score(curr_labels, np.array(curr_logits) > threshs[i], beta=2, average='samples'))\n",
    "                        max_i = Fs.index(max(Fs))\n",
    "                        print('thresh: %f, max F: %f' %(threshs[max_i], Fs[max_i]))\n",
    "                        thresh_log.append(threshs[max_i])\n",
    "                        f_log.append(Fs[max_i])\n",
    "                        \n",
    "                        if epoch == (args.num_epochs2-1):\n",
    "                            predicted_logits.append(curr_logits)\n",
    "                            actual_labels.append(curr_labels)\n",
    "                        \n",
    "                        iteration += 1\n",
    "                    else:\n",
    "                        print(\"EXPLODING LOSS\")\n",
    "                        break\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "    \n",
    "            # Print current loss\n",
    "            print('Entire model epoch loss: %f' % curr_loss)\n",
    "    \n",
    "            # Check F score on logits\n",
    "            threshs = [0.05, 0.1, 0.25, 0.5, 0.75, 0.8, 0.9, 0.95]\n",
    "            Fs = []\n",
    "            for i in range(len(threshs)):\n",
    "                Fs.append(fbeta_score(curr_labels, np.array(curr_logits) > threshs[i], beta=2, average='samples'))\n",
    "            max_i = Fs.index(max(Fs))\n",
    "            print('Entire model epoch thresh: %f, max F: %f' %(threshs[max_i], Fs[max_i]))\n",
    "            \n",
    "            \n",
    "            # Check accuracy on the train and val sets every epoch\n",
    "            # train_acc = check_accuracy(sess, correct_prediction, is_training, train_init_op)\n",
    "            # val_acc = check_accuracy(sess, correct_prediction, is_training, val_init_op)\n",
    "            # print('Train accuracy: %f' % train_acc)\n",
    "            # print('Val accuracy: %f\\n' % val_acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 1, 0],\n",
       "        [0, 1, 0, ..., 0, 1, 0],\n",
       "        ..., \n",
       "        [1, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0]], dtype=int32), array([[0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [1, 1, 0, ..., 0, 1, 0],\n",
       "        ..., \n",
       "        [1, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 1, 0]], dtype=int32), array([[0, 0, 1, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        ..., \n",
       "        [1, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0]], dtype=int32), array([[0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 1, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0]], dtype=int32), array([[0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0]], dtype=int32), array([[0, 1, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 1, 0, ..., 0, 1, 0],\n",
       "        ..., \n",
       "        [1, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0]], dtype=int32), array([[0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        ..., \n",
       "        [0, 1, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0]], dtype=int32), array([[0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0]], dtype=int32), array([[0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 1, 0, ..., 0, 1, 0],\n",
       "        ..., \n",
       "        [0, 1, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0]], dtype=int32), array([[0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        ..., \n",
       "        [1, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 1, 0, ..., 0, 1, 0],\n",
       "        [0, 1, 0, ..., 0, 1, 0]], dtype=int32)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.7339444,\n",
       " 7.4191761,\n",
       " 7.7160192,\n",
       " 7.9325938,\n",
       " 8.340826,\n",
       " 7.9754939,\n",
       " 7.4352045,\n",
       " 7.7459483,\n",
       " 8.023757,\n",
       " 7.66538]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
